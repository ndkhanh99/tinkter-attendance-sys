arguments: app-gui.py
--------------------
tensorflow version: 2.11.0
--------------------
git hash: b'5a61480f5537bceba23c43be3d285a8d332e2e61'
--------------------
b'diff --git a/.DS_Store b/.DS_Store\nindex fe6e40b..def1537 100644\nBinary files a/.DS_Store and b/.DS_Store differ\ndiff --git a/.data/processed/revision_info.txt b/.data/processed/revision_info.txt\ndeleted file mode 100644\nindex 6ce1646..0000000\n--- a/.data/processed/revision_info.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-arguments: app-gui.py\n---------------------\n-tensorflow version: 2.11.0\n---------------------\n-git hash: b\'9c81e69fd384d2ef884820592d4d0392b9fe5090\'\n---------------------\n-b\'diff --git a/Detector.py b/Detector.py\\nindex 4db826c..0896348 100644\\n--- a/Detector.py\\n+++ b/Detector.py\\n@@ -7,7 +7,7 @@ def main_app(name):\\n         face_cascade = cv2.CascadeClassifier(\\\'./data/haarcascade_frontalface_default.xml\\\')\\r\\n         recognizer = cv2.face.LBPHFaceRecognizer_create()\\r\\n         recognizer.read(f"./data/classifiers/{name}_classifier.xml")\\r\\n-        cap = cv2.VideoCapture(0)\\r\\n+        cap = cv2.VideoCapture(1)\\r\\n         pred = 0\\r\\n         while True:\\r\\n             ret, frame = cap.read()\\r\\ndiff --git a/app-gui.py b/app-gui.py\\nindex 0f64293..5bd0e37 100644\\n--- a/app-gui.py\\n+++ b/app-gui.py\\n@@ -1,11 +1,14 @@\\n from Detector import main_app\\r\\n-from create_classifier import train_classifer\\r\\n+from create_classifier import train_classifer, regFaces\\r\\n from create_dataset import start_capture\\r\\n import tkinter as tk\\r\\n from tkinter import font as tkfont\\r\\n-from tkinter import messagebox,PhotoImage\\r\\n-#from PIL import ImageTk, Image\\r\\n-#from gender_prediction import emotion,ageAndgender\\r\\n+from tkinter import messagebox, PhotoImage\\r\\n+from PIL import Image, ImageTk\\r\\n+import cv2\\r\\n+import os\\r\\n+# from PIL import ImageTk, Image\\r\\n+# from gender_prediction import emotion,ageAndgender\\r\\n names = set()\\r\\n \\r\\n \\r\\n@@ -14,23 +17,34 @@ class MainUI(tk.Tk):\\n     def __init__(self, *args, **kwargs):\\r\\n         tk.Tk.__init__(self, *args, **kwargs)\\r\\n         global names\\r\\n+        global open_webcam\\r\\n+        open_webcam = \\\'false\\\'\\r\\n         with open("nameslist.txt", "r") as f:\\r\\n             x = f.read()\\r\\n             z = x.rstrip().split(" ")\\r\\n             for i in z:\\r\\n                 names.add(i)\\r\\n-        self.title_font = tkfont.Font(family=\\\'Helvetica\\\', size=16, weight="bold")\\r\\n+        self.title_font = tkfont.Font(\\r\\n+            family=\\\'Helvetica\\\', size=16, weight="bold")\\r\\n         self.title("Face Recognizer")\\r\\n         self.resizable(False, False)\\r\\n-        self.geometry("500x250")\\r\\n+        app_width = 1200\\r\\n+        app_height = 600\\r\\n+        screen_width = self.winfo_screenwidth()\\r\\n+        screen_height = self.winfo_screenheight()\\r\\n+\\r\\n+        x = (screen_width / 2) - (app_width / 2)\\r\\n+        y = (screen_height / 2) - (app_height / 2)\\r\\n+\\r\\n+        self.geometry(f\\\'{app_width}x{app_height}+{int(x)}+{int(y)}\\\')\\r\\n         self.protocol("WM_DELETE_WINDOW", self.on_closing)\\r\\n         self.active_name = None\\r\\n         container = tk.Frame(self)\\r\\n-        container.grid(sticky="nsew")\\r\\n+        container.place(relx=0.5, rely=0.5, anchor=\\\'center\\\')\\r\\n         container.grid_rowconfigure(0, weight=1)\\r\\n         container.grid_columnconfigure(0, weight=1)\\r\\n         self.frames = {}\\r\\n-        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour):\\r\\n+        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour, PageTakeFace):\\r\\n             page_name = F.__name__\\r\\n             frame = F(parent=container, controller=self)\\r\\n             self.frames[page_name] = frame\\r\\n@@ -38,76 +52,100 @@ class MainUI(tk.Tk):\\n         self.show_frame("StartPage")\\r\\n \\r\\n     def show_frame(self, page_name):\\r\\n-            frame = self.frames[page_name]\\r\\n-            frame.tkraise()\\r\\n+        frame = self.frames[page_name]\\r\\n+        frame.tkraise()\\r\\n \\r\\n     def on_closing(self):\\r\\n \\r\\n         if messagebox.askokcancel("Quit", "Are you sure?"):\\r\\n             global names\\r\\n-            f =  open("nameslist.txt", "a+")\\r\\n+            f = open("nameslist.txt", "a+")\\r\\n             for i in names:\\r\\n-                    f.write(i+" ")\\r\\n+                f.write(i+" ")\\r\\n             self.destroy()\\r\\n \\r\\n \\r\\n class StartPage(tk.Frame):\\r\\n \\r\\n-        def __init__(self, parent, controller):\\r\\n-            tk.Frame.__init__(self, parent)\\r\\n-            self.controller = controller\\r\\n-            #load = Image.open("homepagepic.png")\\r\\n-            #load = load.resize((250, 250), Image.ANTIALIAS)\\r\\n-            render = PhotoImage(file=\\\'homepagepic.png\\\')\\r\\n-            img = tk.Label(self, image=render)\\r\\n-            img.image = render\\r\\n-            img.grid(row=0, column=1, rowspan=4, sticky="nsew")\\r\\n-            label = tk.Label(self, text="        Home Page        ", font=self.controller.title_font,fg="#263942")\\r\\n-            label.grid(row=0, sticky="ew")\\r\\n-            button1 = tk.Button(self, text="   Add a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageOne"))\\r\\n-            button2 = tk.Button(self, text="   Check a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageTwo"))\\r\\n-            button3 = tk.Button(self, text="Quit", fg="#263942", bg="#ffffff", command=self.on_closing)\\r\\n-            button1.grid(row=1, column=0, ipady=3, ipadx=7)\\r\\n-            button2.grid(row=2, column=0, ipady=3, ipadx=2)\\r\\n-            button3.grid(row=3, column=0, ipady=3, ipadx=32)\\r\\n-\\r\\n-\\r\\n-        def on_closing(self):\\r\\n-            if messagebox.askokcancel("Quit", "Are you sure?"):\\r\\n-                global names\\r\\n-                with open("nameslist.txt", "w") as f:\\r\\n-                    for i in names:\\r\\n-                        f.write(i + " ")\\r\\n-                self.controller.destroy()\\r\\n+    def __init__(self, parent, controller):\\r\\n+        tk.Frame.__init__(self, parent)\\r\\n+        self.controller = controller\\r\\n+\\r\\n+        load1 = Image.open("Touch_ID.png")\\r\\n+        load1 = load1.resize((250, 250), Image.ANTIALIAS)\\r\\n+        render1 = PhotoImage(file=\\\'Touch_ID.png\\\')\\r\\n+\\r\\n+        render1 = ImageTk.PhotoImage(Image.open(\\r\\n+            "Touch_ID.png").resize((250, 250), Image.ANTIALIAS))\\r\\n+\\r\\n+        button4 = tk.Button(\\r\\n+            self, image=render1)\\r\\n+        button4.image = render1\\r\\n+        button4.grid(row=0, column=0, rowspan=4,\\r\\n+                     padx=10, pady=12, sticky="nsew")\\r\\n+\\r\\n+        load2 = Image.open("face-id-id.png")\\r\\n+        load2 = load2.resize((50, 50), Image.ANTIALIAS)\\r\\n+        render2 = PhotoImage(file=\\\'face-id-id.png\\\')\\r\\n+\\r\\n+        render2 = ImageTk.PhotoImage(Image.open(\\r\\n+            "face-id-id.png").resize((250, 250), Image.ANTIALIAS))\\r\\n+\\r\\n+        button5 = tk.Button(\\r\\n+            self, image=render2, command=lambda: self.controller.show_frame("PageOne"))\\r\\n+        button5.image = render2\\r\\n+        button5.grid(row=1, column=1, rowspan=4,\\r\\n+                     padx=10, pady=12, sticky="nsew")\\r\\n+\\r\\n+    def on_closing(self):\\r\\n+        if messagebox.askokcancel("Quit", "Are you sure?"):\\r\\n+            global names\\r\\n+            with open("nameslist.txt", "w") as f:\\r\\n+                for i in names:\\r\\n+                    f.write(i + " ")\\r\\n+            self.controller.destroy()\\r\\n \\r\\n \\r\\n class PageOne(tk.Frame):\\r\\n     def __init__(self, parent, controller):\\r\\n         tk.Frame.__init__(self, parent)\\r\\n         self.controller = controller\\r\\n-        tk.Label(self, text="Enter the name", fg="#263942", font=\\\'Helvetica 12 bold\\\').grid(row=0, column=0, pady=10, padx=5)\\r\\n-        self.user_name = tk.Entry(self, borderwidth=3, bg="lightgrey", font=\\\'Helvetica 11\\\')\\r\\n-        self.user_name.grid(row=0, column=1, pady=10, padx=10)\\r\\n-        self.buttoncanc = tk.Button(self, text="Cancel", bg="#ffffff", fg="#263942", command=lambda: controller.show_frame("StartPage"))\\r\\n-        self.buttonext = tk.Button(self, text="Next", fg="#ffffff", bg="#263942", command=self.start_training)\\r\\n-        self.buttoncanc.grid(row=1, column=0, pady=10, ipadx=5, ipady=4)\\r\\n-        self.buttonext.grid(row=1, column=1, pady=10, ipadx=5, ipady=4)\\r\\n-    def start_training(self):\\r\\n-        global names\\r\\n-        if self.user_name.get() == "None":\\r\\n-            messagebox.showerror("Error", "Name cannot be \\\'None\\\'")\\r\\n-            return\\r\\n-        elif self.user_name.get() in names:\\r\\n-            messagebox.showerror("Error", "User already exists!")\\r\\n-            return\\r\\n-        elif len(self.user_name.get()) == 0:\\r\\n-            messagebox.showerror("Error", "Name cannot be empty!")\\r\\n-            return\\r\\n-        name = self.user_name.get()\\r\\n-        names.add(name)\\r\\n-        self.controller.active_name = name\\r\\n-        self.controller.frames["PageTwo"].refresh_names()\\r\\n-        self.controller.show_frame("PageThree")\\r\\n+\\r\\n+        color1 = \\\'#020f12\\\'\\r\\n+        color2 = \\\'#05d7ff\\\'\\r\\n+        color3 = \\\'#65e7ff\\\'\\r\\n+        color4 = \\\'BLACK\\\'\\r\\n+        color5 = \\\'YELLOW\\\'\\r\\n+        self.buttoncanc = tk.Button(self,\\r\\n+                                    background=color2,\\r\\n+                                    foreground=color4,\\r\\n+                                    activebackground=color3,\\r\\n+                                    activeforeground=color4,\\r\\n+                                    highlightthickness=2,\\r\\n+                                    highlightbackground=color2,\\r\\n+                                    width=15,\\r\\n+                                    height=2,\\r\\n+                                    border=0,\\r\\n+                                    cursor=\\\'hand2\\\',\\r\\n+                                    text="Cancel",\\r\\n+                                    font=(\\\'Arial\\\', 16, \\\'bold\\\'),\\r\\n+                                    command=lambda: controller.show_frame("StartPage"))\\r\\n+        self.buttoncanc.place(relx=0.5, rely=0.5, anchor=\\\'center\\\')\\r\\n+\\r\\n+        self.buttonTakeFace = tk.Button(self,\\r\\n+                                        background=color2,\\r\\n+                                        foreground=color4,\\r\\n+                                        activebackground=color3,\\r\\n+                                        activeforeground=color4,\\r\\n+                                        highlightthickness=2,\\r\\n+                                        highlightbackground=color2,\\r\\n+                                        width=15,\\r\\n+                                        height=2,\\r\\n+                                        border=0,\\r\\n+                                        cursor=\\\'hand2\\\',\\r\\n+                                        text="Add new",\\r\\n+                                        font=(\\\'Arial\\\', 16, \\\'bold\\\'), command=lambda: controller.show_frame("PageTakeFace"))\\r\\n+        self.buttonTakeFace.place(relx=0.5, rely=0.3, anchor=\\\'center\\\')\\r\\n \\r\\n \\r\\n class PageTwo(tk.Frame):\\r\\n@@ -116,13 +154,16 @@ class PageTwo(tk.Frame):\\n         tk.Frame.__init__(self, parent)\\r\\n         global names\\r\\n         self.controller = controller\\r\\n-        tk.Label(self, text="Select user", fg="#263942", font=\\\'Helvetica 12 bold\\\').grid(row=0, column=0, padx=10, pady=10)\\r\\n-        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\r\\n+        tk.Label(self, text="Select user", fg="#263942", font=\\\'Helvetica 12 bold\\\').grid(\\r\\n+            row=0, column=0, padx=10, pady=10)\\r\\n+        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame(\\r\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\r\\n         self.menuvar = tk.StringVar(self)\\r\\n         self.dropdown = tk.OptionMenu(self, self.menuvar, *names)\\r\\n         self.dropdown.config(bg="lightgrey")\\r\\n         self.dropdown["menu"].config(bg="lightgrey")\\r\\n-        self.buttonext = tk.Button(self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\r\\n+        self.buttonext = tk.Button(\\r\\n+            self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\r\\n         self.dropdown.grid(row=0, column=1, ipadx=8, padx=10, pady=10)\\r\\n         self.buttoncanc.grid(row=1, ipadx=5, ipady=4, column=0, pady=10)\\r\\n         self.buttonext.grid(row=1, ipadx=5, ipady=4, column=1, pady=10)\\r\\n@@ -139,34 +180,36 @@ class PageTwo(tk.Frame):\\n         self.menuvar.set(\\\'\\\')\\r\\n         self.dropdown[\\\'menu\\\'].delete(0, \\\'end\\\')\\r\\n         for name in names:\\r\\n-            self.dropdown[\\\'menu\\\'].add_command(label=name, command=tk._setit(self.menuvar, name))\\r\\n+            self.dropdown[\\\'menu\\\'].add_command(\\r\\n+                label=name, command=tk._setit(self.menuvar, name))\\r\\n+\\r\\n \\r\\n class PageThree(tk.Frame):\\r\\n \\r\\n     def __init__(self, parent, controller):\\r\\n         tk.Frame.__init__(self, parent)\\r\\n         self.controller = controller\\r\\n-        self.numimglabel = tk.Label(self, text="Number of images captured = 0", font=\\\'Helvetica 12 bold\\\', fg="#263942")\\r\\n-        self.numimglabel.grid(row=0, column=0, columnspan=2, sticky="ew", pady=10)\\r\\n-        self.capturebutton = tk.Button(self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\r\\n-        self.trainbutton = tk.Button(self, text="Train The Model", fg="#ffffff", bg="#263942",command=self.trainmodel)\\r\\n-        self.capturebutton.grid(row=1, column=0, ipadx=5, ipady=4, padx=10, pady=20)\\r\\n-        self.trainbutton.grid(row=1, column=1, ipadx=5, ipady=4, padx=10, pady=20)\\r\\n+        self.numimglabel = tk.Label(\\r\\n+            self, text="Number of images captured = 0", font=\\\'Helvetica 12 bold\\\', fg="#263942")\\r\\n+        self.numimglabel.grid(\\r\\n+            row=0, column=0, columnspan=2, sticky="ew", pady=10)\\r\\n+        # self.capturebutton = tk.Button(\\r\\n+        #     self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\r\\n+        # self.trainbutton = tk.Button(\\r\\n+        #     self, text="Train The Model", fg="#ffffff", bg="#263942", command=self.trainmodel)\\r\\n+        # self.capturebutton.grid(row=1, column=0, ipadx=5,\\r\\n+        #                         ipady=4, padx=10, pady=20)\\r\\n+        # self.trainbutton.grid(row=1, column=1, ipadx=5,\\r\\n+        #                       ipady=4, padx=10, pady=20)\\r\\n \\r\\n     def capimg(self):\\r\\n         self.numimglabel.config(text=str("Captured Images = 0 "))\\r\\n-        messagebox.showinfo("INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\r\\n+        messagebox.showinfo(\\r\\n+            "INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\r\\n         x = start_capture(self.controller.active_name)\\r\\n         self.controller.num_of_images = x\\r\\n-        self.numimglabel.config(text=str("Number of images captured = "+str(x)))\\r\\n-\\r\\n-    def trainmodel(self):\\r\\n-        if self.controller.num_of_images < 300:\\r\\n-            messagebox.showerror("ERROR", "No enough Data, Capture at least 300 images!")\\r\\n-            return\\r\\n-        train_classifer(self.controller.active_name)\\r\\n-        messagebox.showinfo("SUCCESS", "The modele has been successfully trained!")\\r\\n-        self.controller.show_frame("PageFour")\\r\\n+        self.numimglabel.config(\\r\\n+            text=str("Number of images captured = "+str(x)))\\r\\n \\r\\n \\r\\n class PageFour(tk.Frame):\\r\\n@@ -175,27 +218,171 @@ class PageFour(tk.Frame):\\n         tk.Frame.__init__(self, parent)\\r\\n         self.controller = controller\\r\\n \\r\\n-        label = tk.Label(self, text="Face Recognition", font=\\\'Helvetica 16 bold\\\')\\r\\n-        label.grid(row=0,column=0, sticky="ew")\\r\\n-        button1 = tk.Button(self, text="Face Recognition", command=self.openwebcam, fg="#ffffff", bg="#263942")\\r\\n-        #button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\r\\n-        #button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\r\\n-        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\r\\n-        button1.grid(row=1,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n-        #button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n-        #button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n-        button4.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n+        label = tk.Label(self, text="Face Recognition",\\r\\n+                         font=\\\'Helvetica 16 bold\\\')\\r\\n+        label.grid(row=0, column=0, sticky="ew")\\r\\n+        button1 = tk.Button(self, text="Face Recognition",\\r\\n+                            command=self.openwebcam, fg="#ffffff", bg="#263942")\\r\\n+        # button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\r\\n+        # button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\r\\n+        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame(\\r\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\r\\n+        button1.grid(row=1, column=0, sticky="ew",\\r\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\r\\n+        # button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n+        # button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\r\\n+        button4.grid(row=1, column=1, sticky="ew",\\r\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\r\\n \\r\\n     def openwebcam(self):\\r\\n         main_app(self.controller.active_name)\\r\\n-    #def gender_age_pred(self):\\r\\n+    # def gender_age_pred(self):\\r\\n      #  ageAndgender()\\r\\n-    #def emot(self):\\r\\n+    # def emot(self):\\r\\n      #   emotion()\\r\\n \\r\\n \\r\\n+num_of_images = 0\\r\\n+\\r\\n+\\r\\n+class PageTakeFace(tk.Frame):\\r\\n+    def __init__(self, parent, controller):\\r\\n+        tk.Frame.__init__(self, parent)\\r\\n+        self.controller = controller\\r\\n+\\r\\n+        global cam_on\\r\\n+        cam_on = False\\r\\n+        global cap\\r\\n+        cap = None\\r\\n+        # student_id = \\\'_\\\'.join([\\\'student\\\', stundent_id_entry])\\r\\n+\\r\\n+        def display_frame():\\r\\n+            global cam_on\\r\\n+            global num_of_images\\r\\n+            detector = cv2.CascadeClassifier(\\r\\n+                "./data/haarcascade_frontalface_default.xml")\\r\\n+\\r\\n+            filepath = \\\'./data/student/raw/\\\' + stundent_id_entry.get()\\r\\n+\\r\\n+            isExist = os.path.exists(filepath)\\r\\n+\\r\\n+            if not isExist:\\r\\n+                print(\\\'The new directory is created!\\\')\\r\\n+                print(filepath)\\r\\n+                os.makedirs(filepath)\\r\\n+\\r\\n+            if cam_on:\\r\\n+\\r\\n+                ret, frame = cap.read()\\r\\n+\\r\\n+                if ret:\\r\\n+                    opencv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\\r\\n+                    filename = \\\'.\\\'.join([str(num_of_images), \\\'jpg\\\'])\\r\\n+                    path = os.path.join(filepath, filename)\\r\\n+                    cv2.imwrite(path, frame)\\r\\n+                    face = detector.detectMultiScale(\\r\\n+                        image=opencv_image, scaleFactor=1.1, minNeighbors=5)\\r\\n+                    for x, y, w, h in face:\\r\\n+                        cv2.rectangle(frame, (x, y),\\r\\n+                                      (x+w, y+h), (8, 238, 255), 2)\\r\\n+                        cv2.putText(frame, "Face Detected", (x, y-5),\\r\\n+                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\r\\n+                        cv2.putText(frame, str(str(num_of_images)+" images captured"),\\r\\n+                                    (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\r\\n+                        # new_img = frame[y:y+h, x:x+w]\\r\\n+\\r\\n+                    # Capture the latest frame and transform to image\\r\\n+                    captured_image = Image.fromarray(\\r\\n+                        cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA))\\r\\n+\\r\\n+                    # Convert captured image to photoimage\\r\\n+                    photo_image = ImageTk.PhotoImage(\\r\\n+                        captured_image.resize((500, 300), Image.ANTIALIAS))\\r\\n+\\r\\n+                    # Displaying photoimage in the label\\r\\n+                    label_widget.photo_image = photo_image\\r\\n+\\r\\n+                    # Configure image in the label\\r\\n+                    label_widget.configure(image=photo_image)\\r\\n+\\r\\n+                    # Repeat the same process after every 10 seconds\\r\\n+                    num_of_images += 1\\r\\n+\\r\\n+                    if num_of_images == 21:\\r\\n+                        stop_vid()\\r\\n+                        num_of_images = 0\\r\\n+                        messagebox.showinfo(\\r\\n+                            "INSTRUCTIONS", "We captured 20 pic of your Face.")\\r\\n+                        button1.grid(row=8, column=0, padx=10,\\r\\n+                                     pady=10, ipadx=5, ipady=4)\\r\\n+                        return \\\'ok\\\'\\r\\n+\\r\\n+                label_widget.after(10, display_frame)\\r\\n+\\r\\n+        def start_vid():\\r\\n+            global cam_on, cap\\r\\n+            stop_vid()\\r\\n+            cam_on = True\\r\\n+            cap = cv2.VideoCapture(1)\\r\\n+            display_frame()\\r\\n+\\r\\n+        def stop_vid():\\r\\n+            label_widget.configure(image=None)\\r\\n+            label_widget.configure(image="")\\r\\n+\\r\\n+            global cam_on\\r\\n+            cam_on = False\\r\\n+\\r\\n+            if cap:\\r\\n+                cap.release()\\r\\n+\\r\\n+        def trainmodel():\\r\\n+            # if self.controller.num_of_images < 300:\\r\\n+            #     messagebox.showerror(\\r\\n+            #         "ERROR", "No enough Data, Capture at least 300 images!")\\r\\n+            #     return\\r\\n+            regFaces()\\r\\n+            messagebox.showinfo(\\r\\n+                "SUCCESS", "You can now implement your detection")\\r\\n+\\r\\n+        ####### take face screen #######\\r\\n+\\r\\n+        user_info_frame = tk.LabelFrame(self, text="User Information")\\r\\n+        user_info_frame.grid(row=0, column=0, padx=20, pady=10)\\r\\n+\\r\\n+        first_name_label = tk.Label(user_info_frame, text="Your Name")\\r\\n+        first_name_label.grid(row=0, column=0)\\r\\n+        student_id_label = tk.Label(user_info_frame, text="Your Student Id")\\r\\n+        student_id_label.grid(row=0, column=1)\\r\\n+\\r\\n+        first_name_entry = tk.Entry(user_info_frame)\\r\\n+        stundent_id_entry = tk.Entry(user_info_frame)\\r\\n+        first_name_entry.grid(row=1, column=0)\\r\\n+        stundent_id_entry.grid(row=1, column=1)\\r\\n+\\r\\n+        buttoncanc = tk.Button(user_info_frame, text="Cancel", bg="#ffffff",\\r\\n+                               fg="#263942", command=lambda: controller.show_frame("StartPage"))\\r\\n+        buttoncanc.grid(row=2, column=0, pady=10, ipadx=5, ipady=4)\\r\\n+\\r\\n+        buttoncanc = tk.Button(user_info_frame, text="Confirm", bg="#ffffff",\\r\\n+                               fg="#263942", command=start_vid)\\r\\n+        buttoncanc.grid(row=2, column=1, pady=10, ipadx=5, ipady=4)\\r\\n+\\r\\n+        label_widget = tk.Label(self)\\r\\n+        label_widget.grid(row=3, column=0)\\r\\n+\\r\\n+        # age_label = tk.Label(user_info_frame, text="Age")\\r\\n+        # age_spinbox = tk.Spinbox(user_info_frame, from_=18, to=110)\\r\\n+        # age_label.grid(row=2, column=0)\\r\\n+        # age_spinbox.grid(row=3, column=0)\\r\\n+\\r\\n+        for widget in user_info_frame.winfo_children():\\r\\n+            widget.grid_configure(padx=10, pady=5)\\r\\n+\\r\\n+        button1 = tk.Button(self, text="Training Model",\\r\\n+                            command=trainmodel)\\r\\n+\\r\\n \\r\\n app = MainUI()\\r\\n app.iconphoto(False, tk.PhotoImage(file=\\\'icon.ico\\\'))\\r\\n app.mainloop()\\r\\n-\\r\\ndiff --git a/create_classifier.py b/create_classifier.py\\nindex a022cf5..d4bb3c6 100644\\n--- a/create_classifier.py\\n+++ b/create_classifier.py\\n@@ -1,10 +1,34 @@\\n import numpy as np\\r\\n from PIL import Image\\r\\n-import os, cv2\\r\\n-\\r\\n+import os\\r\\n+import cv2\\r\\n+from Helper.align_dataset_mtcnn import main\\r\\n+from Helper.classifier import mainTrain\\r\\n+\\r\\n+\\r\\n+def regFaces():\\r\\n+    input_dir = \\\'./data/raw\\\'\\r\\n+    output_dir = \\\'.data/processed\\\'\\r\\n+    image_size = 160\\r\\n+    margin = 32\\r\\n+    random_order = \\\'random_order\\\'\\r\\n+    gpu_memory_fraction = 0.25\\r\\n+    args = {\\r\\n+        \\\'input_dir\\\': input_dir,\\r\\n+        \\\'output_dir\\\': output_dir,\\r\\n+        \\\'image_size\\\': image_size,\\r\\n+        \\\'margin\\\': margin,\\r\\n+        \\\'random_order\\\': random_order,\\r\\n+        \\\'gpu_memory_fraction\\\': gpu_memory_fraction,\\r\\n+        \\\'detect_multiple_faces\\\': False\\r\\n+    }\\r\\n+    print(args[\\\'output_dir\\\'])\\r\\n+    main(args)\\r\\n+    data = \\\'complete reg faces\\\'\\r\\n+    return\\r\\n+# Method to train custom classifier to recognize face\\r\\n \\r\\n \\r\\n-# Method to train custom classifier to recognize face\\r\\n def train_classifer(name):\\r\\n     # Read all the images in custom data-set\\r\\n     path = os.path.join(os.getcwd()+"/data/"+name+"/")\\r\\n@@ -14,27 +38,24 @@ def train_classifer(name):\\n     labels = []\\r\\n     pictures = {}\\r\\n \\r\\n-\\r\\n     # Store images in a numpy format and ids of the user on the same index in imageNp and id lists\\r\\n \\r\\n-    for root,dirs,files in os.walk(path):\\r\\n-            pictures = files\\r\\n-\\r\\n+    for root, dirs, files in os.walk(path):\\r\\n+        pictures = files\\r\\n \\r\\n-    for pic in pictures :\\r\\n+    for pic in pictures:\\r\\n \\r\\n-            imgpath = path+pic\\r\\n-            img = Image.open(imgpath).convert(\\\'L\\\')\\r\\n-            imageNp = np.array(img, \\\'uint8\\\')\\r\\n-            id = int(pic.split(name)[0])\\r\\n-            #names[name].append(id)\\r\\n-            faces.append(imageNp)\\r\\n-            ids.append(id)\\r\\n+        imgpath = path+pic\\r\\n+        img = Image.open(imgpath).convert(\\\'L\\\')\\r\\n+        imageNp = np.array(img, \\\'uint8\\\')\\r\\n+        id = int(pic.split(name)[0])\\r\\n+        # names[name].append(id)\\r\\n+        faces.append(imageNp)\\r\\n+        ids.append(id)\\r\\n \\r\\n     ids = np.array(ids)\\r\\n \\r\\n-    #Train and save classifier\\r\\n+    # Train and save classifier\\r\\n     clf = cv2.face.LBPHFaceRecognizer_create()\\r\\n     clf.train(faces, ids)\\r\\n     clf.write("./data/classifiers/"+name+"_classifier.xml")\\r\\n-\\r\\ndiff --git a/create_dataset.py b/create_dataset.py\\nindex 1fbeab1..fbc4f04 100644\\n--- a/create_dataset.py\\n+++ b/create_dataset.py\\n@@ -1,38 +1,41 @@\\n import cv2\\r\\n import os\\r\\n \\r\\n-def start_capture(name):\\r\\n-        path = "./data/" + name\\r\\n-        num_of_images = 0\\r\\n-        detector = cv2.CascadeClassifier("./data/haarcascade_frontalface_default.xml")\\r\\n-        try:\\r\\n-            os.makedirs(path)\\r\\n-        except:\\r\\n-            print(\\\'Directory Already Created\\\')\\r\\n-        vid = cv2.VideoCapture(0)\\r\\n-        while True:\\r\\n-\\r\\n-            ret, img = vid.read()\\r\\n-            new_img = None\\r\\n-            grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\r\\n-            face = detector.detectMultiScale(image=grayimg, scaleFactor=1.1, minNeighbors=5)\\r\\n-            for x, y, w, h in face:\\r\\n-                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\r\\n-                cv2.putText(img, "Face Detected", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\r\\n-                cv2.putText(img, str(str(num_of_images)+" images captured"), (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\r\\n-                new_img = img[y:y+h, x:x+w]\\r\\n-            cv2.imshow("FaceDetection", img)\\r\\n-            key = cv2.waitKey(1) & 0xFF\\r\\n \\r\\n+def start_capture(name):\\r\\n+    path = "./data/" + name\\r\\n+    num_of_images = 0\\r\\n+    detector = cv2.CascadeClassifier(\\r\\n+        "./data/haarcascade_frontalface_default.xml")\\r\\n+    try:\\r\\n+        os.makedirs(path)\\r\\n+    except:\\r\\n+        print(\\\'Directory Already Created\\\')\\r\\n+    vid = cv2.VideoCapture(1)\\r\\n+    while True:\\r\\n \\r\\n-            try :\\r\\n-                cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\r\\n-                num_of_images += 1\\r\\n-            except :\\r\\n+        ret, img = vid.read()\\r\\n+        new_img = None\\r\\n+        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\r\\n+        face = detector.detectMultiScale(\\r\\n+            image=grayimg, scaleFactor=1.1, minNeighbors=5)\\r\\n+        for x, y, w, h in face:\\r\\n+            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\r\\n+            cv2.putText(img, "Face Detected", (x, y-5),\\r\\n+                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\r\\n+            cv2.putText(img, str(str(num_of_images)+" images captured"),\\r\\n+                        (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\r\\n+            new_img = img[y:y+h, x:x+w]\\r\\n+        cv2.imshow("FaceDetection", img)\\r\\n+        key = cv2.waitKey(1) & 0xFF\\r\\n \\r\\n-                pass\\r\\n-            if key == ord("q") or key == 27 or num_of_images > 310:\\r\\n-                break\\r\\n-        cv2.destroyAllWindows()\\r\\n-        return num_of_images\\r\\n+        try:\\r\\n+            cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\r\\n+            num_of_images += 1\\r\\n+        except:\\r\\n \\r\\n+            pass\\r\\n+        if key == ord("q") or key == 27 or num_of_images > 10:\\r\\n+            break\\r\\n+    cv2.destroyAllWindows()\\r\\n+    return num_of_images\\r\\ndiff --git a/nameslist.txt b/nameslist.txt\\nindex e605024..e11a3f3 100644\\n--- a/nameslist.txt\\n+++ b/nameslist.txt\\n@@ -1 +1 @@\\n-NO \\n\\\\ No newline at end of file\\n+                                                                    \\n\\\\ No newline at end of file\'\n\\ No newline at end of file\ndiff --git a/.gitignore b/.gitignore\nindex 67208b9..8a268fe 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,2 +1,3 @@\n env/\n-model/\n\\ No newline at end of file\n+model/\n+node_modules/\n\\ No newline at end of file\ndiff --git a/__pycache__/create_classifier.cpython-37.pyc b/__pycache__/create_classifier.cpython-37.pyc\nindex ce214a6..f6c4dac 100644\nBinary files a/__pycache__/create_classifier.cpython-37.pyc and b/__pycache__/create_classifier.cpython-37.pyc differ\ndiff --git a/app-gui.py b/app-gui.py\nindex 0c6fe9b..4ef57ba 100644\n--- a/app-gui.py\n+++ b/app-gui.py\n@@ -32,17 +32,29 @@ cred = credentials.Certificate(\n firebase_admin.initialize_app(cred)\r\n \r\n global arduino\r\n-arduino = serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1)\r\n+\r\n+\r\n+def connectArduino():\r\n+    global arduino\r\n+    arduino = serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1)\r\n+\r\n+\r\n time.sleep(0.2)  # wait for serial to open\r\n \r\n names = set()\r\n db = firestore.client()\r\n utc = pytz.UTC\r\n+global subject_now\r\n+subject_now = db.collection(\r\n+    \'current_subject\').document(\'current\').get()\r\n+subject_now = subject_now.to_dict()\r\n \r\n \r\n class MainUI(tk.Tk):\r\n \r\n     def __init__(self, *args, **kwargs):\r\n+        # loadSubjectModel()\r\n+        connectArduino()\r\n         tk.Tk.__init__(self, *args, **kwargs)\r\n         global names\r\n         global open_webcam\r\n@@ -72,7 +84,7 @@ class MainUI(tk.Tk):\n         container.grid_rowconfigure(0, weight=1)\r\n         container.grid_columnconfigure(0, weight=1)\r\n         self.frames = {}\r\n-        for F in (StartPage, PageOne, PageTwo, PageThree, PageDetectFingert, PageFour, PageTakeFace, PageDetectFace):\r\n+        for F in (StartPage, FaceIndex, FingerIndex, PageEnrollFinger, PageDetectFingert, PageFour, PageTakeFace, PageDetectFace):\r\n             page_name = F.__name__\r\n             frame = F(parent=container, controller=self)\r\n             self.frames[page_name] = frame\r\n@@ -107,7 +119,7 @@ class StartPage(tk.Frame):\n             "Touch_ID.png").resize((250, 250), Image.ANTIALIAS))\r\n \r\n         button4 = tk.Button(\r\n-            self, image=render1, command=lambda: self.controller.show_frame("PageTwo"))\r\n+            self, image=render1, command=lambda: self.controller.show_frame("FingerIndex"))\r\n         button4.image = render1\r\n         button4.grid(row=0, column=0, rowspan=4,\r\n                      padx=10, pady=12, sticky="nsew")\r\n@@ -120,7 +132,7 @@ class StartPage(tk.Frame):\n             "face-id-id.png").resize((250, 250), Image.ANTIALIAS))\r\n \r\n         button5 = tk.Button(\r\n-            self, image=render2, command=lambda: self.controller.show_frame("PageOne"))\r\n+            self, image=render2, command=lambda: self.controller.show_frame("FaceIndex"))\r\n         button5.image = render2\r\n         button5.grid(row=1, column=1, rowspan=4,\r\n                      padx=10, pady=12, sticky="nsew")\r\n@@ -134,7 +146,7 @@ class StartPage(tk.Frame):\n             self.controller.destroy()\r\n \r\n \r\n-class PageOne(tk.Frame):\r\n+class FaceIndex(tk.Frame):\r\n     def __init__(self, parent, controller):\r\n         tk.Frame.__init__(self, parent)\r\n         self.controller = controller\r\n@@ -191,7 +203,7 @@ class PageOne(tk.Frame):\n         self.buttonTakeFace.place(relx=0.5, rely=0.1, anchor=\'center\')\r\n \r\n \r\n-class PageTwo(tk.Frame):\r\n+class FingerIndex(tk.Frame):\r\n     def __init__(self, parent, controller):\r\n         tk.Frame.__init__(self, parent)\r\n         self.controller = controller\r\n@@ -230,7 +242,7 @@ class PageTwo(tk.Frame):\n                                         border=0,\r\n                                         cursor=\'hand2\',\r\n                                         text="New Fingerprint",\r\n-                                        font=(\'Arial\', 16, \'bold\'), command=lambda: controller.show_frame("PageThree"))\r\n+                                        font=(\'Arial\', 16, \'bold\'), command=lambda: controller.show_frame("PageEnrollFinger"))\r\n         self.buttonTakeFace.place(relx=0.5, rely=0.3, anchor=\'center\')\r\n \r\n         self.buttonTakeFace = tk.Button(self,\r\n@@ -249,7 +261,7 @@ class PageTwo(tk.Frame):\n         self.buttonTakeFace.place(relx=0.5, rely=0.1, anchor=\'center\')\r\n \r\n \r\n-class PageThree(tk.Frame):\r\n+class PageEnrollFinger(tk.Frame):\r\n \r\n     global message\r\n     message = False\r\n@@ -259,36 +271,12 @@ class PageThree(tk.Frame):\n         global names\r\n         self.controller = controller\r\n \r\n-        def arduino_detect(msg):\r\n-            print(\'Running. Press CTRL-C to exit.\')\r\n-            if message == True:\r\n-                arduino = serial.Serial(\r\n-                    "/dev/cu.usbmodem14201", 9600, timeout=1)\r\n-                time.sleep(0.1)  # wait for serial to open\r\n-                if arduino.isOpen():\r\n-                    print("{} connected!".format(arduino.port))\r\n-                    try:\r\n-                        # cmd=str(input("Enter command : "))\r\n-                        arduino.write(str(msg).encode())\r\n-                        while True:\r\n-                            time.sleep(0.5)  # wait for arduino to answer\r\n-                            answer = arduino.readline()\r\n-                            print(answer)\r\n-                            if answer == b\'ok\':\r\n-                                # print(\'break\')\r\n-                                # cmd=str(input("Enter command : "))\r\n-                                return answer\r\n-                            # arduino.flushInput()\r\n-                    except KeyboardInterrupt:\r\n-                        print("KeyboardInterrupt has been caught.")\r\n-\r\n         def arduino_enroll(msg, new_finger_id):\r\n             print(msg)\r\n             print(new_finger_id)\r\n             print(\'Running. Press CTRL-C to exit.\')\r\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as enroll_finger:\r\n                 time.sleep(0.1)  # wait for serial to open\r\n-                # global arduino\r\n                 if enroll_finger.isOpen():\r\n                     print("{} connected!".format(enroll_finger.port))\r\n                     try:\r\n@@ -296,15 +284,14 @@ class PageThree(tk.Frame):\n                             time.sleep(0.5)  # wait for arduino to answer\r\n                             answer = enroll_finger.readline()\r\n                             print(answer)\r\n-                            # if b"Sensor contains" in answer or b"doesn\'t" in answer:\r\n                             enroll_finger.write(str(msg).encode())\r\n+\r\n                             if answer == b\'#id\\r\\n\':\r\n-                                # print(\'break\')\r\n                                 arduino.flushInput()\r\n                                 arduino.flushOutput()\r\n                                 arduino.reset_input_buffer()\r\n                                 arduino.reset_output_buffer()\r\n-                                # cmd = str(input("Enter command : "))\r\n+\r\n                                 cmd = str(new_finger_id)\r\n                                 enroll_finger.write(str(cmd).encode())\r\n                                 while True:\r\n@@ -328,6 +315,7 @@ class PageThree(tk.Frame):\n                                             \'fingers\').document(\'id\').update({\'id\': new_finger_id + 1})\r\n                                         self.notify.config(\r\n                                             text=\'Successfully encode fingerprint\')\r\n+                                        connectArduino()\r\n                                         break\r\n                                     # return answer\r\n                                 break\r\n@@ -393,7 +381,7 @@ class PageDetectFingert(tk.Frame):\n         tk.Frame.__init__(self, parent)\r\n         global names\r\n         global status\r\n-        status = \'loading\'\r\n+        status = \'Place your finger to the pad\'\r\n         self.controller = controller\r\n \r\n         def arduino_detect(msg, mode):\r\n@@ -409,7 +397,7 @@ class PageDetectFingert(tk.Frame):\n                         time.sleep(0.5)  # wait for arduino to answer\r\n                         answer = arduino.readline()\r\n                         print(answer)\r\n-                        if b"doesn\'t" in answer:\r\n+                        if b\'any\' in answer:\r\n                             messagebox.showinfo(\r\n                                 "ALERT", "No fingerprint to detect")\r\n                             break\r\n@@ -425,8 +413,6 @@ class PageDetectFingert(tk.Frame):\n                             if b\'ID\' in answer:\r\n                                 idText = answer\r\n                             if b\'ok\' in answer:\r\n-                                self.notify1.config(\r\n-                                    text=\'Successfully detect fingerprint\')\r\n                                 finger_id = idText.decode(\r\n                                     \'utf-8\').split("#")[1]\r\n                                 print(finger_id)\r\n@@ -463,6 +449,8 @@ class PageDetectFingert(tk.Frame):\n                                                 print(\'vao dung gio\')\r\n                                             db.collection(\'check_in\').add(\r\n                                                 {\'subject\': result[\'name\'], \'student_id\': user[\'student_id\'], \'student_name\': user[\'name\'], \'status\': status, \'type\': \'fingerprint_detect\', \'finger_id\': user[\'finger_id\'], \'time_in\': today - timedelta(hours=7)})\r\n+                                            messagebox.showinfo(\r\n+                                                \'NOTIFY\', "Checked in success")\r\n                                         else:\r\n                                             checkExist = db.collection(\'check_in\').where(\r\n                                                 "finger_id", "==", finger_id).get()\r\n@@ -482,6 +470,8 @@ class PageDetectFingert(tk.Frame):\n \r\n                                             db.collection(\'check_out\').add(\r\n                                                 {\'subject\': result[\'name\'], \'student_id\': user[\'student_id\'], \'student_name\': user[\'name\'], \'status\': status, \'type\': \'fingerprint_detect\', \'finger_id\': user[\'finger_id\'], \'time_out\': today - timedelta(hours=7)})\r\n+                                            messagebox.showinfo(\r\n+                                                \'NOTIFY\', "Checked out success")\r\n                                 break\r\n                             # return answer\r\n                         break\r\n@@ -549,12 +539,13 @@ class PageTakeFace(tk.Frame):\n         def display_frame():\r\n             global cam_on\r\n             global num_of_images\r\n+            global subject_now\r\n             detector = cv2.CascadeClassifier(\r\n                 "./data/haarcascade_frontalface_default.xml")\r\n \r\n             id = stundent_id_entry.get()\r\n \r\n-            filepath = \'./data/student/raw/\' + id\r\n+            filepath = \'./data/student/raw/\' + subject_now[\'name\'] + \'/\' + id\r\n \r\n             isExist = os.path.exists(filepath)\r\n \r\n@@ -568,6 +559,7 @@ class PageTakeFace(tk.Frame):\n                 ret, frame = cap.read()\r\n \r\n                 if ret:\r\n+                    time.sleep(0.2)\r\n                     opencv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\r\n                     filename = \'.\'.join([str(num_of_images), \'jpg\'])\r\n                     path = os.path.join(filepath, filename)\r\n@@ -613,10 +605,25 @@ class PageTakeFace(tk.Frame):\n \r\n         def start_vid():\r\n             global cam_on, cap\r\n+            global subject_now\r\n             stop_vid()\r\n-            cam_on = True\r\n-            cap = cv2.VideoCapture(1)\r\n-            display_frame()\r\n+            id = stundent_id_entry.get()\r\n+\r\n+            filepath = \'./data/student/raw/\' + subject_now[\'name\'] + \'/\' + id\r\n+\r\n+            isExist = os.path.exists(filepath)\r\n+\r\n+            if not isExist:\r\n+                cam_on = True\r\n+                subject_now = db.collection(\r\n+                    \'current_subject\').document(\'current\').get()\r\n+                subject_now = subject_now.to_dict()\r\n+                print(subject_now[\'name\'])\r\n+                cap = cv2.VideoCapture(1)\r\n+                display_frame()\r\n+            else:\r\n+                messagebox.showwarning("ALERT", "User exits")\r\n+                return\r\n \r\n         def stop_vid():\r\n             label_widget.configure(image=None)\r\n@@ -629,11 +636,16 @@ class PageTakeFace(tk.Frame):\n                 cap.release()\r\n \r\n         def trainmodel():\r\n+            global subject_now\r\n+            subject_now = db.collection(\r\n+                \'current_subject\').document(\'current\').get()\r\n+            subject_now = subject_now.to_dict()\r\n             # if self.controller.num_of_images < 300:\r\n             #     messagebox.showerror(\r\n             #         "ERROR", "No enough Data, Capture at least 300 images!")\r\n             #     return\r\n-            regFaces()\r\n+            print(subject_now[\'name\'])\r\n+            regFaces(subject_now[\'name\'])\r\n             messagebox.showinfo(\r\n                 "SUCCESS", "You can now implement your detection")\r\n \r\n@@ -682,33 +694,61 @@ THRESHOLD = [0.6, 0.7, 0.7]\n FACTOR = 0.709\r\n IMAGE_SIZE = 182\r\n INPUT_IMAGE_SIZE = 160\r\n-CLASSIFIER_PATH = \'model/facemodel.pkl\'\r\n-FACENET_MODEL_PATH = \'model/20180402-114759.pb\'\r\n-with open(CLASSIFIER_PATH, \'rb\') as file:\r\n-    model, class_names = pickle.load(file)\r\n-    print("Custom Classifier, Successfully loaded")\r\n-with tf.Graph().as_default():\r\n-\r\n-    # Cai dat GPU neu co\r\n-    gpu_options = tf.compat.v1.GPUOptions(\r\n-        per_process_gpu_memory_fraction=0.6)\r\n-    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\r\n-        gpu_options=gpu_options, log_device_placement=False))\r\n-\r\n-    with sess.as_default():\r\n-\r\n-        # Load the model\r\n-        print(\'Loading feature extraction model\')\r\n-        facenet.load_model(FACENET_MODEL_PATH)\r\n-\r\n-        # Get input and output tensors\r\n-        images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\r\n-        embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\r\n-        phase_train_placeholder = tf.compat.v1.get_default_graph(\r\n-        ).get_tensor_by_name("phase_train:0")\r\n-\r\n-        pnet, rnet, onet = detect_face.create_mtcnn(\r\n-            sess, "Helper/align")\r\n+global images_placeholder\r\n+global embeddings\r\n+global phase_train_placeholder\r\n+global pnet\r\n+global rnet\r\n+global onet\r\n+global sess\r\n+global model\r\n+global class_names\r\n+global lastSubject\r\n+lastSubject = \'\'\r\n+\r\n+\r\n+def loadSubjectModel():\r\n+    print("Loading model subject")\r\n+    global images_placeholder\r\n+    global embeddings\r\n+    global phase_train_placeholder\r\n+    global pnet\r\n+    global rnet\r\n+    global onet\r\n+    global sess\r\n+    global model\r\n+    global class_names\r\n+    global subject_now\r\n+\r\n+    CLASSIFIER_PATH = \'model/\' + subject_now[\'name\'] + \'/\' + \'facemodel.pkl\'\r\n+    print(CLASSIFIER_PATH)\r\n+    FACENET_MODEL_PATH = \'model/20180402-114759.pb\'\r\n+\r\n+    with open(CLASSIFIER_PATH, \'rb\') as file:\r\n+        model, class_names = pickle.load(file)\r\n+        print("Custom Classifier, Successfully loaded")\r\n+    with tf.Graph().as_default():\r\n+\r\n+        # Cai dat GPU neu co\r\n+        gpu_options = tf.compat.v1.GPUOptions(\r\n+            per_process_gpu_memory_fraction=0.6)\r\n+        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\r\n+            gpu_options=gpu_options, log_device_placement=False))\r\n+\r\n+        with sess.as_default():\r\n+\r\n+            # Load the model\r\n+            print(\'Loading feature extraction model\')\r\n+            facenet.load_model(FACENET_MODEL_PATH)\r\n+\r\n+            # Get input and output tensors\r\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\r\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\r\n+            phase_train_placeholder = tf.compat.v1.get_default_graph(\r\n+            ).get_tensor_by_name("phase_train:0")\r\n+\r\n+            pnet, rnet, onet = detect_face.create_mtcnn(\r\n+                sess, "Helper/align")\r\n \r\n \r\n ### PAGE DETECT FACES ###\r\n@@ -727,144 +767,191 @@ class PageDetectFace(tk.Frame):\n         detect_time = 0\r\n         global mode\r\n         mode = 1\r\n-        # student_id = \'_\'.join([\'student\', stundent_id_entry])\r\n \r\n         def detect_frame():\r\n+\r\n+            global lastSubject\r\n+            subject_compare = db.collection(\r\n+                \'current_subject\').document(\'current\').get()\r\n+            subject_compare = subject_compare.to_dict()\r\n+            if subject_compare["name"] != lastSubject:\r\n+                loadSubjectModel()\r\n+                lastSubject = subject_compare["name"]\r\n+\r\n+            global images_placeholder\r\n+            global embeddings\r\n+            global phase_train_placeholder\r\n+            global pnet\r\n+            global rnet\r\n+            global onet\r\n+            global sess\r\n+            global model\r\n+            global class_names\r\n+\r\n             global cam_detect_on\r\n             global count_unknown\r\n             global detect_time\r\n+\r\n             if cam_detect_on:\r\n \r\n                 ret, frame = cap_detect.read()\r\n \r\n                 if ret:\r\n-                    # frame = cap.read()\r\n-                    frame = imutils.resize(frame, width=600)\r\n-                    frame = cv2.flip(frame, 1)\r\n-                    # rand_name = random.randint(0, 1000)\r\n-                    bounding_boxes, _ = detect_face.detect_face(\r\n-                        frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\r\n-                    faces_found = bounding_boxes.shape[0]\r\n-\r\n-                    det = bounding_boxes[:, 0:4]\r\n-                    bb = np.zeros((faces_found, 4), dtype=(np.int32))\r\n-                    for i in range(faces_found):\r\n-                        bb[i][0] = det[i][0]\r\n-                        bb[i][1] = det[i][1]\r\n-                        bb[i][2] = det[i][2]\r\n-                        bb[i][3] = det[i][3]\r\n-                        print(bb[i][3] - bb[i][1])\r\n-                        print(frame.shape[0])\r\n-                        print((bb[i][3] - bb[i][1]) / frame.shape[0])\r\n-                        if (bb[i][3] - bb[i][1]) / frame.shape[0] > 0.25:\r\n-                            cropped = frame[bb[i][1]:bb[i]\r\n-                                            [3], bb[i][0]:bb[i][2], :]\r\n-                            scaled = cv2.resize(\r\n-                                cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE), interpolation=(cv2.INTER_CUBIC))\r\n-                            scaled = facenet.prewhiten(scaled)\r\n-                            scaled_reshape = scaled.reshape(\r\n-                                -1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\r\n-                            feed_dict = {\r\n-                                images_placeholder: scaled_reshape, phase_train_placeholder: False}\r\n-                            emb_array = sess.run(\r\n-                                embeddings, feed_dict=feed_dict)\r\n-                            predictions = model.predict_proba(emb_array)\r\n-                            best_class_indices = np.argmax(\r\n-                                predictions, axis=1)\r\n-                            best_class_probabilities = predictions[(\r\n-                                np.arange(len(best_class_indices)), best_class_indices)]\r\n-                            best_name = class_names[best_class_indices[0]]\r\n-                            # print(\'Name: {}, Probability: {}\'.format(\r\n-                            #     best_name, best_class_probabilities))\r\n-\r\n-                            count_unknown += 1\r\n-                            if best_class_probabilities > 0.9:\r\n-                                image_path = \'images/attendance/\'\r\n-                                print(\'Name: {}, Probability: {}\'.format(\r\n-                                    best_name, best_class_probabilities))\r\n-                                cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0,\r\n-                                                                                                  255,\r\n-                                                                                                  0), 2)\r\n-                                text_x = bb[i][0]\r\n-                                text_y = bb[i][3] + 20\r\n-                                cv2.putText(frame, best_name, (text_x, text_y), (cv2.FONT_HERSHEY_COMPLEX_SMALL), 1,\r\n-                                            (255, 255, 255), thickness=1, lineType=2)\r\n-                                cv2.putText(frame, (str(round(best_class_probabilities[0], 3))), (text_x, text_y + 17), (cv2.FONT_HERSHEY_COMPLEX_SMALL),\r\n-                                            1, (255, 255, 255), thickness=1, lineType=2)\r\n-\r\n-                                file_name = best_name + ".jpg"\r\n-                                if detect_time == 2:\r\n-                                    cv2.imwrite(os.path.join(\r\n-                                        image_path, file_name), frame)\r\n-                                    cv2.destroyAllWindows()\r\n-                                    result = db.collection(\r\n-                                        \'current_subject\').document(\'current\').get()\r\n-                                    result = result.to_dict()\r\n-                                    user = db.collection(\r\n-                                        \'current_subject\').document(\'current\').get()\r\n-                                    user.to_dict()\r\n-                                    today = datetime.datetime.now()\r\n-                                    print(today)\r\n-                                    status = \'in_time\'\r\n-                                    global mode\r\n-                                    if mode == 1:\r\n-                                        time_compare = result[\'time_in\'] + \\\r\n-                                            timedelta(hours=7)\r\n-                                        print(time_compare)\r\n-                                        if utc.localize(today) > time_compare:\r\n-                                            status = \'vao_tre\'\r\n-                                            print(\'vao tre\')\r\n-                                        else:\r\n-                                            status = \'vao_dung_gio\'\r\n-                                            print(\'vao dung gio\')\r\n-                                        db.collection(\'check_in\').add(\r\n-                                            {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'finger_id\': user[\'finger_id\'], \'time_in\': today - timedelta(hours=7)})\r\n-                                        print(\'complete detect\')\r\n-                                    else:\r\n-                                        time_compare = result[\'time_out\'] + \\\r\n-                                            timedelta(hours=7)\r\n-                                        if utc.localize(today) > time_compare:\r\n-                                            status = \'ra_dung_gio\'\r\n-                                            print(\'ra dung gio\')\r\n-                                        else:\r\n-                                            status = \'ra_som\'\r\n-                                            print(\'ra som\')\r\n-                                        db.collection(\'check_out\').add(\r\n-                                            {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'time_out\': today - timedelta(hours=7)})\r\n-                                        print(\'complete detect\')\r\n-                                    time.sleep(1)\r\n-                                    stop_detect()\r\n-                                    detect_time = 0\r\n-                                    return best_name\r\n-\r\n-                                detect_time += 1\r\n-                            else:\r\n-                                print(\'Unknown\')\r\n-                                print(count_unknown)\r\n-                                if count_unknown == 20:\r\n-                                    print(\'break\')\r\n-                                    best_name = \'unknown\'\r\n-                                    # VideoStream(src=0).stop()\r\n-                                    # cap.stop()\r\n-                                    cv2.destroyAllWindows()\r\n-                                    stop_detect()\r\n-                                    return best_name\r\n-\r\n-                    # Capture the latest frame and transform to image\r\n-                    captured_image = Image.fromarray(\r\n-                        cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA))\r\n-\r\n-                    # Convert captured image to photoimage\r\n-                    photo_image = ImageTk.PhotoImage(\r\n-                        captured_image.resize((500, 300), Image.ANTIALIAS))\r\n+                    for images in os.listdir("data/student/raw/subject_4/1811945"):\r\n+                        img = cv2.imread(os.path.join(\r\n+                            "data/student/raw/subject_4/1811945/", images))\r\n+                        if images is not None:\r\n+                            # images.append(img)\r\n+                            frame = imutils.resize(img, width=600)\r\n+                            frame = cv2.flip(frame, 1)\r\n+                            bounding_boxes, _ = detect_face.detect_face(\r\n+                                frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\r\n+                            faces_found = bounding_boxes.shape[0]\r\n+\r\n+                            det = bounding_boxes[:, 0:4]\r\n+                            bb = np.zeros((faces_found, 4), dtype=(np.int32))\r\n+                            for i in range(faces_found):\r\n+                                bb[i][0] = det[i][0]\r\n+                                bb[i][1] = det[i][1]\r\n+                                bb[i][2] = det[i][2]\r\n+                                bb[i][3] = det[i][3]\r\n+                                print(bb[i][3] - bb[i][1])\r\n+                                print(frame.shape[0])\r\n+                                print((bb[i][3] - bb[i][1]) / frame.shape[0])\r\n+                                if (bb[i][3] - bb[i][1]) / frame.shape[0] > 0.25:\r\n+                                    cropped = frame[bb[i][1]:bb[i]\r\n+                                                    [3], bb[i][0]:bb[i][2], :]\r\n+                                    scaled = cv2.resize(\r\n+                                        cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE), interpolation=(cv2.INTER_CUBIC))\r\n+                                    scaled = facenet.prewhiten(scaled)\r\n+                                    scaled_reshape = scaled.reshape(\r\n+                                        -1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\r\n+                                    feed_dict = {\r\n+                                        images_placeholder: scaled_reshape, phase_train_placeholder: False}\r\n+                                    emb_array = sess.run(\r\n+                                        embeddings, feed_dict=feed_dict)\r\n+                                    predictions = model.predict_proba(\r\n+                                        emb_array)\r\n+                                    best_class_indices = np.argmax(\r\n+                                        predictions, axis=1)\r\n+                                    best_class_probabilities = predictions[(\r\n+                                        np.arange(len(best_class_indices)), best_class_indices)]\r\n+                                    best_name = class_names[best_class_indices[0]]\r\n+                                    print(\'Name: {}, Probability: {}\'.format(\r\n+                                        best_name, best_class_probabilities))\r\n+                                    count_unknown += 1\r\n+                                    if best_class_probabilities > 0.9:\r\n+                                        image_path = \'images/attendance/\' + \\\r\n+                                            subject_compare["name"] + "/"\r\n+                                        if not os.path.exists(image_path):\r\n+                                            os.makedirs(image_path)\r\n+                                        print(\'Name: {}, Probability: {}\'.format(\r\n+                                            best_name, best_class_probabilities))\r\n+                                        cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0,\r\n+                                                                                                          255,\r\n+                                                                                                          0), 2)\r\n+                                        text_x = bb[i][0]\r\n+                                        text_y = bb[i][3] + 20\r\n+                                        cv2.putText(frame, best_name, (text_x, text_y), (cv2.FONT_HERSHEY_COMPLEX_SMALL), 1,\r\n+                                                    (255, 255, 255), thickness=1, lineType=2)\r\n+                                        cv2.putText(frame, (str(round(best_class_probabilities[0], 3))), (text_x, text_y + 17), (cv2.FONT_HERSHEY_COMPLEX_SMALL),\r\n+                                                    1, (255, 255, 255), thickness=1, lineType=2)\r\n+\r\n+                                        file_name = best_name + ".jpg"\r\n+                                        result = db.collection(\r\n+                                            \'current_subject\').document(\'current\').get()\r\n+                                        result = result.to_dict()\r\n \r\n-                    # Displaying photoimage in the label\r\n-                    detect_widget.photo_image = photo_image\r\n+                                        cv2.imwrite(os.path.join(\r\n+                                            image_path, file_name), frame)\r\n+                                        cv2.destroyAllWindows()\r\n+                                        user = db.collection(\r\n+                                            \'users\').document(best_name).get()\r\n+                                        user = user.to_dict()\r\n+                                        today = datetime.datetime.now()\r\n+                                        print(user)\r\n+                                        status = \'in_time\'\r\n+                                        global mode\r\n+                                        if mode == 1:\r\n+                                            checkInExist = db.collection(\r\n+                                                \'check_in\')\r\n+                                            checkInExist = checkInExist.where(\r\n+                                                filter=FieldFilter(\'subject\', \'==\', result[\'name\']))\r\n+                                            checkInExist = checkInExist.where(\r\n+                                                filter=FieldFilter(\'student_id\', \'==\', best_name))\r\n+                                            checkInExist = checkInExist.get()\r\n+                                            # print(checkInExist.to_dict())\r\n+                                            if len(checkInExist) != 0:\r\n+                                                messagebox.showwarning(\r\n+                                                    \'ALERT\', "You had checked in this subject")\r\n+                                                stop_detect()\r\n+                                                return\r\n+                                            time_compare = result[\'time_in\'] + \\\r\n+                                                timedelta(hours=7)\r\n+                                            print(time_compare)\r\n \r\n-                    # Configure image in the label\r\n-                    detect_widget.configure(image=photo_image)\r\n+                                            if utc.localize(today) > time_compare:\r\n+                                                status = \'vao_tre\'\r\n+                                                print(\'vao tre\')\r\n+                                            else:\r\n+                                                status = \'vao_dung_gio\'\r\n+                                                print(\'vao dung gio\')\r\n \r\n-                detect_widget.after(10, detect_frame)\r\n+                                            db.collection(\'check_in\').add(\r\n+                                                {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': user[\'name\'], \'status\': status, \'type\': \'face_detect\', \'time_in\': today - timedelta(hours=7)})\r\n+                                            print(\'complete detect\')\r\n+                                        else:\r\n+                                            checkExist = db.collection(\'check_in\').where(\r\n+                                                "student_id", "==", best_name).get()\r\n+                                            if not checkExist:\r\n+                                                messagebox.showwarning(\r\n+                                                    \'ALERT\', \'You have not check in\')\r\n+                                                return\r\n+                                            time_compare = result[\'time_out\'] + \\\r\n+                                                timedelta(hours=7)\r\n+                                            if utc.localize(today) > time_compare:\r\n+                                                status = \'ra_dung_gio\'\r\n+                                                print(\'ra dung gio\')\r\n+                                            else:\r\n+                                                status = \'ra_som\'\r\n+                                                print(\'ra som\')\r\n+                                            db.collection(\'check_out\').add(\r\n+                                                {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'time_out\': today - timedelta(hours=7)})\r\n+                                            print(\'complete detect\')\r\n+                                        time.sleep(1)\r\n+                                        stop_detect()\r\n+                                        detect_time = 0\r\n+                                        return best_name\r\n+                                    else:\r\n+                                        print(\'Unknown\')\r\n+                                        print(count_unknown)\r\n+                                        if count_unknown == 20:\r\n+                                            count_unknown = 0\r\n+                                            print(\'break\')\r\n+                                            best_name = \'unknown\'\r\n+                                            # VideoStream(src=0).stop()\r\n+                                            # cap.stop()\r\n+                                            cv2.destroyAllWindows()\r\n+                                            stop_detect()\r\n+                                            return best_name\r\n+                                    break\r\n+\r\n+                            # Capture the latest frame and transform to image\r\n+                            captured_image = Image.fromarray(\r\n+                                cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA))\r\n+\r\n+                            # Convert captured image to photoimage\r\n+                            photo_image = ImageTk.PhotoImage(\r\n+                                captured_image.resize((500, 300), Image.ANTIALIAS))\r\n+\r\n+                            # Displaying photoimage in the label\r\n+                            detect_widget.photo_image = photo_image\r\n+\r\n+                            # Configure image in the label\r\n+                            detect_widget.configure(image=photo_image)\r\n+\r\n+                        detect_widget.after(10, detect_frame)\r\n+                        break\r\n \r\n         def start_check_in():\r\n             global cam_detect_on, cap_detect, mode\r\ndiff --git a/create_classifier.py b/create_classifier.py\nindex 9a16c5e..9389fff 100644\n--- a/create_classifier.py\n+++ b/create_classifier.py\n@@ -6,9 +6,16 @@ from Helper.align_dataset_mtcnn import main\n from Helper.classifier import mainTrain\r\n \r\n \r\n-def regFaces():\r\n-    input_dir = \'data/student/raw\'\r\n-    output_dir = \'data/student/processed\'\r\n+def regFaces(subject):\r\n+    input_dir = \'data/student/raw/\' + subject\r\n+    output_dir = \'data/student/processed/\' + subject\r\n+    isExist = os.path.exists(output_dir)\r\n+\r\n+    if not isExist:\r\n+        print(\'The new directory is created!\')\r\n+        print(output_dir)\r\n+        os.makedirs(output_dir)\r\n+\r\n     image_size = 160\r\n     margin = 32\r\n     random_order = \'random_order\'\r\n@@ -26,30 +33,34 @@ def regFaces():\n     data = main(args)\r\n \r\n     if data == \'ok\':\r\n-        startTraining(data)\r\n+        startTraining(data, subject)\r\n \r\n     # data = \'complete reg faces\'\r\n     return\r\n # Method to train custom classifier to recognize face\r\n \r\n \r\n-def startTraining(data):\r\n-    os.remove(\'model/facemodel.pkl\')\r\n+def startTraining(data, subject):\r\n+    # os.remove(\'model/\' + subject + \'/\' + \'facemodel.pkl\')\r\n     # message = request.form[\'status\']\r\n     if data == \'ok\':\r\n-        data_dir = \'data/student/processed\'\r\n+        data_dir = \'data/student/processed/\' + subject\r\n+        checkExist = \'model/\' + subject\r\n+        isExist = os.path.exists(checkExist)\r\n+        if not isExist:\r\n+            os.mkdir(checkExist)\r\n         # test_data = \'backend/data/test/align\'\r\n         args = {\r\n             \'mode\': \'TRAIN\',\r\n             \'data_dir\': data_dir,\r\n             \'model\': \'model/20180402-114759.pb\',\r\n-            \'classifier_filename\': \'model/facemodel.pkl\',\r\n+            \'classifier_filename\': \'model/\' + subject + \'/\' + \'facemodel.pkl\',\r\n             \'use_split_dataset\': \'store_true\',\r\n             \'batch_size\': 1000,\r\n             \'image_size\': 160,\r\n             \'seed\': 666,\r\n-            \'min_nrof_images_per_class\': 20,\r\n-            \'nrof_train_images_per_class\': 15}\r\n+            \'min_nrof_images_per_class\': 50,\r\n+            \'nrof_train_images_per_class\': 35}\r\n         mainTrain(args)\r\n         data = \'complete trained\'\r\n         return\r\ndiff --git a/data/.DS_Store b/data/.DS_Store\nindex 9cdca35..76c6b04 100644\nBinary files a/data/.DS_Store and b/data/.DS_Store differ\ndiff --git a/data/bounding_boxes_1.png b/data/bounding_boxes_1.png\nindex dbf8d69..0b6c5cb 100644\nBinary files a/data/bounding_boxes_1.png and b/data/bounding_boxes_1.png differ\ndiff --git a/data/student/processed/1911368/0.png b/data/student/processed/1911368/0.png\ndeleted file mode 100644\nindex 27fe0e3..0000000\nBinary files a/data/student/processed/1911368/0.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/1.png b/data/student/processed/1911368/1.png\ndeleted file mode 100644\nindex 5f6d1ba..0000000\nBinary files a/data/student/processed/1911368/1.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/10.png b/data/student/processed/1911368/10.png\ndeleted file mode 100644\nindex 3e24c60..0000000\nBinary files a/data/student/processed/1911368/10.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/11.png b/data/student/processed/1911368/11.png\ndeleted file mode 100644\nindex e064ee0..0000000\nBinary files a/data/student/processed/1911368/11.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/12.png b/data/student/processed/1911368/12.png\ndeleted file mode 100644\nindex 7b58f0f..0000000\nBinary files a/data/student/processed/1911368/12.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/13.png b/data/student/processed/1911368/13.png\ndeleted file mode 100644\nindex d845f48..0000000\nBinary files a/data/student/processed/1911368/13.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/14.png b/data/student/processed/1911368/14.png\ndeleted file mode 100644\nindex 1d49fbe..0000000\nBinary files a/data/student/processed/1911368/14.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/15.png b/data/student/processed/1911368/15.png\ndeleted file mode 100644\nindex fa31d60..0000000\nBinary files a/data/student/processed/1911368/15.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/16.png b/data/student/processed/1911368/16.png\ndeleted file mode 100644\nindex 7221f50..0000000\nBinary files a/data/student/processed/1911368/16.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/17.png b/data/student/processed/1911368/17.png\ndeleted file mode 100644\nindex b171159..0000000\nBinary files a/data/student/processed/1911368/17.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/18.png b/data/student/processed/1911368/18.png\ndeleted file mode 100644\nindex 0f657a8..0000000\nBinary files a/data/student/processed/1911368/18.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/19.png b/data/student/processed/1911368/19.png\ndeleted file mode 100644\nindex 792217f..0000000\nBinary files a/data/student/processed/1911368/19.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/2.png b/data/student/processed/1911368/2.png\ndeleted file mode 100644\nindex 6243529..0000000\nBinary files a/data/student/processed/1911368/2.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/20.png b/data/student/processed/1911368/20.png\ndeleted file mode 100644\nindex 697ec2e..0000000\nBinary files a/data/student/processed/1911368/20.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/3.png b/data/student/processed/1911368/3.png\ndeleted file mode 100644\nindex e3028bd..0000000\nBinary files a/data/student/processed/1911368/3.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/4.png b/data/student/processed/1911368/4.png\ndeleted file mode 100644\nindex c5d674b..0000000\nBinary files a/data/student/processed/1911368/4.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/5.png b/data/student/processed/1911368/5.png\ndeleted file mode 100644\nindex 96ecdb9..0000000\nBinary files a/data/student/processed/1911368/5.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/6.png b/data/student/processed/1911368/6.png\ndeleted file mode 100644\nindex fd56bb9..0000000\nBinary files a/data/student/processed/1911368/6.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/7.png b/data/student/processed/1911368/7.png\ndeleted file mode 100644\nindex 3839679..0000000\nBinary files a/data/student/processed/1911368/7.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/8.png b/data/student/processed/1911368/8.png\ndeleted file mode 100644\nindex dde9c4c..0000000\nBinary files a/data/student/processed/1911368/8.png and /dev/null differ\ndiff --git a/data/student/processed/1911368/9.png b/data/student/processed/1911368/9.png\ndeleted file mode 100644\nindex d6aaa28..0000000\nBinary files a/data/student/processed/1911368/9.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/1.png b/data/student/processed/1915577/1.png\ndeleted file mode 100644\nindex 64f509d..0000000\nBinary files a/data/student/processed/1915577/1.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/10.png b/data/student/processed/1915577/10.png\ndeleted file mode 100644\nindex 53ec53d..0000000\nBinary files a/data/student/processed/1915577/10.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/11.png b/data/student/processed/1915577/11.png\ndeleted file mode 100644\nindex 89b62d4..0000000\nBinary files a/data/student/processed/1915577/11.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/12.png b/data/student/processed/1915577/12.png\ndeleted file mode 100644\nindex 51bb05e..0000000\nBinary files a/data/student/processed/1915577/12.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/13.png b/data/student/processed/1915577/13.png\ndeleted file mode 100644\nindex 125b9fc..0000000\nBinary files a/data/student/processed/1915577/13.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/14.png b/data/student/processed/1915577/14.png\ndeleted file mode 100644\nindex f415b74..0000000\nBinary files a/data/student/processed/1915577/14.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/15.png b/data/student/processed/1915577/15.png\ndeleted file mode 100644\nindex 67ff904..0000000\nBinary files a/data/student/processed/1915577/15.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/16.png b/data/student/processed/1915577/16.png\ndeleted file mode 100644\nindex 22f0470..0000000\nBinary files a/data/student/processed/1915577/16.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/17.png b/data/student/processed/1915577/17.png\ndeleted file mode 100644\nindex f56b74e..0000000\nBinary files a/data/student/processed/1915577/17.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/18.png b/data/student/processed/1915577/18.png\ndeleted file mode 100644\nindex af37c25..0000000\nBinary files a/data/student/processed/1915577/18.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/19.png b/data/student/processed/1915577/19.png\ndeleted file mode 100644\nindex 81331f8..0000000\nBinary files a/data/student/processed/1915577/19.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/2.png b/data/student/processed/1915577/2.png\ndeleted file mode 100644\nindex d8ae681..0000000\nBinary files a/data/student/processed/1915577/2.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/20.png b/data/student/processed/1915577/20.png\ndeleted file mode 100644\nindex 51a9fb8..0000000\nBinary files a/data/student/processed/1915577/20.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/21.png b/data/student/processed/1915577/21.png\ndeleted file mode 100644\nindex 8bc3c2b..0000000\nBinary files a/data/student/processed/1915577/21.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/3.png b/data/student/processed/1915577/3.png\ndeleted file mode 100644\nindex 4a2b228..0000000\nBinary files a/data/student/processed/1915577/3.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/4.png b/data/student/processed/1915577/4.png\ndeleted file mode 100644\nindex 617b737..0000000\nBinary files a/data/student/processed/1915577/4.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/5.png b/data/student/processed/1915577/5.png\ndeleted file mode 100644\nindex 0e0af5a..0000000\nBinary files a/data/student/processed/1915577/5.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/6.png b/data/student/processed/1915577/6.png\ndeleted file mode 100644\nindex 753482b..0000000\nBinary files a/data/student/processed/1915577/6.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/7.png b/data/student/processed/1915577/7.png\ndeleted file mode 100644\nindex a85f664..0000000\nBinary files a/data/student/processed/1915577/7.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/8.png b/data/student/processed/1915577/8.png\ndeleted file mode 100644\nindex 603896a..0000000\nBinary files a/data/student/processed/1915577/8.png and /dev/null differ\ndiff --git a/data/student/processed/1915577/9.png b/data/student/processed/1915577/9.png\ndeleted file mode 100644\nindex fc46bf4..0000000\nBinary files a/data/student/processed/1915577/9.png and /dev/null differ\ndiff --git a/data/student/processed/bounding_boxes_04502.txt b/data/student/processed/bounding_boxes_04502.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_04606.txt b/data/student/processed/bounding_boxes_04606.txt\ndeleted file mode 100644\nindex 37f1467..0000000\n--- a/data/student/processed/bounding_boxes_04606.txt\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-data/student/processed/1911368/20.png 525 133 873 589\n-data/student/processed/1911368/8.png 507 148 826 566\n-data/student/processed/1911368/14.png 489 140 829 580\n-data/student/processed/1911368/10.png 492 142 829 579\n-data/student/processed/1911368/7.png 522 163 838 569\n-data/student/processed/1911368/15.png 504 134 856 582\n-data/student/processed/1911368/6.png 526 190 836 598\n-data/student/processed/1911368/2.png 540 265 834 602\n-data/student/processed/1911368/17.png 516 140 867 594\n-data/student/processed/1911368/0.png 533 214 837 599\n-data/student/processed/1911368/13.png 501 145 835 589\n-data/student/processed/1911368/9.png 497 134 843 577\n-data/student/processed/1911368/19.png 526 132 875 593\n-data/student/processed/1911368/16.png 505 141 851 584\n-data/student/processed/1911368/18.png 522 141 869 589\n-data/student/processed/1911368/12.png 492 140 829 578\n-data/student/processed/1911368/11.png 489 139 826 579\n-data/student/processed/1911368/1.png 530 247 807 601\n-data/student/processed/1911368/5.png 521 196 827 599\n-data/student/processed/1911368/4.png 544 203 840 590\n-data/student/processed/1911368/3.png 551 198 869 612\ndiff --git a/data/student/processed/bounding_boxes_16166.txt b/data/student/processed/bounding_boxes_16166.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_30334.txt b/data/student/processed/bounding_boxes_30334.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_61014.txt b/data/student/processed/bounding_boxes_61014.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_61052.txt b/data/student/processed/bounding_boxes_61052.txt\ndeleted file mode 100644\nindex 49c5aaa..0000000\n--- a/data/student/processed/bounding_boxes_61052.txt\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-data/student/processed/1911368/5.png 543 197 842 573\n-data/student/processed/1911368/17.png 503 185 832 606\n-data/student/processed/1911368/10.png 505 185 860 656\n-data/student/processed/1911368/18.png 506 174 853 630\n-data/student/processed/1911368/7.png 517 178 867 644\n-data/student/processed/1911368/3.png 549 196 835 566\n-data/student/processed/1911368/9.png 505 185 860 650\n-data/student/processed/1911368/8.png 511 191 862 655\n-data/student/processed/1911368/2.png 545 193 836 565\n-data/student/processed/1911368/13.png 485 140 850 608\n-data/student/processed/1911368/0.png 548 189 842 547\n-data/student/processed/1911368/12.png 491 160 850 604\n-data/student/processed/1911368/19.png 503 174 852 633\n-data/student/processed/1911368/6.png 532 186 857 616\n-data/student/processed/1911368/4.png 541 190 833 563\n-data/student/processed/1911368/1.png 544 194 833 561\n-data/student/processed/1911368/16.png 498 159 848 613\n-data/student/processed/1911368/20.png 496 177 854 640\n-data/student/processed/1911368/14.png 490 148 858 608\n-data/student/processed/1911368/11.png 500 171 854 633\n-data/student/processed/1911368/15.png 496 159 855 603\ndiff --git a/data/student/processed/bounding_boxes_81454.txt b/data/student/processed/bounding_boxes_81454.txt\ndeleted file mode 100644\nindex 56f4a0a..0000000\n--- a/data/student/processed/bounding_boxes_81454.txt\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-data/student/processed/1911368/10.png 505 159 860 629\n-data/student/processed/1911368/1.png 572 220 855 612\n-data/student/processed/1911368/18.png 511 166 861 615\n-data/student/processed/1911368/16.png 505 141 854 598\n-data/student/processed/1911368/8.png 510 178 867 646\n-data/student/processed/1911368/6.png 535 202 862 617\n-data/student/processed/1911368/4.png 540 200 835 587\n-data/student/processed/1911368/3.png 518 212 819 593\n-data/student/processed/1911368/7.png 523 183 877 637\n-data/student/processed/1911368/2.png 525 227 825 590\n-data/student/processed/1911368/20.png 512 160 863 610\n-data/student/processed/1911368/13.png 487 127 864 595\n-data/student/processed/1911368/5.png 532 184 856 606\n-data/student/processed/1911368/15.png 497 124 865 592\n-data/student/processed/1911368/11.png 500 145 855 623\n-data/student/processed/1911368/12.png 491 135 859 597\n-data/student/processed/1911368/17.png 505 143 855 608\n-data/student/processed/1911368/9.png 514 184 855 647\n-data/student/processed/1911368/19.png 511 167 861 613\n-data/student/processed/1911368/0.png 578 243 848 588\n-data/student/processed/1911368/14.png 493 127 860 589\ndiff --git a/data/student/processed/bounding_boxes_90001.txt b/data/student/processed/bounding_boxes_90001.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_93249.txt b/data/student/processed/bounding_boxes_93249.txt\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/data/student/processed/bounding_boxes_98648.txt b/data/student/processed/bounding_boxes_98648.txt\ndeleted file mode 100644\nindex 258cd42..0000000\n--- a/data/student/processed/bounding_boxes_98648.txt\n+++ /dev/null\n@@ -1,41 +0,0 @@\n-data/student/processed/1915577/11.png 531 169 811 524\n-data/student/processed/1915577/7.png 533 170 811 532\n-data/student/processed/1915577/3.png 534 165 816 529\n-data/student/processed/1915577/18.png 536 165 815 527\n-data/student/processed/1915577/9.png 536 166 815 525\n-data/student/processed/1915577/5.png 532 166 813 527\n-data/student/processed/1915577/21.png 534 172 812 526\n-data/student/processed/1915577/20.png 533 166 814 527\n-data/student/processed/1915577/10.png 535 167 814 526\n-data/student/processed/1915577/19.png 536 167 816 526\n-data/student/processed/1915577/6.png 532 166 813 528\n-data/student/processed/1915577/4.png 532 167 814 527\n-data/student/processed/1915577/1.png 536 164 819 531\n-data/student/processed/1915577/17.png 537 168 815 526\n-data/student/processed/1915577/14.png 536 165 815 528\n-data/student/processed/1915577/16.png 536 166 816 527\n-data/student/processed/1915577/2.png 536 164 818 528\n-data/student/processed/1915577/13.png 533 166 814 525\n-data/student/processed/1915577/8.png 533 168 814 527\n-data/student/processed/1915577/12.png 535 165 815 528\n-data/student/processed/1915577/15.png 537 167 817 527\n-data/student/processed/1911368/10.png 557 219 862 615\n-data/student/processed/1911368/17.png 567 198 866 600\n-data/student/processed/1911368/0.png 536 204 861 618\n-data/student/processed/1911368/9.png 553 223 859 611\n-data/student/processed/1911368/19.png 566 205 870 603\n-data/student/processed/1911368/18.png 579 205 868 598\n-data/student/processed/1911368/11.png 558 216 860 617\n-data/student/processed/1911368/5.png 546 209 868 629\n-data/student/processed/1911368/1.png 538 218 861 636\n-data/student/processed/1911368/15.png 571 211 869 607\n-data/student/processed/1911368/6.png 542 180 876 624\n-data/student/processed/1911368/4.png 545 213 871 633\n-data/student/processed/1911368/7.png 541 184 874 621\n-data/student/processed/1911368/14.png 554 225 866 613\n-data/student/processed/1911368/8.png 547 212 860 617\n-data/student/processed/1911368/3.png 533 213 857 624\n-data/student/processed/1911368/16.png 567 195 868 600\n-data/student/processed/1911368/2.png 539 215 866 636\n-data/student/processed/1911368/12.png 538 197 865 617\n-data/student/processed/1911368/13.png 556 218 865 622\ndiff --git a/data/student/processed/revision_info.txt b/data/student/processed/revision_info.txt\ndeleted file mode 100644\nindex 2cd026a..0000000\n--- a/data/student/processed/revision_info.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-arguments: app-gui.py\n---------------------\n-tensorflow version: 2.11.0\n---------------------\n-git hash: b\'327e78b08956ac731a903cc76880b0ad4074195d\'\n---------------------\n-b\'diff --git a/.DS_Store b/.DS_Store\\nindex 8d5060d..fe6e40b 100644\\nBinary files a/.DS_Store and b/.DS_Store differ\\ndiff --git a/app-gui.py b/app-gui.py\\nindex 107ede6..aeea48f 100644\\n--- a/app-gui.py\\n+++ b/app-gui.py\\n@@ -1,3 +1,6 @@\\n+import pickle\\r\\n+import facenet.src.facenet as facenet\\r\\n+import argparse\\r\\n from Detector import main_app\\r\\n from create_classifier import train_classifer, regFaces\\r\\n from create_dataset import start_capture\\r\\n@@ -9,6 +12,9 @@ import cv2\\n import os\\r\\n import imutils\\r\\n from Helper.align import detect_face\\r\\n+import datetime\\r\\n+import pytz\\r\\n+from datetime import timedelta\\r\\n \\r\\n import tensorflow as tf\\r\\n from imutils.video import VideoStream\\r\\n@@ -16,14 +22,17 @@ import numpy as np\\n import random\\r\\n import time\\r\\n import serial\\r\\n+import firebase_admin\\r\\n+from firebase_admin import credentials, firestore\\r\\n \\r\\n-import argparse\\r\\n-import facenet.src.facenet as facenet\\r\\n-import pickle\\r\\n \\r\\n-# from PIL import ImageTk, Image\\r\\n-# from gender_prediction import emotion,ageAndgender\\r\\n+cred = credentials.Certificate(\\r\\n+    "key/attendace-sys-firebase-adminsdk-e2nde-ea40d5feeb.json")\\r\\n+firebase_admin.initialize_app(cred)\\r\\n+\\r\\n names = set()\\r\\n+db = firestore.client()\\r\\n+utc = pytz.UTC\\r\\n \\r\\n \\r\\n class MainUI(tk.Tk):\\r\\n@@ -182,11 +191,48 @@ class PageTwo(tk.Frame):\\n         tk.Frame.__init__(self, parent)\\r\\n         self.controller = controller\\r\\n \\r\\n+        # def deleteDB(msg):\\r\\n+        #     print(\\\'Running. Press CTRL-C to exit.\\\')\\r\\n+        #     with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\r\\n+        #         time.sleep(0.1)  # wait for serial to open\\r\\n+        #         if arduino.isOpen():\\r\\n+        #             print("{} connected!".format(arduino.port))\\r\\n+        #             try:\\r\\n+        #                 while True:\\r\\n+        #                     time.sleep(0.5)  # wait for arduino to answer\\r\\n+        #                     answer = arduino.readline()\\r\\n+        #                     print(answer)\\r\\n+        #                     if answer == b\\\'sensor templates\\\':\\r\\n+        #                         arduino.write(str(msg).encode())\\r\\n+        #                     if answer == b\\\'success\\\':\\r\\n+        #                         # print(\\\'break\\\')\\r\\n+        #                         arduino.flushInput()\\r\\n+        #                         break\\r\\n+        #                     # arduino.flushInput()\\r\\n+        #             except KeyboardInterrupt:\\r\\n+        #                 print("KeyboardInterrupt has been caught.")\\r\\n+\\r\\n         color1 = \\\'#020f12\\\'\\r\\n         color2 = \\\'#05d7ff\\\'\\r\\n         color3 = \\\'#65e7ff\\\'\\r\\n         color4 = \\\'BLACK\\\'\\r\\n         color5 = \\\'YELLOW\\\'\\r\\n+        # self.buttoncanc = tk.Button(self,\\r\\n+        #                             background=color2,\\r\\n+        #                             foreground=color4,\\r\\n+        #                             activebackground=color3,\\r\\n+        #                             activeforeground=color4,\\r\\n+        #                             highlightthickness=2,\\r\\n+        #                             highlightbackground=color2,\\r\\n+        #                             width=15,\\r\\n+        #                             height=2,\\r\\n+        #                             border=0,\\r\\n+        #                             cursor=\\\'hand2\\\',\\r\\n+        #                             text="Empty Database",\\r\\n+        #                             font=(\\\'Arial\\\', 16, \\\'bold\\\'),\\r\\n+        #                             command=deleteDB(3))\\r\\n+        # self.buttoncanc.place(relx=0.5, rely=0.7, anchor=\\\'center\\\')\\r\\n+\\r\\n         self.buttoncanc = tk.Button(self,\\r\\n                                     background=color2,\\r\\n                                     foreground=color4,\\r\\n@@ -267,9 +313,9 @@ class PageThree(tk.Frame):\\n                     except KeyboardInterrupt:\\r\\n                         print("KeyboardInterrupt has been caught.")\\r\\n \\r\\n-        def arduino_enroll(msg):\\r\\n+        def arduino_enroll(msg, new_finger_id):\\r\\n             print(msg)\\r\\n-            print(fingerprint_id_entry.get())\\r\\n+            print(new_finger_id)\\r\\n             print(\\\'Running. Press CTRL-C to exit.\\\')\\r\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\r\\n                 time.sleep(0.1)  # wait for serial to open\\r\\n@@ -280,21 +326,25 @@ class PageThree(tk.Frame):\\n                             time.sleep(0.5)  # wait for arduino to answer\\r\\n                             answer = arduino.readline()\\r\\n                             print(answer)\\r\\n-                            if answer == b\\\'Sensor contains 11 templates\\\\r\\\\n\\\':\\r\\n+                            if b"Sensor contains" in answer or b"doesn\\\'t" in answer:\\r\\n                                 arduino.write(str(msg).encode())\\r\\n                             if answer == b\\\'#id\\\\r\\\\n\\\':\\r\\n                                 # print(\\\'break\\\')\\r\\n                                 arduino.flushInput()\\r\\n                                 # cmd = str(input("Enter command : "))\\r\\n-                                cmd = str(fingerprint_id_entry.get())\\r\\n+                                cmd = str(new_finger_id)\\r\\n                                 arduino.write(str(cmd).encode())\\r\\n                                 while True:\\r\\n                                     answer = arduino.readline()\\r\\n                                     print(answer)\\r\\n                                     if answer == b\\\'Place same finger again\\\\r\\\\n\\\':\\r\\n-                                        self.notify.config(\\r\\n-                                            text=\\\'Take your finger out and Put it back\\\')\\r\\n+                                        messagebox.showinfo(\\r\\n+                                            \\\'NOTIFY\\\', \\\'Take out and Place same finger again!\\\')\\r\\n                                     if answer == b\\\'Stored!\\\\r\\\\n\\\':\\r\\n+                                        db.collection(\\\'users\\\').document(\\r\\n+                                            student_code_entry.get()).set({\\\'finger_id\\\': str(new_finger_id)}, merge=True)\\r\\n+                                        db.collection(\\r\\n+                                            \\\'fingers\\\').document(\\\'id\\\').update({\\\'id\\\': new_finger_id + 1})\\r\\n                                         self.notify.config(\\r\\n                                             text=\\\'Successfully encode fingerprint\\\')\\r\\n                                         break\\r\\n@@ -306,11 +356,19 @@ class PageThree(tk.Frame):\\n \\r\\n         def start_enroll():\\r\\n             stop_enroll()\\r\\n-            self.notify.config(text=\\\'Loading.......\\\')\\r\\n-            self.notify.place(relx=0.5, rely=0.4, anchor=\\\'center\\\')\\r\\n             global message\\r\\n             message == True\\r\\n-            arduino_enroll(2)\\r\\n+            result = db.collection(\\\'users\\\').document(\\r\\n+                student_code_entry.get()).get()\\r\\n+            if result.exists:\\r\\n+                new_finger_id = db.collection(\\\'fingers\\\').document(\\\'id\\\').get()\\r\\n+                new_finger_id = new_finger_id.to_dict()\\r\\n+                new_finger_id = new_finger_id[\\\'id\\\']\\r\\n+                arduino_enroll(2, new_finger_id)\\r\\n+            else:\\r\\n+                print(\\\'no match\\\')\\r\\n+                messagebox.showwarning(\\\'ALERT\\\', \\\'No Users Match\\\')\\r\\n+                return\\r\\n \\r\\n         def stop_enroll():\\r\\n             global message\\r\\n@@ -320,31 +378,24 @@ class PageThree(tk.Frame):\\n             self, text="Enter your student code to register new fingerprint")\\r\\n         label1.place(relx=0.5, rely=0.1, anchor=\\\'center\\\')\\r\\n \\r\\n-        fingerprint_id_entry = tk.Entry(self)\\r\\n-        fingerprint_id_entry.place(relx=0.5, rely=0.2, anchor=\\\'center\\\')\\r\\n+        student_code_entry = tk.Entry(self)\\r\\n+        student_code_entry.place(relx=0.5, rely=0.2, anchor=\\\'center\\\')\\r\\n+\\r\\n+        label2 = tk.Label(\\r\\n+            self, text="Enter your fingerId")\\r\\n+        label2.place(relx=0.5, rely=0.3, anchor=\\\'center\\\')\\r\\n \\r\\n         buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\r\\n                                 fg="#263942", command=start_enroll)\\r\\n-        buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\'center\\\')\\r\\n+        buttoncanc2.place(relx=0.5, rely=0.5, anchor=\\\'center\\\')\\r\\n \\r\\n         self.notify = tk.Label(\\r\\n             self, text="abc")\\r\\n-        self.notify.place(relx=0.5, rely=0.4, anchor=\\\'center\\\')\\r\\n+        self.notify.place(relx=0.5, rely=0.6, anchor=\\\'center\\\')\\r\\n \\r\\n         buttoncanc1 = tk.Button(self, text="Cancel", bg="#ffffff",\\r\\n                                 fg="#263942", command=lambda: controller.show_frame("StartPage"))\\r\\n-        buttoncanc1.place(relx=0.5, rely=0.5, anchor=\\\'center\\\')\\r\\n-\\r\\n-        # def initFingerprint():\\r\\n-        #     if message == True:\\r\\n-\\r\\n-        #         mode = int(input("Select mode detect"))\\r\\n-\\r\\n-        #         if mode == 1:\\r\\n-        #             arduino_detect(1)\\r\\n-\\r\\n-        #         if mode == 2:\\r\\n-        #             arduino_enroll(2)\\r\\n+        buttoncanc1.place(relx=0.5, rely=0.7, anchor=\\\'center\\\')\\r\\n \\r\\n \\r\\n class PageDetectFingert(tk.Frame):\\r\\n@@ -359,7 +410,7 @@ class PageDetectFingert(tk.Frame):\\n         status = \\\'loading\\\'\\r\\n         self.controller = controller\\r\\n \\r\\n-        def arduino_detect(msg):\\r\\n+        def arduino_detect(msg, mode):\\r\\n             print(msg)\\r\\n             print(\\\'Running. Press CTRL-C to exit.\\\')\\r\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\r\\n@@ -371,37 +422,78 @@ class PageDetectFingert(tk.Frame):\\n                             time.sleep(0.5)  # wait for arduino to answer\\r\\n                             answer = arduino.readline()\\r\\n                             print(answer)\\r\\n-                            if answer == b\\\'Sensor contains 12 templates\\\\r\\\\n\\\':\\r\\n+                            if b"doesn\\\'t" in answer:\\r\\n+                                messagebox.showinfo(\\r\\n+                                    "ALERT", "No fingerprint to detect")\\r\\n+                                break\\r\\n+                            if answer == b\\\'Sensor contains 14 templates\\\\r\\\\n\\\':\\r\\n                                 arduino.write(str(msg).encode())\\r\\n                                 while True:\\r\\n                                     answer = arduino.readline()\\r\\n                                     print(answer)\\r\\n-                                    if answer == b\\\'ok\\\':\\r\\n+                                    idText = b\\\'\\\'\\r\\n+                                    if b\\\'ID\\\' in answer:\\r\\n+                                        idText = answer\\r\\n+                                    if b\\\'ok\\\' in answer or b\\\'Unknown\\\' in answer:\\r\\n                                         self.notify1.config(\\r\\n                                             text=\\\'Successfully detect fingerprint\\\')\\r\\n-\\r\\n-                                        self.notify1.config(text="")\\r\\n+                                        finger_id = idText.decode(\\r\\n+                                            \\\'utf-8\\\').split("#")[1]\\r\\n+                                        print(finger_id)\\r\\n+                                        if finger_id != \\\'\\\':\\r\\n+                                            query = db.collection(\\\'users\\\').where(\\r\\n+                                                "finger_id", "==", finger_id).get()\\r\\n+                                            for doc in query:\\r\\n+                                                user = doc.to_dict()\\r\\n+                                                result = db.collection(\\r\\n+                                                    \\\'current_subject\\\').document(\\\'current\\\').get()\\r\\n+                                                result = result.to_dict()\\r\\n+                                                today = datetime.datetime.now()\\r\\n+                                                status = \\\'in_time\\\'\\r\\n+                                                if mode == 1:\\r\\n+                                                    time_compare = result[\\\'time_in\\\'] + \\\\\\r\\n+                                                        timedelta(hours=7)\\r\\n+                                                    if utc.localize(today) > time_compare:\\r\\n+                                                        status = \\\'vao_tre\\\'\\r\\n+                                                        print(\\\'vao_tre\\\')\\r\\n+                                                    else:\\r\\n+                                                        status = \\\'vao_dung_gio\\\'\\r\\n+                                                        print(\\\'vao dung gio\\\')\\r\\n+                                                    db.collection(\\\'check_in\\\').add(\\r\\n+                                                        {\\\'subject\\\': result[\\\'name\\\'], \\\'student_id\\\': user[\\\'student_id\\\'], \\\'student_name\\\': user[\\\'name\\\'], \\\'status\\\': status, \\\'type\\\': \\\'fingerprint_detect\\\', \\\'time_in\\\': today - timedelta(hours=7)})\\r\\n+                                                else:\\r\\n+                                                    time_compare = result[\\\'time_out\\\'] + \\\\\\r\\n+                                                        timedelta(hours=7)\\r\\n+                                                    if utc.localize(today) > time_compare:\\r\\n+                                                        status = \\\'ra_dung_gio\\\'\\r\\n+                                                        print(\\\'ra dung gio\\\')\\r\\n+                                                    else:\\r\\n+                                                        status = \\\'ra_som\\\'\\r\\n+                                                        print(\\\'ra som\\\')\\r\\n+\\r\\n+                                                    db.collection(\\\'check_out\\\').add(\\r\\n+                                                        {\\\'subject\\\': result[\\\'name\\\'], \\\'student_id\\\': user[\\\'student_id\\\'], \\\'student_name\\\': user[\\\'name\\\'], \\\'status\\\': status, \\\'type\\\': \\\'fingerprint_detect\\\', \\\'time_out\\\': today - timedelta(hours=7)})\\r\\n                                         break\\r\\n                                     # return answer\\r\\n                                 break\\r\\n                     except KeyboardInterrupt:\\r\\n                         print("KeyboardInterrupt has been caught.")\\r\\n \\r\\n-        def start_detect():\\r\\n+        def start_check_in():\\r\\n             stop_detect()\\r\\n             global status\\r\\n             status = \\\'Init Parameters\\\'\\r\\n             print(status)\\r\\n             global message\\r\\n             message == True\\r\\n-            arduino_detect(1)\\r\\n+            arduino_detect(1, 1)\\r\\n \\r\\n         def stop_detect():\\r\\n             global message\\r\\n             message == False\\r\\n \\r\\n-        buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\r\\n-                                fg="#263942", command=start_detect)\\r\\n+        buttoncanc2 = tk.Button(self, text="Finger Check In", bg="#ffffff",\\r\\n+                                fg="#263942", command=start_check_in)\\r\\n         buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\'center\\\')\\r\\n \\r\\n         self.notify1 = tk.Label(\\r\\n@@ -441,7 +533,9 @@ class PageTakeFace(tk.Frame):\\n             detector = cv2.CascadeClassifier(\\r\\n                 "./data/haarcascade_frontalface_default.xml")\\r\\n \\r\\n-            filepath = \\\'./data/student/raw/\\\' + stundent_id_entry.get()\\r\\n+            id = stundent_id_entry.get()\\r\\n+\\r\\n+            filepath = \\\'./data/student/raw/\\\' + id\\r\\n \\r\\n             isExist = os.path.exists(filepath)\\r\\n \\r\\n@@ -490,6 +584,8 @@ class PageTakeFace(tk.Frame):\\n                     if num_of_images == 21:\\r\\n                         stop_vid()\\r\\n                         num_of_images = 0\\r\\n+                        db.collection(\\\'users\\\').document(id).set(\\r\\n+                            {\\\'name\\\': first_name_entry.get(), \\\'student_id\\\': id, \\\'image_path\\\': filepath})\\r\\n                         messagebox.showinfo(\\r\\n                             "INSTRUCTIONS", "We captured 20 pic of your Face.")\\r\\n                         return \\\'ok\\\'\\r\\n@@ -607,9 +703,11 @@ class PageDetectFace(tk.Frame):\\n         global cap_detect\\r\\n         cap_detect = None\\r\\n         global count_unknown\\r\\n-        global detect_time\\r\\n         count_unknown = 0\\r\\n+        global detect_time\\r\\n         detect_time = 0\\r\\n+        global mode\\r\\n+        mode = 1\\r\\n         # student_id = \\\'_\\\'.join([\\\'student\\\', stundent_id_entry])\\r\\n \\r\\n         def detect_frame():\\r\\n@@ -624,7 +722,7 @@ class PageDetectFace(tk.Frame):\\n                     # frame = cap.read()\\r\\n                     frame = imutils.resize(frame, width=600)\\r\\n                     frame = cv2.flip(frame, 1)\\r\\n-                    rand_name = random.randint(0, 1000)\\r\\n+                    # rand_name = random.randint(0, 1000)\\r\\n                     bounding_boxes, _ = detect_face.detect_face(\\r\\n                         frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\r\\n                     faces_found = bounding_boxes.shape[0]\\r\\n@@ -676,11 +774,42 @@ class PageDetectFace(tk.Frame):\\n                                             1, (255, 255, 255), thickness=1, lineType=2)\\r\\n \\r\\n                                 file_name = best_name + ".jpg"\\r\\n-                                if detect_time == 3:\\r\\n+                                if detect_time == 2:\\r\\n                                     cv2.imwrite(os.path.join(\\r\\n                                         image_path, file_name), frame)\\r\\n                                     cv2.destroyAllWindows()\\r\\n-                                    print(\\\'complete detect\\\')\\r\\n+                                    result = db.collection(\\r\\n+                                        \\\'current_subject\\\').document(\\\'current\\\').get()\\r\\n+                                    result = result.to_dict()\\r\\n+                                    today = datetime.datetime.now()\\r\\n+                                    print(today)\\r\\n+                                    status = \\\'in_time\\\'\\r\\n+                                    global mode\\r\\n+                                    if mode == 1:\\r\\n+                                        time_compare = result[\\\'time_in\\\'] + \\\\\\r\\n+                                            timedelta(hours=7)\\r\\n+                                        print(time_compare)\\r\\n+                                        if utc.localize(today) > time_compare:\\r\\n+                                            status = \\\'vao_tre\\\'\\r\\n+                                            print(\\\'vao tre\\\')\\r\\n+                                        else:\\r\\n+                                            status = \\\'vao_dung_gio\\\'\\r\\n+                                            print(\\\'vao dung gio\\\')\\r\\n+                                        db.collection(\\\'check_in\\\').add(\\r\\n+                                            {\\\'subject\\\': result[\\\'name\\\'], \\\'student_id\\\': best_name, \\\'student_name\\\': \\\'name\\\', \\\'status\\\': status, \\\'type\\\': \\\'face_detect\\\', \\\'time_in\\\': today - timedelta(hours=7)})\\r\\n+                                        print(\\\'complete detect\\\')\\r\\n+                                    else:\\r\\n+                                        time_compare = result[\\\'time_out\\\'] + \\\\\\r\\n+                                            timedelta(hours=7)\\r\\n+                                        if utc.localize(today) > time_compare:\\r\\n+                                            status = \\\'ra_dung_gio\\\'\\r\\n+                                            print(\\\'ra dung gio\\\')\\r\\n+                                        else:\\r\\n+                                            status = \\\'ra_som\\\'\\r\\n+                                            print(\\\'ra som\\\')\\r\\n+                                        db.collection(\\\'check_out\\\').add(\\r\\n+                                            {\\\'subject\\\': result[\\\'name\\\'], \\\'student_id\\\': best_name, \\\'student_name\\\': \\\'name\\\', \\\'status\\\': status, \\\'type\\\': \\\'face_detect\\\', \\\'time_out\\\': today - timedelta(hours=7)})\\r\\n+                                        print(\\\'complete detect\\\')\\r\\n                                     time.sleep(1)\\r\\n                                     stop_detect()\\r\\n                                     detect_time = 0\\r\\n@@ -688,7 +817,6 @@ class PageDetectFace(tk.Frame):\\n \\r\\n                                 detect_time += 1\\r\\n                             else:\\r\\n-                                name = \\\'Unknown\\\'\\r\\n                                 print(\\\'Unknown\\\')\\r\\n                                 print(count_unknown)\\r\\n                                 if count_unknown == 20:\\r\\n@@ -716,11 +844,20 @@ class PageDetectFace(tk.Frame):\\n \\r\\n                 detect_widget.after(10, detect_frame)\\r\\n \\r\\n-        def start_detect():\\r\\n-            global cam_detect_on, cap_detect\\r\\n+        def start_check_in():\\r\\n+            global cam_detect_on, cap_detect, mode\\r\\n             stop_detect()\\r\\n             cam_detect_on = True\\r\\n             cap_detect = cv2.VideoCapture(1)\\r\\n+            mode = 1\\r\\n+            detect_frame()\\r\\n+\\r\\n+        def start_check_out():\\r\\n+            global cam_detect_on, cap_detect, mode\\r\\n+            stop_detect()\\r\\n+            cam_detect_on = True\\r\\n+            cap_detect = cv2.VideoCapture(1)\\r\\n+            mode = 2\\r\\n             detect_frame()\\r\\n \\r\\n         def stop_detect():\\r\\n@@ -743,10 +880,14 @@ class PageDetectFace(tk.Frame):\\n                                 fg="#263942", command=stop_detect)\\r\\n         buttoncanc3.place(relx=0.5, rely=0.3, anchor=\\\'center\\\')\\r\\n \\r\\n-        buttoncanc2 = tk.Button(self, text="Detect", bg="#ffffff",\\r\\n-                                fg="#263942", command=start_detect)\\r\\n+        buttoncanc2 = tk.Button(self, text="Face Check In", bg="#ffffff",\\r\\n+                                fg="#263942", command=start_check_in)\\r\\n         buttoncanc2.place(relx=0.5, rely=0.1, anchor=\\\'center\\\')\\r\\n \\r\\n+        buttoncanc2 = tk.Button(self, text="Face Check Out", bg="#ffffff",\\r\\n+                                fg="#263942", command=start_check_out)\\r\\n+        buttoncanc2.place(relx=0.5, rely=0.2, anchor=\\\'center\\\')\\r\\n+\\r\\n         detect_widget = tk.Label(self)\\r\\n         detect_widget.place(relx=0.5, rely=0.7, anchor=\\\'center\\\')\\r\\n \\r\\ndiff --git a/data/bounding_boxes_1.png b/data/bounding_boxes_1.png\\nindex d5906f3..38cf6ce 100644\\nBinary files a/data/bounding_boxes_1.png and b/data/bounding_boxes_1.png differ\\ndiff --git a/data/student/processed/1911368/0.png b/data/student/processed/1911368/0.png\\ndeleted file mode 100644\\nindex c051192..0000000\\nBinary files a/data/student/processed/1911368/0.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/1.png b/data/student/processed/1911368/1.png\\ndeleted file mode 100644\\nindex 99e5d28..0000000\\nBinary files a/data/student/processed/1911368/1.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/10.png b/data/student/processed/1911368/10.png\\ndeleted file mode 100644\\nindex df469d0..0000000\\nBinary files a/data/student/processed/1911368/10.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/11.png b/data/student/processed/1911368/11.png\\ndeleted file mode 100644\\nindex 20d1c4d..0000000\\nBinary files a/data/student/processed/1911368/11.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/12.png b/data/student/processed/1911368/12.png\\ndeleted file mode 100644\\nindex 088ec3b..0000000\\nBinary files a/data/student/processed/1911368/12.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/13.png b/data/student/processed/1911368/13.png\\ndeleted file mode 100644\\nindex 0ca5dd8..0000000\\nBinary files a/data/student/processed/1911368/13.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/14.png b/data/student/processed/1911368/14.png\\ndeleted file mode 100644\\nindex 62952ad..0000000\\nBinary files a/data/student/processed/1911368/14.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/15.png b/data/student/processed/1911368/15.png\\ndeleted file mode 100644\\nindex a8e62c6..0000000\\nBinary files a/data/student/processed/1911368/15.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/16.png b/data/student/processed/1911368/16.png\\ndeleted file mode 100644\\nindex c260216..0000000\\nBinary files a/data/student/processed/1911368/16.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/17.png b/data/student/processed/1911368/17.png\\ndeleted file mode 100644\\nindex 380bafb..0000000\\nBinary files a/data/student/processed/1911368/17.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/18.png b/data/student/processed/1911368/18.png\\ndeleted file mode 100644\\nindex 0c561fd..0000000\\nBinary files a/data/student/processed/1911368/18.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/19.png b/data/student/processed/1911368/19.png\\ndeleted file mode 100644\\nindex 5e31f0c..0000000\\nBinary files a/data/student/processed/1911368/19.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/2.png b/data/student/processed/1911368/2.png\\ndeleted file mode 100644\\nindex 36d8db6..0000000\\nBinary files a/data/student/processed/1911368/2.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/3.png b/data/student/processed/1911368/3.png\\ndeleted file mode 100644\\nindex f4b183a..0000000\\nBinary files a/data/student/processed/1911368/3.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/4.png b/data/student/processed/1911368/4.png\\ndeleted file mode 100644\\nindex 218248d..0000000\\nBinary files a/data/student/processed/1911368/4.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/5.png b/data/student/processed/1911368/5.png\\ndeleted file mode 100644\\nindex e531ba3..0000000\\nBinary files a/data/student/processed/1911368/5.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/6.png b/data/student/processed/1911368/6.png\\ndeleted file mode 100644\\nindex 02041a3..0000000\\nBinary files a/data/student/processed/1911368/6.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/7.png b/data/student/processed/1911368/7.png\\ndeleted file mode 100644\\nindex 000e3f9..0000000\\nBinary files a/data/student/processed/1911368/7.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/8.png b/data/student/processed/1911368/8.png\\ndeleted file mode 100644\\nindex 777fd4f..0000000\\nBinary files a/data/student/processed/1911368/8.png and /dev/null differ\\ndiff --git a/data/student/processed/1911368/9.png b/data/student/processed/1911368/9.png\\ndeleted file mode 100644\\nindex b4b589e..0000000\\nBinary files a/data/student/processed/1911368/9.png and /dev/null differ\\ndiff --git a/data/student/processed/revision_info.txt b/data/student/processed/revision_info.txt\\nindex 0cbd5a1..4aa2175 100644\\n--- a/data/student/processed/revision_info.txt\\n+++ b/data/student/processed/revision_info.txt\\n@@ -2,6 +2,6 @@ arguments: app-gui.py\\n --------------------\\n tensorflow version: 2.11.0\\n --------------------\\n-git hash: b\\\'9c81e69fd384d2ef884820592d4d0392b9fe5090\\\'\\n+git hash: b\\\'327e78b08956ac731a903cc76880b0ad4074195d\\\'\\n --------------------\\n-b\\\'diff --git a/Detector.py b/Detector.py\\\\nindex 4db826c..0896348 100644\\\\n--- a/Detector.py\\\\n+++ b/Detector.py\\\\n@@ -7,7 +7,7 @@ def main_app(name):\\\\n         face_cascade = cv2.CascadeClassifier(\\\\\\\'./data/haarcascade_frontalface_default.xml\\\\\\\')\\\\r\\\\n         recognizer = cv2.face.LBPHFaceRecognizer_create()\\\\r\\\\n         recognizer.read(f"./data/classifiers/{name}_classifier.xml")\\\\r\\\\n-        cap = cv2.VideoCapture(0)\\\\r\\\\n+        cap = cv2.VideoCapture(1)\\\\r\\\\n         pred = 0\\\\r\\\\n         while True:\\\\r\\\\n             ret, frame = cap.read()\\\\r\\\\ndiff --git a/app-gui.py b/app-gui.py\\\\nindex 0f64293..c53ccc6 100644\\\\n--- a/app-gui.py\\\\n+++ b/app-gui.py\\\\n@@ -1,11 +1,14 @@\\\\n from Detector import main_app\\\\r\\\\n-from create_classifier import train_classifer\\\\r\\\\n+from create_classifier import train_classifer, regFaces\\\\r\\\\n from create_dataset import start_capture\\\\r\\\\n import tkinter as tk\\\\r\\\\n from tkinter import font as tkfont\\\\r\\\\n-from tkinter import messagebox,PhotoImage\\\\r\\\\n-#from PIL import ImageTk, Image\\\\r\\\\n-#from gender_prediction import emotion,ageAndgender\\\\r\\\\n+from tkinter import messagebox, PhotoImage\\\\r\\\\n+from PIL import Image, ImageTk\\\\r\\\\n+import cv2\\\\r\\\\n+import os\\\\r\\\\n+# from PIL import ImageTk, Image\\\\r\\\\n+# from gender_prediction import emotion,ageAndgender\\\\r\\\\n names = set()\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n@@ -14,23 +17,34 @@ class MainUI(tk.Tk):\\\\n     def __init__(self, *args, **kwargs):\\\\r\\\\n         tk.Tk.__init__(self, *args, **kwargs)\\\\r\\\\n         global names\\\\r\\\\n+        global open_webcam\\\\r\\\\n+        open_webcam = \\\\\\\'false\\\\\\\'\\\\r\\\\n         with open("nameslist.txt", "r") as f:\\\\r\\\\n             x = f.read()\\\\r\\\\n             z = x.rstrip().split(" ")\\\\r\\\\n             for i in z:\\\\r\\\\n                 names.add(i)\\\\r\\\\n-        self.title_font = tkfont.Font(family=\\\\\\\'Helvetica\\\\\\\', size=16, weight="bold")\\\\r\\\\n+        self.title_font = tkfont.Font(\\\\r\\\\n+            family=\\\\\\\'Helvetica\\\\\\\', size=16, weight="bold")\\\\r\\\\n         self.title("Face Recognizer")\\\\r\\\\n         self.resizable(False, False)\\\\r\\\\n-        self.geometry("500x250")\\\\r\\\\n+        app_width = 1200\\\\r\\\\n+        app_height = 600\\\\r\\\\n+        screen_width = self.winfo_screenwidth()\\\\r\\\\n+        screen_height = self.winfo_screenheight()\\\\r\\\\n+\\\\r\\\\n+        x = (screen_width / 2) - (app_width / 2)\\\\r\\\\n+        y = (screen_height / 2) - (app_height / 2)\\\\r\\\\n+\\\\r\\\\n+        self.geometry(f\\\\\\\'{app_width}x{app_height}+{int(x)}+{int(y)}\\\\\\\')\\\\r\\\\n         self.protocol("WM_DELETE_WINDOW", self.on_closing)\\\\r\\\\n         self.active_name = None\\\\r\\\\n         container = tk.Frame(self)\\\\r\\\\n-        container.grid(sticky="nsew")\\\\r\\\\n+        container.place(relx=0.5, rely=0.5, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n         container.grid_rowconfigure(0, weight=1)\\\\r\\\\n         container.grid_columnconfigure(0, weight=1)\\\\r\\\\n         self.frames = {}\\\\r\\\\n-        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour):\\\\r\\\\n+        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour, PageTakeFace):\\\\r\\\\n             page_name = F.__name__\\\\r\\\\n             frame = F(parent=container, controller=self)\\\\r\\\\n             self.frames[page_name] = frame\\\\r\\\\n@@ -38,76 +52,100 @@ class MainUI(tk.Tk):\\\\n         self.show_frame("StartPage")\\\\r\\\\n \\\\r\\\\n     def show_frame(self, page_name):\\\\r\\\\n-            frame = self.frames[page_name]\\\\r\\\\n-            frame.tkraise()\\\\r\\\\n+        frame = self.frames[page_name]\\\\r\\\\n+        frame.tkraise()\\\\r\\\\n \\\\r\\\\n     def on_closing(self):\\\\r\\\\n \\\\r\\\\n         if messagebox.askokcancel("Quit", "Are you sure?"):\\\\r\\\\n             global names\\\\r\\\\n-            f =  open("nameslist.txt", "a+")\\\\r\\\\n+            f = open("nameslist.txt", "a+")\\\\r\\\\n             for i in names:\\\\r\\\\n-                    f.write(i+" ")\\\\r\\\\n+                f.write(i+" ")\\\\r\\\\n             self.destroy()\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class StartPage(tk.Frame):\\\\r\\\\n \\\\r\\\\n-        def __init__(self, parent, controller):\\\\r\\\\n-            tk.Frame.__init__(self, parent)\\\\r\\\\n-            self.controller = controller\\\\r\\\\n-            #load = Image.open("homepagepic.png")\\\\r\\\\n-            #load = load.resize((250, 250), Image.ANTIALIAS)\\\\r\\\\n-            render = PhotoImage(file=\\\\\\\'homepagepic.png\\\\\\\')\\\\r\\\\n-            img = tk.Label(self, image=render)\\\\r\\\\n-            img.image = render\\\\r\\\\n-            img.grid(row=0, column=1, rowspan=4, sticky="nsew")\\\\r\\\\n-            label = tk.Label(self, text="        Home Page        ", font=self.controller.title_font,fg="#263942")\\\\r\\\\n-            label.grid(row=0, sticky="ew")\\\\r\\\\n-            button1 = tk.Button(self, text="   Add a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageOne"))\\\\r\\\\n-            button2 = tk.Button(self, text="   Check a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageTwo"))\\\\r\\\\n-            button3 = tk.Button(self, text="Quit", fg="#263942", bg="#ffffff", command=self.on_closing)\\\\r\\\\n-            button1.grid(row=1, column=0, ipady=3, ipadx=7)\\\\r\\\\n-            button2.grid(row=2, column=0, ipady=3, ipadx=2)\\\\r\\\\n-            button3.grid(row=3, column=0, ipady=3, ipadx=32)\\\\r\\\\n-\\\\r\\\\n-\\\\r\\\\n-        def on_closing(self):\\\\r\\\\n-            if messagebox.askokcancel("Quit", "Are you sure?"):\\\\r\\\\n-                global names\\\\r\\\\n-                with open("nameslist.txt", "w") as f:\\\\r\\\\n-                    for i in names:\\\\r\\\\n-                        f.write(i + " ")\\\\r\\\\n-                self.controller.destroy()\\\\r\\\\n+    def __init__(self, parent, controller):\\\\r\\\\n+        tk.Frame.__init__(self, parent)\\\\r\\\\n+        self.controller = controller\\\\r\\\\n+\\\\r\\\\n+        load1 = Image.open("Touch_ID.png")\\\\r\\\\n+        load1 = load1.resize((250, 250), Image.ANTIALIAS)\\\\r\\\\n+        render1 = PhotoImage(file=\\\\\\\'Touch_ID.png\\\\\\\')\\\\r\\\\n+\\\\r\\\\n+        render1 = ImageTk.PhotoImage(Image.open(\\\\r\\\\n+            "Touch_ID.png").resize((250, 250), Image.ANTIALIAS))\\\\r\\\\n+\\\\r\\\\n+        button4 = tk.Button(\\\\r\\\\n+            self, image=render1)\\\\r\\\\n+        button4.image = render1\\\\r\\\\n+        button4.grid(row=0, column=0, rowspan=4,\\\\r\\\\n+                     padx=10, pady=12, sticky="nsew")\\\\r\\\\n+\\\\r\\\\n+        load2 = Image.open("face-id-id.png")\\\\r\\\\n+        load2 = load2.resize((50, 50), Image.ANTIALIAS)\\\\r\\\\n+        render2 = PhotoImage(file=\\\\\\\'face-id-id.png\\\\\\\')\\\\r\\\\n+\\\\r\\\\n+        render2 = ImageTk.PhotoImage(Image.open(\\\\r\\\\n+            "face-id-id.png").resize((250, 250), Image.ANTIALIAS))\\\\r\\\\n+\\\\r\\\\n+        button5 = tk.Button(\\\\r\\\\n+            self, image=render2, command=lambda: self.controller.show_frame("PageOne"))\\\\r\\\\n+        button5.image = render2\\\\r\\\\n+        button5.grid(row=1, column=1, rowspan=4,\\\\r\\\\n+                     padx=10, pady=12, sticky="nsew")\\\\r\\\\n+\\\\r\\\\n+    def on_closing(self):\\\\r\\\\n+        if messagebox.askokcancel("Quit", "Are you sure?"):\\\\r\\\\n+            global names\\\\r\\\\n+            with open("nameslist.txt", "w") as f:\\\\r\\\\n+                for i in names:\\\\r\\\\n+                    f.write(i + " ")\\\\r\\\\n+            self.controller.destroy()\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class PageOne(tk.Frame):\\\\r\\\\n     def __init__(self, parent, controller):\\\\r\\\\n         tk.Frame.__init__(self, parent)\\\\r\\\\n         self.controller = controller\\\\r\\\\n-        tk.Label(self, text="Enter the name", fg="#263942", font=\\\\\\\'Helvetica 12 bold\\\\\\\').grid(row=0, column=0, pady=10, padx=5)\\\\r\\\\n-        self.user_name = tk.Entry(self, borderwidth=3, bg="lightgrey", font=\\\\\\\'Helvetica 11\\\\\\\')\\\\r\\\\n-        self.user_name.grid(row=0, column=1, pady=10, padx=10)\\\\r\\\\n-        self.buttoncanc = tk.Button(self, text="Cancel", bg="#ffffff", fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\r\\\\n-        self.buttonext = tk.Button(self, text="Next", fg="#ffffff", bg="#263942", command=self.start_training)\\\\r\\\\n-        self.buttoncanc.grid(row=1, column=0, pady=10, ipadx=5, ipady=4)\\\\r\\\\n-        self.buttonext.grid(row=1, column=1, pady=10, ipadx=5, ipady=4)\\\\r\\\\n-    def start_training(self):\\\\r\\\\n-        global names\\\\r\\\\n-        if self.user_name.get() == "None":\\\\r\\\\n-            messagebox.showerror("Error", "Name cannot be \\\\\\\'None\\\\\\\'")\\\\r\\\\n-            return\\\\r\\\\n-        elif self.user_name.get() in names:\\\\r\\\\n-            messagebox.showerror("Error", "User already exists!")\\\\r\\\\n-            return\\\\r\\\\n-        elif len(self.user_name.get()) == 0:\\\\r\\\\n-            messagebox.showerror("Error", "Name cannot be empty!")\\\\r\\\\n-            return\\\\r\\\\n-        name = self.user_name.get()\\\\r\\\\n-        names.add(name)\\\\r\\\\n-        self.controller.active_name = name\\\\r\\\\n-        self.controller.frames["PageTwo"].refresh_names()\\\\r\\\\n-        self.controller.show_frame("PageThree")\\\\r\\\\n+\\\\r\\\\n+        color1 = \\\\\\\'#020f12\\\\\\\'\\\\r\\\\n+        color2 = \\\\\\\'#05d7ff\\\\\\\'\\\\r\\\\n+        color3 = \\\\\\\'#65e7ff\\\\\\\'\\\\r\\\\n+        color4 = \\\\\\\'BLACK\\\\\\\'\\\\r\\\\n+        color5 = \\\\\\\'YELLOW\\\\\\\'\\\\r\\\\n+        self.buttoncanc = tk.Button(self,\\\\r\\\\n+                                    background=color2,\\\\r\\\\n+                                    foreground=color4,\\\\r\\\\n+                                    activebackground=color3,\\\\r\\\\n+                                    activeforeground=color4,\\\\r\\\\n+                                    highlightthickness=2,\\\\r\\\\n+                                    highlightbackground=color2,\\\\r\\\\n+                                    width=15,\\\\r\\\\n+                                    height=2,\\\\r\\\\n+                                    border=0,\\\\r\\\\n+                                    cursor=\\\\\\\'hand2\\\\\\\',\\\\r\\\\n+                                    text="Cancel",\\\\r\\\\n+                                    font=(\\\\\\\'Arial\\\\\\\', 16, \\\\\\\'bold\\\\\\\'),\\\\r\\\\n+                                    command=lambda: controller.show_frame("StartPage"))\\\\r\\\\n+        self.buttoncanc.place(relx=0.5, rely=0.5, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+\\\\r\\\\n+        self.buttonTakeFace = tk.Button(self,\\\\r\\\\n+                                        background=color2,\\\\r\\\\n+                                        foreground=color4,\\\\r\\\\n+                                        activebackground=color3,\\\\r\\\\n+                                        activeforeground=color4,\\\\r\\\\n+                                        highlightthickness=2,\\\\r\\\\n+                                        highlightbackground=color2,\\\\r\\\\n+                                        width=15,\\\\r\\\\n+                                        height=2,\\\\r\\\\n+                                        border=0,\\\\r\\\\n+                                        cursor=\\\\\\\'hand2\\\\\\\',\\\\r\\\\n+                                        text="Add new",\\\\r\\\\n+                                        font=(\\\\\\\'Arial\\\\\\\', 16, \\\\\\\'bold\\\\\\\'), command=lambda: controller.show_frame("PageTakeFace"))\\\\r\\\\n+        self.buttonTakeFace.place(relx=0.5, rely=0.3, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class PageTwo(tk.Frame):\\\\r\\\\n@@ -116,13 +154,16 @@ class PageTwo(tk.Frame):\\\\n         tk.Frame.__init__(self, parent)\\\\r\\\\n         global names\\\\r\\\\n         self.controller = controller\\\\r\\\\n-        tk.Label(self, text="Select user", fg="#263942", font=\\\\\\\'Helvetica 12 bold\\\\\\\').grid(row=0, column=0, padx=10, pady=10)\\\\r\\\\n-        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\\\r\\\\n+        tk.Label(self, text="Select user", fg="#263942", font=\\\\\\\'Helvetica 12 bold\\\\\\\').grid(\\\\r\\\\n+            row=0, column=0, padx=10, pady=10)\\\\r\\\\n+        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame(\\\\r\\\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\\\r\\\\n         self.menuvar = tk.StringVar(self)\\\\r\\\\n         self.dropdown = tk.OptionMenu(self, self.menuvar, *names)\\\\r\\\\n         self.dropdown.config(bg="lightgrey")\\\\r\\\\n         self.dropdown["menu"].config(bg="lightgrey")\\\\r\\\\n-        self.buttonext = tk.Button(self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\\\r\\\\n+        self.buttonext = tk.Button(\\\\r\\\\n+            self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\\\r\\\\n         self.dropdown.grid(row=0, column=1, ipadx=8, padx=10, pady=10)\\\\r\\\\n         self.buttoncanc.grid(row=1, ipadx=5, ipady=4, column=0, pady=10)\\\\r\\\\n         self.buttonext.grid(row=1, ipadx=5, ipady=4, column=1, pady=10)\\\\r\\\\n@@ -139,34 +180,36 @@ class PageTwo(tk.Frame):\\\\n         self.menuvar.set(\\\\\\\'\\\\\\\')\\\\r\\\\n         self.dropdown[\\\\\\\'menu\\\\\\\'].delete(0, \\\\\\\'end\\\\\\\')\\\\r\\\\n         for name in names:\\\\r\\\\n-            self.dropdown[\\\\\\\'menu\\\\\\\'].add_command(label=name, command=tk._setit(self.menuvar, name))\\\\r\\\\n+            self.dropdown[\\\\\\\'menu\\\\\\\'].add_command(\\\\r\\\\n+                label=name, command=tk._setit(self.menuvar, name))\\\\r\\\\n+\\\\r\\\\n \\\\r\\\\n class PageThree(tk.Frame):\\\\r\\\\n \\\\r\\\\n     def __init__(self, parent, controller):\\\\r\\\\n         tk.Frame.__init__(self, parent)\\\\r\\\\n         self.controller = controller\\\\r\\\\n-        self.numimglabel = tk.Label(self, text="Number of images captured = 0", font=\\\\\\\'Helvetica 12 bold\\\\\\\', fg="#263942")\\\\r\\\\n-        self.numimglabel.grid(row=0, column=0, columnspan=2, sticky="ew", pady=10)\\\\r\\\\n-        self.capturebutton = tk.Button(self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\\\r\\\\n-        self.trainbutton = tk.Button(self, text="Train The Model", fg="#ffffff", bg="#263942",command=self.trainmodel)\\\\r\\\\n-        self.capturebutton.grid(row=1, column=0, ipadx=5, ipady=4, padx=10, pady=20)\\\\r\\\\n-        self.trainbutton.grid(row=1, column=1, ipadx=5, ipady=4, padx=10, pady=20)\\\\r\\\\n+        self.numimglabel = tk.Label(\\\\r\\\\n+            self, text="Number of images captured = 0", font=\\\\\\\'Helvetica 12 bold\\\\\\\', fg="#263942")\\\\r\\\\n+        self.numimglabel.grid(\\\\r\\\\n+            row=0, column=0, columnspan=2, sticky="ew", pady=10)\\\\r\\\\n+        # self.capturebutton = tk.Button(\\\\r\\\\n+        #     self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\\\r\\\\n+        # self.trainbutton = tk.Button(\\\\r\\\\n+        #     self, text="Train The Model", fg="#ffffff", bg="#263942", command=self.trainmodel)\\\\r\\\\n+        # self.capturebutton.grid(row=1, column=0, ipadx=5,\\\\r\\\\n+        #                         ipady=4, padx=10, pady=20)\\\\r\\\\n+        # self.trainbutton.grid(row=1, column=1, ipadx=5,\\\\r\\\\n+        #                       ipady=4, padx=10, pady=20)\\\\r\\\\n \\\\r\\\\n     def capimg(self):\\\\r\\\\n         self.numimglabel.config(text=str("Captured Images = 0 "))\\\\r\\\\n-        messagebox.showinfo("INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\\\r\\\\n+        messagebox.showinfo(\\\\r\\\\n+            "INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\\\r\\\\n         x = start_capture(self.controller.active_name)\\\\r\\\\n         self.controller.num_of_images = x\\\\r\\\\n-        self.numimglabel.config(text=str("Number of images captured = "+str(x)))\\\\r\\\\n-\\\\r\\\\n-    def trainmodel(self):\\\\r\\\\n-        if self.controller.num_of_images < 300:\\\\r\\\\n-            messagebox.showerror("ERROR", "No enough Data, Capture at least 300 images!")\\\\r\\\\n-            return\\\\r\\\\n-        train_classifer(self.controller.active_name)\\\\r\\\\n-        messagebox.showinfo("SUCCESS", "The modele has been successfully trained!")\\\\r\\\\n-        self.controller.show_frame("PageFour")\\\\r\\\\n+        self.numimglabel.config(\\\\r\\\\n+            text=str("Number of images captured = "+str(x)))\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class PageFour(tk.Frame):\\\\r\\\\n@@ -175,27 +218,171 @@ class PageFour(tk.Frame):\\\\n         tk.Frame.__init__(self, parent)\\\\r\\\\n         self.controller = controller\\\\r\\\\n \\\\r\\\\n-        label = tk.Label(self, text="Face Recognition", font=\\\\\\\'Helvetica 16 bold\\\\\\\')\\\\r\\\\n-        label.grid(row=0,column=0, sticky="ew")\\\\r\\\\n-        button1 = tk.Button(self, text="Face Recognition", command=self.openwebcam, fg="#ffffff", bg="#263942")\\\\r\\\\n-        #button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\\\r\\\\n-        #button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\\\r\\\\n-        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\\\r\\\\n-        button1.grid(row=1,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n-        #button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n-        #button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n-        button4.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n+        label = tk.Label(self, text="Face Recognition",\\\\r\\\\n+                         font=\\\\\\\'Helvetica 16 bold\\\\\\\')\\\\r\\\\n+        label.grid(row=0, column=0, sticky="ew")\\\\r\\\\n+        button1 = tk.Button(self, text="Face Recognition",\\\\r\\\\n+                            command=self.openwebcam, fg="#ffffff", bg="#263942")\\\\r\\\\n+        # button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\\\r\\\\n+        # button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\\\r\\\\n+        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame(\\\\r\\\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\\\r\\\\n+        button1.grid(row=1, column=0, sticky="ew",\\\\r\\\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n+        # button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n+        # button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n+        button4.grid(row=1, column=1, sticky="ew",\\\\r\\\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\\\r\\\\n \\\\r\\\\n     def openwebcam(self):\\\\r\\\\n         main_app(self.controller.active_name)\\\\r\\\\n-    #def gender_age_pred(self):\\\\r\\\\n+    # def gender_age_pred(self):\\\\r\\\\n      #  ageAndgender()\\\\r\\\\n-    #def emot(self):\\\\r\\\\n+    # def emot(self):\\\\r\\\\n      #   emotion()\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n+num_of_images = 0\\\\r\\\\n+\\\\r\\\\n+\\\\r\\\\n+class PageTakeFace(tk.Frame):\\\\r\\\\n+    def __init__(self, parent, controller):\\\\r\\\\n+        tk.Frame.__init__(self, parent)\\\\r\\\\n+        self.controller = controller\\\\r\\\\n+\\\\r\\\\n+        global cam_on\\\\r\\\\n+        cam_on = False\\\\r\\\\n+        global cap\\\\r\\\\n+        cap = None\\\\r\\\\n+        # student_id = \\\\\\\'_\\\\\\\'.join([\\\\\\\'student\\\\\\\', stundent_id_entry])\\\\r\\\\n+\\\\r\\\\n+        def display_frame():\\\\r\\\\n+            global cam_on\\\\r\\\\n+            global num_of_images\\\\r\\\\n+            detector = cv2.CascadeClassifier(\\\\r\\\\n+                "./data/haarcascade_frontalface_default.xml")\\\\r\\\\n+\\\\r\\\\n+            filepath = \\\\\\\'./data/student/raw/\\\\\\\' + stundent_id_entry.get()\\\\r\\\\n+\\\\r\\\\n+            isExist = os.path.exists(filepath)\\\\r\\\\n+\\\\r\\\\n+            if not isExist:\\\\r\\\\n+                print(\\\\\\\'The new directory is created!\\\\\\\')\\\\r\\\\n+                print(filepath)\\\\r\\\\n+                os.makedirs(filepath)\\\\r\\\\n+\\\\r\\\\n+            if cam_on:\\\\r\\\\n+\\\\r\\\\n+                ret, frame = cap.read()\\\\r\\\\n+\\\\r\\\\n+                if ret:\\\\r\\\\n+                    opencv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\\\\r\\\\n+                    filename = \\\\\\\'.\\\\\\\'.join([str(num_of_images), \\\\\\\'jpg\\\\\\\'])\\\\r\\\\n+                    path = os.path.join(filepath, filename)\\\\r\\\\n+                    cv2.imwrite(path, frame)\\\\r\\\\n+                    face = detector.detectMultiScale(\\\\r\\\\n+                        image=opencv_image, scaleFactor=1.1, minNeighbors=5)\\\\r\\\\n+                    for x, y, w, h in face:\\\\r\\\\n+                        cv2.rectangle(frame, (x, y),\\\\r\\\\n+                                      (x+w, y+h), (8, 238, 255), 2)\\\\r\\\\n+                        cv2.putText(frame, "Face Detected", (x, y-5),\\\\r\\\\n+                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\\\r\\\\n+                        cv2.putText(frame, str(str(num_of_images)+" images captured"),\\\\r\\\\n+                                    (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\\\r\\\\n+                        # new_img = frame[y:y+h, x:x+w]\\\\r\\\\n+\\\\r\\\\n+                    # Capture the latest frame and transform to image\\\\r\\\\n+                    captured_image = Image.fromarray(\\\\r\\\\n+                        cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA))\\\\r\\\\n+\\\\r\\\\n+                    # Convert captured image to photoimage\\\\r\\\\n+                    photo_image = ImageTk.PhotoImage(\\\\r\\\\n+                        captured_image.resize((500, 300), Image.ANTIALIAS))\\\\r\\\\n+\\\\r\\\\n+                    # Displaying photoimage in the label\\\\r\\\\n+                    label_widget.photo_image = photo_image\\\\r\\\\n+\\\\r\\\\n+                    # Configure image in the label\\\\r\\\\n+                    label_widget.configure(image=photo_image)\\\\r\\\\n+\\\\r\\\\n+                    # Repeat the same process after every 10 seconds\\\\r\\\\n+                    num_of_images += 1\\\\r\\\\n+\\\\r\\\\n+                    if num_of_images == 21:\\\\r\\\\n+                        stop_vid()\\\\r\\\\n+                        num_of_images = 0\\\\r\\\\n+                        messagebox.showinfo(\\\\r\\\\n+                            "INSTRUCTIONS", "We captured 20 pic of your Face.")\\\\r\\\\n+                        return \\\\\\\'ok\\\\\\\'\\\\r\\\\n+\\\\r\\\\n+                label_widget.after(10, display_frame)\\\\r\\\\n+\\\\r\\\\n+        def start_vid():\\\\r\\\\n+            global cam_on, cap\\\\r\\\\n+            stop_vid()\\\\r\\\\n+            cam_on = True\\\\r\\\\n+            cap = cv2.VideoCapture(1)\\\\r\\\\n+            display_frame()\\\\r\\\\n+\\\\r\\\\n+        def stop_vid():\\\\r\\\\n+            label_widget.configure(image=None)\\\\r\\\\n+            label_widget.configure(image="")\\\\r\\\\n+\\\\r\\\\n+            global cam_on\\\\r\\\\n+            cam_on = False\\\\r\\\\n+\\\\r\\\\n+            if cap:\\\\r\\\\n+                cap.release()\\\\r\\\\n+\\\\r\\\\n+        def trainmodel():\\\\r\\\\n+            # if self.controller.num_of_images < 300:\\\\r\\\\n+            #     messagebox.showerror(\\\\r\\\\n+            #         "ERROR", "No enough Data, Capture at least 300 images!")\\\\r\\\\n+            #     return\\\\r\\\\n+            regFaces()\\\\r\\\\n+            messagebox.showinfo(\\\\r\\\\n+                "SUCCESS", "You can now implement your detection")\\\\r\\\\n+\\\\r\\\\n+        ####### take face screen #######\\\\r\\\\n+\\\\r\\\\n+        user_info_frame = tk.LabelFrame(self, text="User Information")\\\\r\\\\n+        user_info_frame.grid(row=0, column=0, padx=20, pady=10)\\\\r\\\\n+\\\\r\\\\n+        first_name_label = tk.Label(user_info_frame, text="Your Name")\\\\r\\\\n+        first_name_label.grid(row=0, column=0)\\\\r\\\\n+        student_id_label = tk.Label(user_info_frame, text="Your Student Id")\\\\r\\\\n+        student_id_label.grid(row=0, column=1)\\\\r\\\\n+\\\\r\\\\n+        first_name_entry = tk.Entry(user_info_frame)\\\\r\\\\n+        stundent_id_entry = tk.Entry(user_info_frame)\\\\r\\\\n+        first_name_entry.grid(row=1, column=0)\\\\r\\\\n+        stundent_id_entry.grid(row=1, column=1)\\\\r\\\\n+\\\\r\\\\n+        buttoncanc = tk.Button(user_info_frame, text="Cancel", bg="#ffffff",\\\\r\\\\n+                               fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\r\\\\n+        buttoncanc.grid(row=2, column=0, pady=10, ipadx=5, ipady=4)\\\\r\\\\n+\\\\r\\\\n+        buttoncanc = tk.Button(user_info_frame, text="Confirm", bg="#ffffff",\\\\r\\\\n+                               fg="#263942", command=start_vid)\\\\r\\\\n+        buttoncanc.grid(row=2, column=1, pady=10, ipadx=5, ipady=4)\\\\r\\\\n+\\\\r\\\\n+        label_widget = tk.Label(self)\\\\r\\\\n+        label_widget.grid(row=3, column=0)\\\\r\\\\n+\\\\r\\\\n+        # age_label = tk.Label(user_info_frame, text="Age")\\\\r\\\\n+        # age_spinbox = tk.Spinbox(user_info_frame, from_=18, to=110)\\\\r\\\\n+        # age_label.grid(row=2, column=0)\\\\r\\\\n+        # age_spinbox.grid(row=3, column=0)\\\\r\\\\n+\\\\r\\\\n+        for widget in user_info_frame.winfo_children():\\\\r\\\\n+            widget.grid_configure(padx=10, pady=5)\\\\r\\\\n+\\\\r\\\\n+        button1 = tk.Button(self, text="Training Model",\\\\r\\\\n+                            command=trainmodel)\\\\r\\\\n+        button1.grid(row=8, column=0, padx=10,\\\\r\\\\n+                     pady=10, ipadx=5, ipady=4)\\\\r\\\\n+\\\\r\\\\n \\\\r\\\\n app = MainUI()\\\\r\\\\n app.iconphoto(False, tk.PhotoImage(file=\\\\\\\'icon.ico\\\\\\\'))\\\\r\\\\n app.mainloop()\\\\r\\\\n-\\\\r\\\\ndiff --git a/create_classifier.py b/create_classifier.py\\\\nindex a022cf5..9a16c5e 100644\\\\n--- a/create_classifier.py\\\\n+++ b/create_classifier.py\\\\n@@ -1,10 +1,60 @@\\\\n import numpy as np\\\\r\\\\n from PIL import Image\\\\r\\\\n-import os, cv2\\\\r\\\\n+import os\\\\r\\\\n+import cv2\\\\r\\\\n+from Helper.align_dataset_mtcnn import main\\\\r\\\\n+from Helper.classifier import mainTrain\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n+def regFaces():\\\\r\\\\n+    input_dir = \\\\\\\'data/student/raw\\\\\\\'\\\\r\\\\n+    output_dir = \\\\\\\'data/student/processed\\\\\\\'\\\\r\\\\n+    image_size = 160\\\\r\\\\n+    margin = 32\\\\r\\\\n+    random_order = \\\\\\\'random_order\\\\\\\'\\\\r\\\\n+    gpu_memory_fraction = 0.25\\\\r\\\\n+    args = {\\\\r\\\\n+        \\\\\\\'input_dir\\\\\\\': input_dir,\\\\r\\\\n+        \\\\\\\'output_dir\\\\\\\': output_dir,\\\\r\\\\n+        \\\\\\\'image_size\\\\\\\': image_size,\\\\r\\\\n+        \\\\\\\'margin\\\\\\\': margin,\\\\r\\\\n+        \\\\\\\'random_order\\\\\\\': random_order,\\\\r\\\\n+        \\\\\\\'gpu_memory_fraction\\\\\\\': gpu_memory_fraction,\\\\r\\\\n+        \\\\\\\'detect_multiple_faces\\\\\\\': False\\\\r\\\\n+    }\\\\r\\\\n+    print(args[\\\\\\\'output_dir\\\\\\\'])\\\\r\\\\n+    data = main(args)\\\\r\\\\n \\\\r\\\\n+    if data == \\\\\\\'ok\\\\\\\':\\\\r\\\\n+        startTraining(data)\\\\r\\\\n+\\\\r\\\\n+    # data = \\\\\\\'complete reg faces\\\\\\\'\\\\r\\\\n+    return\\\\r\\\\n # Method to train custom classifier to recognize face\\\\r\\\\n+\\\\r\\\\n+\\\\r\\\\n+def startTraining(data):\\\\r\\\\n+    os.remove(\\\\\\\'model/facemodel.pkl\\\\\\\')\\\\r\\\\n+    # message = request.form[\\\\\\\'status\\\\\\\']\\\\r\\\\n+    if data == \\\\\\\'ok\\\\\\\':\\\\r\\\\n+        data_dir = \\\\\\\'data/student/processed\\\\\\\'\\\\r\\\\n+        # test_data = \\\\\\\'backend/data/test/align\\\\\\\'\\\\r\\\\n+        args = {\\\\r\\\\n+            \\\\\\\'mode\\\\\\\': \\\\\\\'TRAIN\\\\\\\',\\\\r\\\\n+            \\\\\\\'data_dir\\\\\\\': data_dir,\\\\r\\\\n+            \\\\\\\'model\\\\\\\': \\\\\\\'model/20180402-114759.pb\\\\\\\',\\\\r\\\\n+            \\\\\\\'classifier_filename\\\\\\\': \\\\\\\'model/facemodel.pkl\\\\\\\',\\\\r\\\\n+            \\\\\\\'use_split_dataset\\\\\\\': \\\\\\\'store_true\\\\\\\',\\\\r\\\\n+            \\\\\\\'batch_size\\\\\\\': 1000,\\\\r\\\\n+            \\\\\\\'image_size\\\\\\\': 160,\\\\r\\\\n+            \\\\\\\'seed\\\\\\\': 666,\\\\r\\\\n+            \\\\\\\'min_nrof_images_per_class\\\\\\\': 20,\\\\r\\\\n+            \\\\\\\'nrof_train_images_per_class\\\\\\\': 15}\\\\r\\\\n+        mainTrain(args)\\\\r\\\\n+        data = \\\\\\\'complete trained\\\\\\\'\\\\r\\\\n+        return\\\\r\\\\n+\\\\r\\\\n+\\\\r\\\\n def train_classifer(name):\\\\r\\\\n     # Read all the images in custom data-set\\\\r\\\\n     path = os.path.join(os.getcwd()+"/data/"+name+"/")\\\\r\\\\n@@ -14,27 +64,24 @@ def train_classifer(name):\\\\n     labels = []\\\\r\\\\n     pictures = {}\\\\r\\\\n \\\\r\\\\n-\\\\r\\\\n     # Store images in a numpy format and ids of the user on the same index in imageNp and id lists\\\\r\\\\n \\\\r\\\\n-    for root,dirs,files in os.walk(path):\\\\r\\\\n-            pictures = files\\\\r\\\\n+    for root, dirs, files in os.walk(path):\\\\r\\\\n+        pictures = files\\\\r\\\\n \\\\r\\\\n+    for pic in pictures:\\\\r\\\\n \\\\r\\\\n-    for pic in pictures :\\\\r\\\\n-\\\\r\\\\n-            imgpath = path+pic\\\\r\\\\n-            img = Image.open(imgpath).convert(\\\\\\\'L\\\\\\\')\\\\r\\\\n-            imageNp = np.array(img, \\\\\\\'uint8\\\\\\\')\\\\r\\\\n-            id = int(pic.split(name)[0])\\\\r\\\\n-            #names[name].append(id)\\\\r\\\\n-            faces.append(imageNp)\\\\r\\\\n-            ids.append(id)\\\\r\\\\n+        imgpath = path+pic\\\\r\\\\n+        img = Image.open(imgpath).convert(\\\\\\\'L\\\\\\\')\\\\r\\\\n+        imageNp = np.array(img, \\\\\\\'uint8\\\\\\\')\\\\r\\\\n+        id = int(pic.split(name)[0])\\\\r\\\\n+        # names[name].append(id)\\\\r\\\\n+        faces.append(imageNp)\\\\r\\\\n+        ids.append(id)\\\\r\\\\n \\\\r\\\\n     ids = np.array(ids)\\\\r\\\\n \\\\r\\\\n-    #Train and save classifier\\\\r\\\\n+    # Train and save classifier\\\\r\\\\n     clf = cv2.face.LBPHFaceRecognizer_create()\\\\r\\\\n     clf.train(faces, ids)\\\\r\\\\n     clf.write("./data/classifiers/"+name+"_classifier.xml")\\\\r\\\\n-\\\\r\\\\ndiff --git a/create_dataset.py b/create_dataset.py\\\\nindex 1fbeab1..fbc4f04 100644\\\\n--- a/create_dataset.py\\\\n+++ b/create_dataset.py\\\\n@@ -1,38 +1,41 @@\\\\n import cv2\\\\r\\\\n import os\\\\r\\\\n \\\\r\\\\n-def start_capture(name):\\\\r\\\\n-        path = "./data/" + name\\\\r\\\\n-        num_of_images = 0\\\\r\\\\n-        detector = cv2.CascadeClassifier("./data/haarcascade_frontalface_default.xml")\\\\r\\\\n-        try:\\\\r\\\\n-            os.makedirs(path)\\\\r\\\\n-        except:\\\\r\\\\n-            print(\\\\\\\'Directory Already Created\\\\\\\')\\\\r\\\\n-        vid = cv2.VideoCapture(0)\\\\r\\\\n-        while True:\\\\r\\\\n-\\\\r\\\\n-            ret, img = vid.read()\\\\r\\\\n-            new_img = None\\\\r\\\\n-            grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\\\r\\\\n-            face = detector.detectMultiScale(image=grayimg, scaleFactor=1.1, minNeighbors=5)\\\\r\\\\n-            for x, y, w, h in face:\\\\r\\\\n-                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\\\r\\\\n-                cv2.putText(img, "Face Detected", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\r\\\\n-                cv2.putText(img, str(str(num_of_images)+" images captured"), (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\r\\\\n-                new_img = img[y:y+h, x:x+w]\\\\r\\\\n-            cv2.imshow("FaceDetection", img)\\\\r\\\\n-            key = cv2.waitKey(1) & 0xFF\\\\r\\\\n \\\\r\\\\n+def start_capture(name):\\\\r\\\\n+    path = "./data/" + name\\\\r\\\\n+    num_of_images = 0\\\\r\\\\n+    detector = cv2.CascadeClassifier(\\\\r\\\\n+        "./data/haarcascade_frontalface_default.xml")\\\\r\\\\n+    try:\\\\r\\\\n+        os.makedirs(path)\\\\r\\\\n+    except:\\\\r\\\\n+        print(\\\\\\\'Directory Already Created\\\\\\\')\\\\r\\\\n+    vid = cv2.VideoCapture(1)\\\\r\\\\n+    while True:\\\\r\\\\n \\\\r\\\\n-            try :\\\\r\\\\n-                cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\\\r\\\\n-                num_of_images += 1\\\\r\\\\n-            except :\\\\r\\\\n+        ret, img = vid.read()\\\\r\\\\n+        new_img = None\\\\r\\\\n+        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\\\r\\\\n+        face = detector.detectMultiScale(\\\\r\\\\n+            image=grayimg, scaleFactor=1.1, minNeighbors=5)\\\\r\\\\n+        for x, y, w, h in face:\\\\r\\\\n+            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\\\r\\\\n+            cv2.putText(img, "Face Detected", (x, y-5),\\\\r\\\\n+                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\r\\\\n+            cv2.putText(img, str(str(num_of_images)+" images captured"),\\\\r\\\\n+                        (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\r\\\\n+            new_img = img[y:y+h, x:x+w]\\\\r\\\\n+        cv2.imshow("FaceDetection", img)\\\\r\\\\n+        key = cv2.waitKey(1) & 0xFF\\\\r\\\\n \\\\r\\\\n-                pass\\\\r\\\\n-            if key == ord("q") or key == 27 or num_of_images > 310:\\\\r\\\\n-                break\\\\r\\\\n-        cv2.destroyAllWindows()\\\\r\\\\n-        return num_of_images\\\\r\\\\n+        try:\\\\r\\\\n+            cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\\\r\\\\n+            num_of_images += 1\\\\r\\\\n+        except:\\\\r\\\\n \\\\r\\\\n+            pass\\\\r\\\\n+        if key == ord("q") or key == 27 or num_of_images > 10:\\\\r\\\\n+            break\\\\r\\\\n+    cv2.destroyAllWindows()\\\\r\\\\n+    return num_of_images\\\\r\\\\ndiff --git a/nameslist.txt b/nameslist.txt\\\\nindex e605024..5f8a285 100644\\\\n--- a/nameslist.txt\\\\n+++ b/nameslist.txt\\\\n@@ -1 +1 @@\\\\n-NO \\\\n\\\\\\\\ No newline at end of file\\\\n+                                                                     \\\\n\\\\\\\\ No newline at end of file\\\'\\n\\\\ No newline at end of file\\n+b\\\'diff --git a/.DS_Store b/.DS_Store\\\\nindex 8d5060d..fe6e40b 100644\\\\nBinary files a/.DS_Store and b/.DS_Store differ\\\\ndiff --git a/app-gui.py b/app-gui.py\\\\nindex 107ede6..205d5c5 100644\\\\n--- a/app-gui.py\\\\n+++ b/app-gui.py\\\\n@@ -1,3 +1,6 @@\\\\n+import pickle\\\\r\\\\n+import facenet.src.facenet as facenet\\\\r\\\\n+import argparse\\\\r\\\\n from Detector import main_app\\\\r\\\\n from create_classifier import train_classifer, regFaces\\\\r\\\\n from create_dataset import start_capture\\\\r\\\\n@@ -9,6 +12,9 @@ import cv2\\\\n import os\\\\r\\\\n import imutils\\\\r\\\\n from Helper.align import detect_face\\\\r\\\\n+import datetime\\\\r\\\\n+import pytz\\\\r\\\\n+from datetime import timedelta\\\\r\\\\n \\\\r\\\\n import tensorflow as tf\\\\r\\\\n from imutils.video import VideoStream\\\\r\\\\n@@ -16,14 +22,17 @@ import numpy as np\\\\n import random\\\\r\\\\n import time\\\\r\\\\n import serial\\\\r\\\\n+import firebase_admin\\\\r\\\\n+from firebase_admin import credentials, firestore\\\\r\\\\n \\\\r\\\\n-import argparse\\\\r\\\\n-import facenet.src.facenet as facenet\\\\r\\\\n-import pickle\\\\r\\\\n \\\\r\\\\n-# from PIL import ImageTk, Image\\\\r\\\\n-# from gender_prediction import emotion,ageAndgender\\\\r\\\\n+cred = credentials.Certificate(\\\\r\\\\n+    "key/attendace-sys-firebase-adminsdk-e2nde-ea40d5feeb.json")\\\\r\\\\n+firebase_admin.initialize_app(cred)\\\\r\\\\n+\\\\r\\\\n names = set()\\\\r\\\\n+db = firestore.client()\\\\r\\\\n+utc = pytz.UTC\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class MainUI(tk.Tk):\\\\r\\\\n@@ -182,11 +191,48 @@ class PageTwo(tk.Frame):\\\\n         tk.Frame.__init__(self, parent)\\\\r\\\\n         self.controller = controller\\\\r\\\\n \\\\r\\\\n+        # def deleteDB(msg):\\\\r\\\\n+        #     print(\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\')\\\\r\\\\n+        #     with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\r\\\\n+        #         time.sleep(0.1)  # wait for serial to open\\\\r\\\\n+        #         if arduino.isOpen():\\\\r\\\\n+        #             print("{} connected!".format(arduino.port))\\\\r\\\\n+        #             try:\\\\r\\\\n+        #                 while True:\\\\r\\\\n+        #                     time.sleep(0.5)  # wait for arduino to answer\\\\r\\\\n+        #                     answer = arduino.readline()\\\\r\\\\n+        #                     print(answer)\\\\r\\\\n+        #                     if answer == b\\\\\\\'sensor templates\\\\\\\':\\\\r\\\\n+        #                         arduino.write(str(msg).encode())\\\\r\\\\n+        #                     if answer == b\\\\\\\'success\\\\\\\':\\\\r\\\\n+        #                         # print(\\\\\\\'break\\\\\\\')\\\\r\\\\n+        #                         arduino.flushInput()\\\\r\\\\n+        #                         break\\\\r\\\\n+        #                     # arduino.flushInput()\\\\r\\\\n+        #             except KeyboardInterrupt:\\\\r\\\\n+        #                 print("KeyboardInterrupt has been caught.")\\\\r\\\\n+\\\\r\\\\n         color1 = \\\\\\\'#020f12\\\\\\\'\\\\r\\\\n         color2 = \\\\\\\'#05d7ff\\\\\\\'\\\\r\\\\n         color3 = \\\\\\\'#65e7ff\\\\\\\'\\\\r\\\\n         color4 = \\\\\\\'BLACK\\\\\\\'\\\\r\\\\n         color5 = \\\\\\\'YELLOW\\\\\\\'\\\\r\\\\n+        # self.buttoncanc = tk.Button(self,\\\\r\\\\n+        #                             background=color2,\\\\r\\\\n+        #                             foreground=color4,\\\\r\\\\n+        #                             activebackground=color3,\\\\r\\\\n+        #                             activeforeground=color4,\\\\r\\\\n+        #                             highlightthickness=2,\\\\r\\\\n+        #                             highlightbackground=color2,\\\\r\\\\n+        #                             width=15,\\\\r\\\\n+        #                             height=2,\\\\r\\\\n+        #                             border=0,\\\\r\\\\n+        #                             cursor=\\\\\\\'hand2\\\\\\\',\\\\r\\\\n+        #                             text="Empty Database",\\\\r\\\\n+        #                             font=(\\\\\\\'Arial\\\\\\\', 16, \\\\\\\'bold\\\\\\\'),\\\\r\\\\n+        #                             command=deleteDB(3))\\\\r\\\\n+        # self.buttoncanc.place(relx=0.5, rely=0.7, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+\\\\r\\\\n         self.buttoncanc = tk.Button(self,\\\\r\\\\n                                     background=color2,\\\\r\\\\n                                     foreground=color4,\\\\r\\\\n@@ -267,9 +313,9 @@ class PageThree(tk.Frame):\\\\n                     except KeyboardInterrupt:\\\\r\\\\n                         print("KeyboardInterrupt has been caught.")\\\\r\\\\n \\\\r\\\\n-        def arduino_enroll(msg):\\\\r\\\\n+        def arduino_enroll(msg, new_finger_id):\\\\r\\\\n             print(msg)\\\\r\\\\n-            print(fingerprint_id_entry.get())\\\\r\\\\n+            print(new_finger_id)\\\\r\\\\n             print(\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\')\\\\r\\\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\r\\\\n                 time.sleep(0.1)  # wait for serial to open\\\\r\\\\n@@ -280,13 +326,13 @@ class PageThree(tk.Frame):\\\\n                             time.sleep(0.5)  # wait for arduino to answer\\\\r\\\\n                             answer = arduino.readline()\\\\r\\\\n                             print(answer)\\\\r\\\\n-                            if answer == b\\\\\\\'Sensor contains 11 templates\\\\\\\\r\\\\\\\\n\\\\\\\':\\\\r\\\\n+                            if b"Sensor contains" in answer or b"doesn\\\\\\\'t" in answer:\\\\r\\\\n                                 arduino.write(str(msg).encode())\\\\r\\\\n                             if answer == b\\\\\\\'#id\\\\\\\\r\\\\\\\\n\\\\\\\':\\\\r\\\\n                                 # print(\\\\\\\'break\\\\\\\')\\\\r\\\\n                                 arduino.flushInput()\\\\r\\\\n                                 # cmd = str(input("Enter command : "))\\\\r\\\\n-                                cmd = str(fingerprint_id_entry.get())\\\\r\\\\n+                                cmd = str(new_finger_id)\\\\r\\\\n                                 arduino.write(str(cmd).encode())\\\\r\\\\n                                 while True:\\\\r\\\\n                                     answer = arduino.readline()\\\\r\\\\n@@ -295,6 +341,10 @@ class PageThree(tk.Frame):\\\\n                                         self.notify.config(\\\\r\\\\n                                             text=\\\\\\\'Take your finger out and Put it back\\\\\\\')\\\\r\\\\n                                     if answer == b\\\\\\\'Stored!\\\\\\\\r\\\\\\\\n\\\\\\\':\\\\r\\\\n+                                        db.collection(\\\\\\\'users\\\\\\\').document(\\\\r\\\\n+                                            student_code_entry.get()).set({\\\\\\\'finger_id\\\\\\\': str(new_finger_id)}, merge=True)\\\\r\\\\n+                                        db.collection(\\\\r\\\\n+                                            \\\\\\\'fingers\\\\\\\').document(\\\\\\\'id\\\\\\\').update({\\\\\\\'id\\\\\\\': new_finger_id + 1})\\\\r\\\\n                                         self.notify.config(\\\\r\\\\n                                             text=\\\\\\\'Successfully encode fingerprint\\\\\\\')\\\\r\\\\n                                         break\\\\r\\\\n@@ -306,11 +356,19 @@ class PageThree(tk.Frame):\\\\n \\\\r\\\\n         def start_enroll():\\\\r\\\\n             stop_enroll()\\\\r\\\\n-            self.notify.config(text=\\\\\\\'Loading.......\\\\\\\')\\\\r\\\\n-            self.notify.place(relx=0.5, rely=0.4, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n             global message\\\\r\\\\n             message == True\\\\r\\\\n-            arduino_enroll(2)\\\\r\\\\n+            result = db.collection(\\\\\\\'users\\\\\\\').document(\\\\r\\\\n+                student_code_entry.get()).get()\\\\r\\\\n+            if result.exists:\\\\r\\\\n+                new_finger_id = db.collection(\\\\\\\'fingers\\\\\\\').document(\\\\\\\'id\\\\\\\').get()\\\\r\\\\n+                new_finger_id = new_finger_id.to_dict()\\\\r\\\\n+                new_finger_id = new_finger_id[\\\\\\\'id\\\\\\\']\\\\r\\\\n+                arduino_enroll(2, new_finger_id)\\\\r\\\\n+            else:\\\\r\\\\n+                print(\\\\\\\'no match\\\\\\\')\\\\r\\\\n+                messagebox.showwarning(\\\\\\\'ALERT\\\\\\\', \\\\\\\'No Users Match\\\\\\\')\\\\r\\\\n+                return\\\\r\\\\n \\\\r\\\\n         def stop_enroll():\\\\r\\\\n             global message\\\\r\\\\n@@ -320,31 +378,24 @@ class PageThree(tk.Frame):\\\\n             self, text="Enter your student code to register new fingerprint")\\\\r\\\\n         label1.place(relx=0.5, rely=0.1, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n-        fingerprint_id_entry = tk.Entry(self)\\\\r\\\\n-        fingerprint_id_entry.place(relx=0.5, rely=0.2, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+        student_code_entry = tk.Entry(self)\\\\r\\\\n+        student_code_entry.place(relx=0.5, rely=0.2, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+\\\\r\\\\n+        label2 = tk.Label(\\\\r\\\\n+            self, text="Enter your fingerId")\\\\r\\\\n+        label2.place(relx=0.5, rely=0.3, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n         buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\\\r\\\\n                                 fg="#263942", command=start_enroll)\\\\r\\\\n-        buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+        buttoncanc2.place(relx=0.5, rely=0.5, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n         self.notify = tk.Label(\\\\r\\\\n             self, text="abc")\\\\r\\\\n-        self.notify.place(relx=0.5, rely=0.4, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+        self.notify.place(relx=0.5, rely=0.6, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n         buttoncanc1 = tk.Button(self, text="Cancel", bg="#ffffff",\\\\r\\\\n                                 fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\r\\\\n-        buttoncanc1.place(relx=0.5, rely=0.5, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n-\\\\r\\\\n-        # def initFingerprint():\\\\r\\\\n-        #     if message == True:\\\\r\\\\n-\\\\r\\\\n-        #         mode = int(input("Select mode detect"))\\\\r\\\\n-\\\\r\\\\n-        #         if mode == 1:\\\\r\\\\n-        #             arduino_detect(1)\\\\r\\\\n-\\\\r\\\\n-        #         if mode == 2:\\\\r\\\\n-        #             arduino_enroll(2)\\\\r\\\\n+        buttoncanc1.place(relx=0.5, rely=0.7, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n \\\\r\\\\n class PageDetectFingert(tk.Frame):\\\\r\\\\n@@ -359,7 +410,7 @@ class PageDetectFingert(tk.Frame):\\\\n         status = \\\\\\\'loading\\\\\\\'\\\\r\\\\n         self.controller = controller\\\\r\\\\n \\\\r\\\\n-        def arduino_detect(msg):\\\\r\\\\n+        def arduino_detect(msg, mode):\\\\r\\\\n             print(msg)\\\\r\\\\n             print(\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\')\\\\r\\\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\r\\\\n@@ -371,37 +422,78 @@ class PageDetectFingert(tk.Frame):\\\\n                             time.sleep(0.5)  # wait for arduino to answer\\\\r\\\\n                             answer = arduino.readline()\\\\r\\\\n                             print(answer)\\\\r\\\\n-                            if answer == b\\\\\\\'Sensor contains 12 templates\\\\\\\\r\\\\\\\\n\\\\\\\':\\\\r\\\\n+                            if b"doesn\\\\\\\'t" in answer:\\\\r\\\\n+                                messagebox.showinfo(\\\\r\\\\n+                                    "ALERT", "No fingerprint to detect")\\\\r\\\\n+                                break\\\\r\\\\n+                            if answer == b\\\\\\\'Sensor contains 14 templates\\\\\\\\r\\\\\\\\n\\\\\\\':\\\\r\\\\n                                 arduino.write(str(msg).encode())\\\\r\\\\n                                 while True:\\\\r\\\\n                                     answer = arduino.readline()\\\\r\\\\n                                     print(answer)\\\\r\\\\n-                                    if answer == b\\\\\\\'ok\\\\\\\':\\\\r\\\\n+                                    idText = b\\\\\\\'\\\\\\\'\\\\r\\\\n+                                    if b\\\\\\\'ID\\\\\\\' in answer:\\\\r\\\\n+                                        idText = answer\\\\r\\\\n+                                    if b\\\\\\\'ok\\\\\\\' in answer or b\\\\\\\'Unknown\\\\\\\' in answer:\\\\r\\\\n                                         self.notify1.config(\\\\r\\\\n                                             text=\\\\\\\'Successfully detect fingerprint\\\\\\\')\\\\r\\\\n-\\\\r\\\\n-                                        self.notify1.config(text="")\\\\r\\\\n+                                        finger_id = idText.decode(\\\\r\\\\n+                                            \\\\\\\'utf-8\\\\\\\').split("#")[1]\\\\r\\\\n+                                        print(finger_id)\\\\r\\\\n+                                        if finger_id != \\\\\\\'\\\\\\\':\\\\r\\\\n+                                            query = db.collection(\\\\\\\'users\\\\\\\').where(\\\\r\\\\n+                                                "finger_id", "==", finger_id).get()\\\\r\\\\n+                                            for doc in query:\\\\r\\\\n+                                                user = doc.to_dict()\\\\r\\\\n+                                                result = db.collection(\\\\r\\\\n+                                                    \\\\\\\'current_subject\\\\\\\').document(\\\\\\\'current\\\\\\\').get()\\\\r\\\\n+                                                result = result.to_dict()\\\\r\\\\n+                                                today = datetime.datetime.now()\\\\r\\\\n+                                                status = \\\\\\\'in_time\\\\\\\'\\\\r\\\\n+                                                if mode == 1:\\\\r\\\\n+                                                    time_compare = result[\\\\\\\'time_in\\\\\\\'] + \\\\\\\\\\\\r\\\\n+                                                        timedelta(hours=7)\\\\r\\\\n+                                                    if utc.localize(today) > time_compare:\\\\r\\\\n+                                                        status = \\\\\\\'vao_tre\\\\\\\'\\\\r\\\\n+                                                        print(\\\\\\\'vao_tre\\\\\\\')\\\\r\\\\n+                                                    else:\\\\r\\\\n+                                                        status = \\\\\\\'vao_dung_gio\\\\\\\'\\\\r\\\\n+                                                        print(\\\\\\\'vao dung gio\\\\\\\')\\\\r\\\\n+                                                    db.collection(\\\\\\\'check_in\\\\\\\').add(\\\\r\\\\n+                                                        {\\\\\\\'subject\\\\\\\': result[\\\\\\\'name\\\\\\\'], \\\\\\\'student_id\\\\\\\': user[\\\\\\\'student_id\\\\\\\'], \\\\\\\'student_name\\\\\\\': user[\\\\\\\'name\\\\\\\'], \\\\\\\'status\\\\\\\': status, \\\\\\\'type\\\\\\\': \\\\\\\'fingerprint_detect\\\\\\\', \\\\\\\'time_in\\\\\\\': today - timedelta(hours=7)})\\\\r\\\\n+                                                else:\\\\r\\\\n+                                                    time_compare = result[\\\\\\\'time_out\\\\\\\'] + \\\\\\\\\\\\r\\\\n+                                                        timedelta(hours=7)\\\\r\\\\n+                                                    if utc.localize(today) > time_compare:\\\\r\\\\n+                                                        status = \\\\\\\'ra_dung_gio\\\\\\\'\\\\r\\\\n+                                                        print(\\\\\\\'ra dung gio\\\\\\\')\\\\r\\\\n+                                                    else:\\\\r\\\\n+                                                        status = \\\\\\\'ra_som\\\\\\\'\\\\r\\\\n+                                                        print(\\\\\\\'ra som\\\\\\\')\\\\r\\\\n+\\\\r\\\\n+                                                    db.collection(\\\\\\\'check_out\\\\\\\').add(\\\\r\\\\n+                                                        {\\\\\\\'subject\\\\\\\': result[\\\\\\\'name\\\\\\\'], \\\\\\\'student_id\\\\\\\': user[\\\\\\\'student_id\\\\\\\'], \\\\\\\'student_name\\\\\\\': user[\\\\\\\'name\\\\\\\'], \\\\\\\'status\\\\\\\': status, \\\\\\\'type\\\\\\\': \\\\\\\'fingerprint_detect\\\\\\\', \\\\\\\'time_out\\\\\\\': today - timedelta(hours=7)})\\\\r\\\\n                                         break\\\\r\\\\n                                     # return answer\\\\r\\\\n                                 break\\\\r\\\\n                     except KeyboardInterrupt:\\\\r\\\\n                         print("KeyboardInterrupt has been caught.")\\\\r\\\\n \\\\r\\\\n-        def start_detect():\\\\r\\\\n+        def start_check_in():\\\\r\\\\n             stop_detect()\\\\r\\\\n             global status\\\\r\\\\n             status = \\\\\\\'Init Parameters\\\\\\\'\\\\r\\\\n             print(status)\\\\r\\\\n             global message\\\\r\\\\n             message == True\\\\r\\\\n-            arduino_detect(1)\\\\r\\\\n+            arduino_detect(1, 1)\\\\r\\\\n \\\\r\\\\n         def stop_detect():\\\\r\\\\n             global message\\\\r\\\\n             message == False\\\\r\\\\n \\\\r\\\\n-        buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\\\r\\\\n-                                fg="#263942", command=start_detect)\\\\r\\\\n+        buttoncanc2 = tk.Button(self, text="Finger Check In", bg="#ffffff",\\\\r\\\\n+                                fg="#263942", command=start_check_in)\\\\r\\\\n         buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n         self.notify1 = tk.Label(\\\\r\\\\n@@ -441,7 +533,9 @@ class PageTakeFace(tk.Frame):\\\\n             detector = cv2.CascadeClassifier(\\\\r\\\\n                 "./data/haarcascade_frontalface_default.xml")\\\\r\\\\n \\\\r\\\\n-            filepath = \\\\\\\'./data/student/raw/\\\\\\\' + stundent_id_entry.get()\\\\r\\\\n+            id = stundent_id_entry.get()\\\\r\\\\n+\\\\r\\\\n+            filepath = \\\\\\\'./data/student/raw/\\\\\\\' + id\\\\r\\\\n \\\\r\\\\n             isExist = os.path.exists(filepath)\\\\r\\\\n \\\\r\\\\n@@ -490,6 +584,8 @@ class PageTakeFace(tk.Frame):\\\\n                     if num_of_images == 21:\\\\r\\\\n                         stop_vid()\\\\r\\\\n                         num_of_images = 0\\\\r\\\\n+                        db.collection(\\\\\\\'users\\\\\\\').document(id).set(\\\\r\\\\n+                            {\\\\\\\'name\\\\\\\': first_name_entry.get(), \\\\\\\'student_id\\\\\\\': id, \\\\\\\'image_path\\\\\\\': filepath})\\\\r\\\\n                         messagebox.showinfo(\\\\r\\\\n                             "INSTRUCTIONS", "We captured 20 pic of your Face.")\\\\r\\\\n                         return \\\\\\\'ok\\\\\\\'\\\\r\\\\n@@ -607,9 +703,11 @@ class PageDetectFace(tk.Frame):\\\\n         global cap_detect\\\\r\\\\n         cap_detect = None\\\\r\\\\n         global count_unknown\\\\r\\\\n-        global detect_time\\\\r\\\\n         count_unknown = 0\\\\r\\\\n+        global detect_time\\\\r\\\\n         detect_time = 0\\\\r\\\\n+        global mode\\\\r\\\\n+        mode = 1\\\\r\\\\n         # student_id = \\\\\\\'_\\\\\\\'.join([\\\\\\\'student\\\\\\\', stundent_id_entry])\\\\r\\\\n \\\\r\\\\n         def detect_frame():\\\\r\\\\n@@ -624,7 +722,7 @@ class PageDetectFace(tk.Frame):\\\\n                     # frame = cap.read()\\\\r\\\\n                     frame = imutils.resize(frame, width=600)\\\\r\\\\n                     frame = cv2.flip(frame, 1)\\\\r\\\\n-                    rand_name = random.randint(0, 1000)\\\\r\\\\n+                    # rand_name = random.randint(0, 1000)\\\\r\\\\n                     bounding_boxes, _ = detect_face.detect_face(\\\\r\\\\n                         frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\r\\\\n                     faces_found = bounding_boxes.shape[0]\\\\r\\\\n@@ -676,11 +774,42 @@ class PageDetectFace(tk.Frame):\\\\n                                             1, (255, 255, 255), thickness=1, lineType=2)\\\\r\\\\n \\\\r\\\\n                                 file_name = best_name + ".jpg"\\\\r\\\\n-                                if detect_time == 3:\\\\r\\\\n+                                if detect_time == 2:\\\\r\\\\n                                     cv2.imwrite(os.path.join(\\\\r\\\\n                                         image_path, file_name), frame)\\\\r\\\\n                                     cv2.destroyAllWindows()\\\\r\\\\n-                                    print(\\\\\\\'complete detect\\\\\\\')\\\\r\\\\n+                                    result = db.collection(\\\\r\\\\n+                                        \\\\\\\'current_subject\\\\\\\').document(\\\\\\\'current\\\\\\\').get()\\\\r\\\\n+                                    result = result.to_dict()\\\\r\\\\n+                                    today = datetime.datetime.now()\\\\r\\\\n+                                    print(today)\\\\r\\\\n+                                    status = \\\\\\\'in_time\\\\\\\'\\\\r\\\\n+                                    global mode\\\\r\\\\n+                                    if mode == 1:\\\\r\\\\n+                                        time_compare = result[\\\\\\\'time_in\\\\\\\'] + \\\\\\\\\\\\r\\\\n+                                            timedelta(hours=7)\\\\r\\\\n+                                        print(time_compare)\\\\r\\\\n+                                        if utc.localize(today) > time_compare:\\\\r\\\\n+                                            status = \\\\\\\'vao_tre\\\\\\\'\\\\r\\\\n+                                            print(\\\\\\\'vao tre\\\\\\\')\\\\r\\\\n+                                        else:\\\\r\\\\n+                                            status = \\\\\\\'vao_dung_gio\\\\\\\'\\\\r\\\\n+                                            print(\\\\\\\'vao dung gio\\\\\\\')\\\\r\\\\n+                                        db.collection(\\\\\\\'check_in\\\\\\\').add(\\\\r\\\\n+                                            {\\\\\\\'subject\\\\\\\': result[\\\\\\\'name\\\\\\\'], \\\\\\\'student_id\\\\\\\': best_name, \\\\\\\'student_name\\\\\\\': \\\\\\\'name\\\\\\\', \\\\\\\'status\\\\\\\': status, \\\\\\\'type\\\\\\\': \\\\\\\'face_detect\\\\\\\', \\\\\\\'time_in\\\\\\\': today - timedelta(hours=7)})\\\\r\\\\n+                                        print(\\\\\\\'complete detect\\\\\\\')\\\\r\\\\n+                                    else:\\\\r\\\\n+                                        time_compare = result[\\\\\\\'time_out\\\\\\\'] + \\\\\\\\\\\\r\\\\n+                                            timedelta(hours=7)\\\\r\\\\n+                                        if utc.localize(today) > time_compare:\\\\r\\\\n+                                            status = \\\\\\\'ra_dung_gio\\\\\\\'\\\\r\\\\n+                                            print(\\\\\\\'ra dung gio\\\\\\\')\\\\r\\\\n+                                        else:\\\\r\\\\n+                                            status = \\\\\\\'ra_som\\\\\\\'\\\\r\\\\n+                                            print(\\\\\\\'ra som\\\\\\\')\\\\r\\\\n+                                        db.collection(\\\\\\\'check_out\\\\\\\').add(\\\\r\\\\n+                                            {\\\\\\\'subject\\\\\\\': result[\\\\\\\'name\\\\\\\'], \\\\\\\'student_id\\\\\\\': best_name, \\\\\\\'student_name\\\\\\\': \\\\\\\'name\\\\\\\', \\\\\\\'status\\\\\\\': status, \\\\\\\'type\\\\\\\': \\\\\\\'face_detect\\\\\\\', \\\\\\\'time_out\\\\\\\': today - timedelta(hours=7)})\\\\r\\\\n+                                        print(\\\\\\\'complete detect\\\\\\\')\\\\r\\\\n                                     time.sleep(1)\\\\r\\\\n                                     stop_detect()\\\\r\\\\n                                     detect_time = 0\\\\r\\\\n@@ -688,7 +817,6 @@ class PageDetectFace(tk.Frame):\\\\n \\\\r\\\\n                                 detect_time += 1\\\\r\\\\n                             else:\\\\r\\\\n-                                name = \\\\\\\'Unknown\\\\\\\'\\\\r\\\\n                                 print(\\\\\\\'Unknown\\\\\\\')\\\\r\\\\n                                 print(count_unknown)\\\\r\\\\n                                 if count_unknown == 20:\\\\r\\\\n@@ -716,11 +844,20 @@ class PageDetectFace(tk.Frame):\\\\n \\\\r\\\\n                 detect_widget.after(10, detect_frame)\\\\r\\\\n \\\\r\\\\n-        def start_detect():\\\\r\\\\n-            global cam_detect_on, cap_detect\\\\r\\\\n+        def start_check_in():\\\\r\\\\n+            global cam_detect_on, cap_detect, mode\\\\r\\\\n             stop_detect()\\\\r\\\\n             cam_detect_on = True\\\\r\\\\n             cap_detect = cv2.VideoCapture(1)\\\\r\\\\n+            mode = 1\\\\r\\\\n+            detect_frame()\\\\r\\\\n+\\\\r\\\\n+        def start_check_out():\\\\r\\\\n+            global cam_detect_on, cap_detect, mode\\\\r\\\\n+            stop_detect()\\\\r\\\\n+            cam_detect_on = True\\\\r\\\\n+            cap_detect = cv2.VideoCapture(1)\\\\r\\\\n+            mode = 2\\\\r\\\\n             detect_frame()\\\\r\\\\n \\\\r\\\\n         def stop_detect():\\\\r\\\\n@@ -743,10 +880,14 @@ class PageDetectFace(tk.Frame):\\\\n                                 fg="#263942", command=stop_detect)\\\\r\\\\n         buttoncanc3.place(relx=0.5, rely=0.3, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n-        buttoncanc2 = tk.Button(self, text="Detect", bg="#ffffff",\\\\r\\\\n-                                fg="#263942", command=start_detect)\\\\r\\\\n+        buttoncanc2 = tk.Button(self, text="Face Check In", bg="#ffffff",\\\\r\\\\n+                                fg="#263942", command=start_check_in)\\\\r\\\\n         buttoncanc2.place(relx=0.5, rely=0.1, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\n+        buttoncanc2 = tk.Button(self, text="Face Check Out", bg="#ffffff",\\\\r\\\\n+                                fg="#263942", command=start_check_out)\\\\r\\\\n+        buttoncanc2.place(relx=0.5, rely=0.2, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n+\\\\r\\\\n         detect_widget = tk.Label(self)\\\\r\\\\n         detect_widget.place(relx=0.5, rely=0.7, anchor=\\\\\\\'center\\\\\\\')\\\\r\\\\n \\\\r\\\\ndiff --git a/data/bounding_boxes_1.png b/data/bounding_boxes_1.png\\\\nindex d5906f3..53fec3e 100644\\\\nBinary files a/data/bounding_boxes_1.png and b/data/bounding_boxes_1.png differ\\\\ndiff --git a/data/student/processed/1911368/0.png b/data/student/processed/1911368/0.png\\\\ndeleted file mode 100644\\\\nindex c051192..0000000\\\\nBinary files a/data/student/processed/1911368/0.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/1.png b/data/student/processed/1911368/1.png\\\\ndeleted file mode 100644\\\\nindex 99e5d28..0000000\\\\nBinary files a/data/student/processed/1911368/1.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/10.png b/data/student/processed/1911368/10.png\\\\ndeleted file mode 100644\\\\nindex df469d0..0000000\\\\nBinary files a/data/student/processed/1911368/10.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/11.png b/data/student/processed/1911368/11.png\\\\ndeleted file mode 100644\\\\nindex 20d1c4d..0000000\\\\nBinary files a/data/student/processed/1911368/11.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/12.png b/data/student/processed/1911368/12.png\\\\ndeleted file mode 100644\\\\nindex 088ec3b..0000000\\\\nBinary files a/data/student/processed/1911368/12.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/13.png b/data/student/processed/1911368/13.png\\\\ndeleted file mode 100644\\\\nindex 0ca5dd8..0000000\\\\nBinary files a/data/student/processed/1911368/13.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/14.png b/data/student/processed/1911368/14.png\\\\ndeleted file mode 100644\\\\nindex 62952ad..0000000\\\\nBinary files a/data/student/processed/1911368/14.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/15.png b/data/student/processed/1911368/15.png\\\\ndeleted file mode 100644\\\\nindex a8e62c6..0000000\\\\nBinary files a/data/student/processed/1911368/15.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/16.png b/data/student/processed/1911368/16.png\\\\ndeleted file mode 100644\\\\nindex c260216..0000000\\\\nBinary files a/data/student/processed/1911368/16.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/17.png b/data/student/processed/1911368/17.png\\\\ndeleted file mode 100644\\\\nindex 380bafb..0000000\\\\nBinary files a/data/student/processed/1911368/17.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/18.png b/data/student/processed/1911368/18.png\\\\ndeleted file mode 100644\\\\nindex 0c561fd..0000000\\\\nBinary files a/data/student/processed/1911368/18.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/19.png b/data/student/processed/1911368/19.png\\\\ndeleted file mode 100644\\\\nindex 5e31f0c..0000000\\\\nBinary files a/data/student/processed/1911368/19.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/2.png b/data/student/processed/1911368/2.png\\\\ndeleted file mode 100644\\\\nindex 36d8db6..0000000\\\\nBinary files a/data/student/processed/1911368/2.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/3.png b/data/student/processed/1911368/3.png\\\\ndeleted file mode 100644\\\\nindex f4b183a..0000000\\\\nBinary files a/data/student/processed/1911368/3.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/4.png b/data/student/processed/1911368/4.png\\\\ndeleted file mode 100644\\\\nindex 218248d..0000000\\\\nBinary files a/data/student/processed/1911368/4.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/5.png b/data/student/processed/1911368/5.png\\\\ndeleted file mode 100644\\\\nindex e531ba3..0000000\\\\nBinary files a/data/student/processed/1911368/5.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/6.png b/data/student/processed/1911368/6.png\\\\ndeleted file mode 100644\\\\nindex 02041a3..0000000\\\\nBinary files a/data/student/processed/1911368/6.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/7.png b/data/student/processed/1911368/7.png\\\\ndeleted file mode 100644\\\\nindex 000e3f9..0000000\\\\nBinary files a/data/student/processed/1911368/7.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/8.png b/data/student/processed/1911368/8.png\\\\ndeleted file mode 100644\\\\nindex 777fd4f..0000000\\\\nBinary files a/data/student/processed/1911368/8.png and /dev/null differ\\\\ndiff --git a/data/student/processed/1911368/9.png b/data/student/processed/1911368/9.png\\\\ndeleted file mode 100644\\\\nindex b4b589e..0000000\\\\nBinary files a/data/student/processed/1911368/9.png and /dev/null differ\\\\ndiff --git a/data/student/processed/revision_info.txt b/data/student/processed/revision_info.txt\\\\nindex 0cbd5a1..c8416ab 100644\\\\n--- a/data/student/processed/revision_info.txt\\\\n+++ b/data/student/processed/revision_info.txt\\\\n@@ -2,6 +2,6 @@ arguments: app-gui.py\\\\n --------------------\\\\n tensorflow version: 2.11.0\\\\n --------------------\\\\n-git hash: b\\\\\\\'9c81e69fd384d2ef884820592d4d0392b9fe5090\\\\\\\'\\\\n+git hash: b\\\\\\\'327e78b08956ac731a903cc76880b0ad4074195d\\\\\\\'\\\\n --------------------\\\\n-b\\\\\\\'diff --git a/Detector.py b/Detector.py\\\\\\\\nindex 4db826c..0896348 100644\\\\\\\\n--- a/Detector.py\\\\\\\\n+++ b/Detector.py\\\\\\\\n@@ -7,7 +7,7 @@ def main_app(name):\\\\\\\\n         face_cascade = cv2.CascadeClassifier(\\\\\\\\\\\\\\\'./data/haarcascade_frontalface_default.xml\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n         recognizer = cv2.face.LBPHFaceRecognizer_create()\\\\\\\\r\\\\\\\\n         recognizer.read(f"./data/classifiers/{name}_classifier.xml")\\\\\\\\r\\\\\\\\n-        cap = cv2.VideoCapture(0)\\\\\\\\r\\\\\\\\n+        cap = cv2.VideoCapture(1)\\\\\\\\r\\\\\\\\n         pred = 0\\\\\\\\r\\\\\\\\n         while True:\\\\\\\\r\\\\\\\\n             ret, frame = cap.read()\\\\\\\\r\\\\\\\\ndiff --git a/app-gui.py b/app-gui.py\\\\\\\\nindex 0f64293..c53ccc6 100644\\\\\\\\n--- a/app-gui.py\\\\\\\\n+++ b/app-gui.py\\\\\\\\n@@ -1,11 +1,14 @@\\\\\\\\n from Detector import main_app\\\\\\\\r\\\\\\\\n-from create_classifier import train_classifer\\\\\\\\r\\\\\\\\n+from create_classifier import train_classifer, regFaces\\\\\\\\r\\\\\\\\n from create_dataset import start_capture\\\\\\\\r\\\\\\\\n import tkinter as tk\\\\\\\\r\\\\\\\\n from tkinter import font as tkfont\\\\\\\\r\\\\\\\\n-from tkinter import messagebox,PhotoImage\\\\\\\\r\\\\\\\\n-#from PIL import ImageTk, Image\\\\\\\\r\\\\\\\\n-#from gender_prediction import emotion,ageAndgender\\\\\\\\r\\\\\\\\n+from tkinter import messagebox, PhotoImage\\\\\\\\r\\\\\\\\n+from PIL import Image, ImageTk\\\\\\\\r\\\\\\\\n+import cv2\\\\\\\\r\\\\\\\\n+import os\\\\\\\\r\\\\\\\\n+# from PIL import ImageTk, Image\\\\\\\\r\\\\\\\\n+# from gender_prediction import emotion,ageAndgender\\\\\\\\r\\\\\\\\n names = set()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n@@ -14,23 +17,34 @@ class MainUI(tk.Tk):\\\\\\\\n     def __init__(self, *args, **kwargs):\\\\\\\\r\\\\\\\\n         tk.Tk.__init__(self, *args, **kwargs)\\\\\\\\r\\\\\\\\n         global names\\\\\\\\r\\\\\\\\n+        global open_webcam\\\\\\\\r\\\\\\\\n+        open_webcam = \\\\\\\\\\\\\\\'false\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         with open("nameslist.txt", "r") as f:\\\\\\\\r\\\\\\\\n             x = f.read()\\\\\\\\r\\\\\\\\n             z = x.rstrip().split(" ")\\\\\\\\r\\\\\\\\n             for i in z:\\\\\\\\r\\\\\\\\n                 names.add(i)\\\\\\\\r\\\\\\\\n-        self.title_font = tkfont.Font(family=\\\\\\\\\\\\\\\'Helvetica\\\\\\\\\\\\\\\', size=16, weight="bold")\\\\\\\\r\\\\\\\\n+        self.title_font = tkfont.Font(\\\\\\\\r\\\\\\\\n+            family=\\\\\\\\\\\\\\\'Helvetica\\\\\\\\\\\\\\\', size=16, weight="bold")\\\\\\\\r\\\\\\\\n         self.title("Face Recognizer")\\\\\\\\r\\\\\\\\n         self.resizable(False, False)\\\\\\\\r\\\\\\\\n-        self.geometry("500x250")\\\\\\\\r\\\\\\\\n+        app_width = 1200\\\\\\\\r\\\\\\\\n+        app_height = 600\\\\\\\\r\\\\\\\\n+        screen_width = self.winfo_screenwidth()\\\\\\\\r\\\\\\\\n+        screen_height = self.winfo_screenheight()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        x = (screen_width / 2) - (app_width / 2)\\\\\\\\r\\\\\\\\n+        y = (screen_height / 2) - (app_height / 2)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        self.geometry(f\\\\\\\\\\\\\\\'{app_width}x{app_height}+{int(x)}+{int(y)}\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n         self.protocol("WM_DELETE_WINDOW", self.on_closing)\\\\\\\\r\\\\\\\\n         self.active_name = None\\\\\\\\r\\\\\\\\n         container = tk.Frame(self)\\\\\\\\r\\\\\\\\n-        container.grid(sticky="nsew")\\\\\\\\r\\\\\\\\n+        container.place(relx=0.5, rely=0.5, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n         container.grid_rowconfigure(0, weight=1)\\\\\\\\r\\\\\\\\n         container.grid_columnconfigure(0, weight=1)\\\\\\\\r\\\\\\\\n         self.frames = {}\\\\\\\\r\\\\\\\\n-        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour):\\\\\\\\r\\\\\\\\n+        for F in (StartPage, PageOne, PageTwo, PageThree, PageFour, PageTakeFace):\\\\\\\\r\\\\\\\\n             page_name = F.__name__\\\\\\\\r\\\\\\\\n             frame = F(parent=container, controller=self)\\\\\\\\r\\\\\\\\n             self.frames[page_name] = frame\\\\\\\\r\\\\\\\\n@@ -38,76 +52,100 @@ class MainUI(tk.Tk):\\\\\\\\n         self.show_frame("StartPage")\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     def show_frame(self, page_name):\\\\\\\\r\\\\\\\\n-            frame = self.frames[page_name]\\\\\\\\r\\\\\\\\n-            frame.tkraise()\\\\\\\\r\\\\\\\\n+        frame = self.frames[page_name]\\\\\\\\r\\\\\\\\n+        frame.tkraise()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     def on_closing(self):\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         if messagebox.askokcancel("Quit", "Are you sure?"):\\\\\\\\r\\\\\\\\n             global names\\\\\\\\r\\\\\\\\n-            f =  open("nameslist.txt", "a+")\\\\\\\\r\\\\\\\\n+            f = open("nameslist.txt", "a+")\\\\\\\\r\\\\\\\\n             for i in names:\\\\\\\\r\\\\\\\\n-                    f.write(i+" ")\\\\\\\\r\\\\\\\\n+                f.write(i+" ")\\\\\\\\r\\\\\\\\n             self.destroy()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class StartPage(tk.Frame):\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        def __init__(self, parent, controller):\\\\\\\\r\\\\\\\\n-            tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n-            self.controller = controller\\\\\\\\r\\\\\\\\n-            #load = Image.open("homepagepic.png")\\\\\\\\r\\\\\\\\n-            #load = load.resize((250, 250), Image.ANTIALIAS)\\\\\\\\r\\\\\\\\n-            render = PhotoImage(file=\\\\\\\\\\\\\\\'homepagepic.png\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-            img = tk.Label(self, image=render)\\\\\\\\r\\\\\\\\n-            img.image = render\\\\\\\\r\\\\\\\\n-            img.grid(row=0, column=1, rowspan=4, sticky="nsew")\\\\\\\\r\\\\\\\\n-            label = tk.Label(self, text="        Home Page        ", font=self.controller.title_font,fg="#263942")\\\\\\\\r\\\\\\\\n-            label.grid(row=0, sticky="ew")\\\\\\\\r\\\\\\\\n-            button1 = tk.Button(self, text="   Add a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageOne"))\\\\\\\\r\\\\\\\\n-            button2 = tk.Button(self, text="   Check a User  ", fg="#ffffff", bg="#263942",command=lambda: self.controller.show_frame("PageTwo"))\\\\\\\\r\\\\\\\\n-            button3 = tk.Button(self, text="Quit", fg="#263942", bg="#ffffff", command=self.on_closing)\\\\\\\\r\\\\\\\\n-            button1.grid(row=1, column=0, ipady=3, ipadx=7)\\\\\\\\r\\\\\\\\n-            button2.grid(row=2, column=0, ipady=3, ipadx=2)\\\\\\\\r\\\\\\\\n-            button3.grid(row=3, column=0, ipady=3, ipadx=32)\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-        def on_closing(self):\\\\\\\\r\\\\\\\\n-            if messagebox.askokcancel("Quit", "Are you sure?"):\\\\\\\\r\\\\\\\\n-                global names\\\\\\\\r\\\\\\\\n-                with open("nameslist.txt", "w") as f:\\\\\\\\r\\\\\\\\n-                    for i in names:\\\\\\\\r\\\\\\\\n-                        f.write(i + " ")\\\\\\\\r\\\\\\\\n-                self.controller.destroy()\\\\\\\\r\\\\\\\\n+    def __init__(self, parent, controller):\\\\\\\\r\\\\\\\\n+        tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n+        self.controller = controller\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        load1 = Image.open("Touch_ID.png")\\\\\\\\r\\\\\\\\n+        load1 = load1.resize((250, 250), Image.ANTIALIAS)\\\\\\\\r\\\\\\\\n+        render1 = PhotoImage(file=\\\\\\\\\\\\\\\'Touch_ID.png\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        render1 = ImageTk.PhotoImage(Image.open(\\\\\\\\r\\\\\\\\n+            "Touch_ID.png").resize((250, 250), Image.ANTIALIAS))\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        button4 = tk.Button(\\\\\\\\r\\\\\\\\n+            self, image=render1)\\\\\\\\r\\\\\\\\n+        button4.image = render1\\\\\\\\r\\\\\\\\n+        button4.grid(row=0, column=0, rowspan=4,\\\\\\\\r\\\\\\\\n+                     padx=10, pady=12, sticky="nsew")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        load2 = Image.open("face-id-id.png")\\\\\\\\r\\\\\\\\n+        load2 = load2.resize((50, 50), Image.ANTIALIAS)\\\\\\\\r\\\\\\\\n+        render2 = PhotoImage(file=\\\\\\\\\\\\\\\'face-id-id.png\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        render2 = ImageTk.PhotoImage(Image.open(\\\\\\\\r\\\\\\\\n+            "face-id-id.png").resize((250, 250), Image.ANTIALIAS))\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        button5 = tk.Button(\\\\\\\\r\\\\\\\\n+            self, image=render2, command=lambda: self.controller.show_frame("PageOne"))\\\\\\\\r\\\\\\\\n+        button5.image = render2\\\\\\\\r\\\\\\\\n+        button5.grid(row=1, column=1, rowspan=4,\\\\\\\\r\\\\\\\\n+                     padx=10, pady=12, sticky="nsew")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+    def on_closing(self):\\\\\\\\r\\\\\\\\n+        if messagebox.askokcancel("Quit", "Are you sure?"):\\\\\\\\r\\\\\\\\n+            global names\\\\\\\\r\\\\\\\\n+            with open("nameslist.txt", "w") as f:\\\\\\\\r\\\\\\\\n+                for i in names:\\\\\\\\r\\\\\\\\n+                    f.write(i + " ")\\\\\\\\r\\\\\\\\n+            self.controller.destroy()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class PageOne(tk.Frame):\\\\\\\\r\\\\\\\\n     def __init__(self, parent, controller):\\\\\\\\r\\\\\\\\n         tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n-        tk.Label(self, text="Enter the name", fg="#263942", font=\\\\\\\\\\\\\\\'Helvetica 12 bold\\\\\\\\\\\\\\\').grid(row=0, column=0, pady=10, padx=5)\\\\\\\\r\\\\\\\\n-        self.user_name = tk.Entry(self, borderwidth=3, bg="lightgrey", font=\\\\\\\\\\\\\\\'Helvetica 11\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-        self.user_name.grid(row=0, column=1, pady=10, padx=10)\\\\\\\\r\\\\\\\\n-        self.buttoncanc = tk.Button(self, text="Cancel", bg="#ffffff", fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\\\\\r\\\\\\\\n-        self.buttonext = tk.Button(self, text="Next", fg="#ffffff", bg="#263942", command=self.start_training)\\\\\\\\r\\\\\\\\n-        self.buttoncanc.grid(row=1, column=0, pady=10, ipadx=5, ipady=4)\\\\\\\\r\\\\\\\\n-        self.buttonext.grid(row=1, column=1, pady=10, ipadx=5, ipady=4)\\\\\\\\r\\\\\\\\n-    def start_training(self):\\\\\\\\r\\\\\\\\n-        global names\\\\\\\\r\\\\\\\\n-        if self.user_name.get() == "None":\\\\\\\\r\\\\\\\\n-            messagebox.showerror("Error", "Name cannot be \\\\\\\\\\\\\\\'None\\\\\\\\\\\\\\\'")\\\\\\\\r\\\\\\\\n-            return\\\\\\\\r\\\\\\\\n-        elif self.user_name.get() in names:\\\\\\\\r\\\\\\\\n-            messagebox.showerror("Error", "User already exists!")\\\\\\\\r\\\\\\\\n-            return\\\\\\\\r\\\\\\\\n-        elif len(self.user_name.get()) == 0:\\\\\\\\r\\\\\\\\n-            messagebox.showerror("Error", "Name cannot be empty!")\\\\\\\\r\\\\\\\\n-            return\\\\\\\\r\\\\\\\\n-        name = self.user_name.get()\\\\\\\\r\\\\\\\\n-        names.add(name)\\\\\\\\r\\\\\\\\n-        self.controller.active_name = name\\\\\\\\r\\\\\\\\n-        self.controller.frames["PageTwo"].refresh_names()\\\\\\\\r\\\\\\\\n-        self.controller.show_frame("PageThree")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        color1 = \\\\\\\\\\\\\\\'#020f12\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        color2 = \\\\\\\\\\\\\\\'#05d7ff\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        color3 = \\\\\\\\\\\\\\\'#65e7ff\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        color4 = \\\\\\\\\\\\\\\'BLACK\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        color5 = \\\\\\\\\\\\\\\'YELLOW\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        self.buttoncanc = tk.Button(self,\\\\\\\\r\\\\\\\\n+                                    background=color2,\\\\\\\\r\\\\\\\\n+                                    foreground=color4,\\\\\\\\r\\\\\\\\n+                                    activebackground=color3,\\\\\\\\r\\\\\\\\n+                                    activeforeground=color4,\\\\\\\\r\\\\\\\\n+                                    highlightthickness=2,\\\\\\\\r\\\\\\\\n+                                    highlightbackground=color2,\\\\\\\\r\\\\\\\\n+                                    width=15,\\\\\\\\r\\\\\\\\n+                                    height=2,\\\\\\\\r\\\\\\\\n+                                    border=0,\\\\\\\\r\\\\\\\\n+                                    cursor=\\\\\\\\\\\\\\\'hand2\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+                                    text="Cancel",\\\\\\\\r\\\\\\\\n+                                    font=(\\\\\\\\\\\\\\\'Arial\\\\\\\\\\\\\\\', 16, \\\\\\\\\\\\\\\'bold\\\\\\\\\\\\\\\'),\\\\\\\\r\\\\\\\\n+                                    command=lambda: controller.show_frame("StartPage"))\\\\\\\\r\\\\\\\\n+        self.buttoncanc.place(relx=0.5, rely=0.5, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        self.buttonTakeFace = tk.Button(self,\\\\\\\\r\\\\\\\\n+                                        background=color2,\\\\\\\\r\\\\\\\\n+                                        foreground=color4,\\\\\\\\r\\\\\\\\n+                                        activebackground=color3,\\\\\\\\r\\\\\\\\n+                                        activeforeground=color4,\\\\\\\\r\\\\\\\\n+                                        highlightthickness=2,\\\\\\\\r\\\\\\\\n+                                        highlightbackground=color2,\\\\\\\\r\\\\\\\\n+                                        width=15,\\\\\\\\r\\\\\\\\n+                                        height=2,\\\\\\\\r\\\\\\\\n+                                        border=0,\\\\\\\\r\\\\\\\\n+                                        cursor=\\\\\\\\\\\\\\\'hand2\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+                                        text="Add new",\\\\\\\\r\\\\\\\\n+                                        font=(\\\\\\\\\\\\\\\'Arial\\\\\\\\\\\\\\\', 16, \\\\\\\\\\\\\\\'bold\\\\\\\\\\\\\\\'), command=lambda: controller.show_frame("PageTakeFace"))\\\\\\\\r\\\\\\\\n+        self.buttonTakeFace.place(relx=0.5, rely=0.3, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class PageTwo(tk.Frame):\\\\\\\\r\\\\\\\\n@@ -116,13 +154,16 @@ class PageTwo(tk.Frame):\\\\\\\\n         tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n         global names\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n-        tk.Label(self, text="Select user", fg="#263942", font=\\\\\\\\\\\\\\\'Helvetica 12 bold\\\\\\\\\\\\\\\').grid(row=0, column=0, padx=10, pady=10)\\\\\\\\r\\\\\\\\n-        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\\\\\\\r\\\\\\\\n+        tk.Label(self, text="Select user", fg="#263942", font=\\\\\\\\\\\\\\\'Helvetica 12 bold\\\\\\\\\\\\\\\').grid(\\\\\\\\r\\\\\\\\n+            row=0, column=0, padx=10, pady=10)\\\\\\\\r\\\\\\\\n+        self.buttoncanc = tk.Button(self, text="Cancel", command=lambda: controller.show_frame(\\\\\\\\r\\\\\\\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\\\\\\\r\\\\\\\\n         self.menuvar = tk.StringVar(self)\\\\\\\\r\\\\\\\\n         self.dropdown = tk.OptionMenu(self, self.menuvar, *names)\\\\\\\\r\\\\\\\\n         self.dropdown.config(bg="lightgrey")\\\\\\\\r\\\\\\\\n         self.dropdown["menu"].config(bg="lightgrey")\\\\\\\\r\\\\\\\\n-        self.buttonext = tk.Button(self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n+        self.buttonext = tk.Button(\\\\\\\\r\\\\\\\\n+            self, text="Next", command=self.nextfoo, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n         self.dropdown.grid(row=0, column=1, ipadx=8, padx=10, pady=10)\\\\\\\\r\\\\\\\\n         self.buttoncanc.grid(row=1, ipadx=5, ipady=4, column=0, pady=10)\\\\\\\\r\\\\\\\\n         self.buttonext.grid(row=1, ipadx=5, ipady=4, column=1, pady=10)\\\\\\\\r\\\\\\\\n@@ -139,34 +180,36 @@ class PageTwo(tk.Frame):\\\\\\\\n         self.menuvar.set(\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n         self.dropdown[\\\\\\\\\\\\\\\'menu\\\\\\\\\\\\\\\'].delete(0, \\\\\\\\\\\\\\\'end\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n         for name in names:\\\\\\\\r\\\\\\\\n-            self.dropdown[\\\\\\\\\\\\\\\'menu\\\\\\\\\\\\\\\'].add_command(label=name, command=tk._setit(self.menuvar, name))\\\\\\\\r\\\\\\\\n+            self.dropdown[\\\\\\\\\\\\\\\'menu\\\\\\\\\\\\\\\'].add_command(\\\\\\\\r\\\\\\\\n+                label=name, command=tk._setit(self.menuvar, name))\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class PageThree(tk.Frame):\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     def __init__(self, parent, controller):\\\\\\\\r\\\\\\\\n         tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n-        self.numimglabel = tk.Label(self, text="Number of images captured = 0", font=\\\\\\\\\\\\\\\'Helvetica 12 bold\\\\\\\\\\\\\\\', fg="#263942")\\\\\\\\r\\\\\\\\n-        self.numimglabel.grid(row=0, column=0, columnspan=2, sticky="ew", pady=10)\\\\\\\\r\\\\\\\\n-        self.capturebutton = tk.Button(self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\\\\\\\r\\\\\\\\n-        self.trainbutton = tk.Button(self, text="Train The Model", fg="#ffffff", bg="#263942",command=self.trainmodel)\\\\\\\\r\\\\\\\\n-        self.capturebutton.grid(row=1, column=0, ipadx=5, ipady=4, padx=10, pady=20)\\\\\\\\r\\\\\\\\n-        self.trainbutton.grid(row=1, column=1, ipadx=5, ipady=4, padx=10, pady=20)\\\\\\\\r\\\\\\\\n+        self.numimglabel = tk.Label(\\\\\\\\r\\\\\\\\n+            self, text="Number of images captured = 0", font=\\\\\\\\\\\\\\\'Helvetica 12 bold\\\\\\\\\\\\\\\', fg="#263942")\\\\\\\\r\\\\\\\\n+        self.numimglabel.grid(\\\\\\\\r\\\\\\\\n+            row=0, column=0, columnspan=2, sticky="ew", pady=10)\\\\\\\\r\\\\\\\\n+        # self.capturebutton = tk.Button(\\\\\\\\r\\\\\\\\n+        #     self, text="Capture Data Set", fg="#ffffff", bg="#263942", command=self.capimg)\\\\\\\\r\\\\\\\\n+        # self.trainbutton = tk.Button(\\\\\\\\r\\\\\\\\n+        #     self, text="Train The Model", fg="#ffffff", bg="#263942", command=self.trainmodel)\\\\\\\\r\\\\\\\\n+        # self.capturebutton.grid(row=1, column=0, ipadx=5,\\\\\\\\r\\\\\\\\n+        #                         ipady=4, padx=10, pady=20)\\\\\\\\r\\\\\\\\n+        # self.trainbutton.grid(row=1, column=1, ipadx=5,\\\\\\\\r\\\\\\\\n+        #                       ipady=4, padx=10, pady=20)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     def capimg(self):\\\\\\\\r\\\\\\\\n         self.numimglabel.config(text=str("Captured Images = 0 "))\\\\\\\\r\\\\\\\\n-        messagebox.showinfo("INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\\\\\\\r\\\\\\\\n+        messagebox.showinfo(\\\\\\\\r\\\\\\\\n+            "INSTRUCTIONS", "We will Capture 300 pic of your Face.")\\\\\\\\r\\\\\\\\n         x = start_capture(self.controller.active_name)\\\\\\\\r\\\\\\\\n         self.controller.num_of_images = x\\\\\\\\r\\\\\\\\n-        self.numimglabel.config(text=str("Number of images captured = "+str(x)))\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-    def trainmodel(self):\\\\\\\\r\\\\\\\\n-        if self.controller.num_of_images < 300:\\\\\\\\r\\\\\\\\n-            messagebox.showerror("ERROR", "No enough Data, Capture at least 300 images!")\\\\\\\\r\\\\\\\\n-            return\\\\\\\\r\\\\\\\\n-        train_classifer(self.controller.active_name)\\\\\\\\r\\\\\\\\n-        messagebox.showinfo("SUCCESS", "The modele has been successfully trained!")\\\\\\\\r\\\\\\\\n-        self.controller.show_frame("PageFour")\\\\\\\\r\\\\\\\\n+        self.numimglabel.config(\\\\\\\\r\\\\\\\\n+            text=str("Number of images captured = "+str(x)))\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class PageFour(tk.Frame):\\\\\\\\r\\\\\\\\n@@ -175,27 +218,171 @@ class PageFour(tk.Frame):\\\\\\\\n         tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        label = tk.Label(self, text="Face Recognition", font=\\\\\\\\\\\\\\\'Helvetica 16 bold\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-        label.grid(row=0,column=0, sticky="ew")\\\\\\\\r\\\\\\\\n-        button1 = tk.Button(self, text="Face Recognition", command=self.openwebcam, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n-        #button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n-        #button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n-        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame("StartPage"), bg="#ffffff", fg="#263942")\\\\\\\\r\\\\\\\\n-        button1.grid(row=1,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n-        #button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n-        #button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n-        button4.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n+        label = tk.Label(self, text="Face Recognition",\\\\\\\\r\\\\\\\\n+                         font=\\\\\\\\\\\\\\\'Helvetica 16 bold\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        label.grid(row=0, column=0, sticky="ew")\\\\\\\\r\\\\\\\\n+        button1 = tk.Button(self, text="Face Recognition",\\\\\\\\r\\\\\\\\n+                            command=self.openwebcam, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n+        # button2 = tk.Button(self, text="Emotion Detection", command=self.emot, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n+        # button3 = tk.Button(self, text="Gender and Age Prediction", command=self.gender_age_pred, fg="#ffffff", bg="#263942")\\\\\\\\r\\\\\\\\n+        button4 = tk.Button(self, text="Go to Home Page", command=lambda: self.controller.show_frame(\\\\\\\\r\\\\\\\\n+            "StartPage"), bg="#ffffff", fg="#263942")\\\\\\\\r\\\\\\\\n+        button1.grid(row=1, column=0, sticky="ew",\\\\\\\\r\\\\\\\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n+        # button2.grid(row=1,column=1, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n+        # button3.grid(row=2,column=0, sticky="ew", ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n+        button4.grid(row=1, column=1, sticky="ew",\\\\\\\\r\\\\\\\\n+                     ipadx=5, ipady=4, padx=10, pady=10)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     def openwebcam(self):\\\\\\\\r\\\\\\\\n         main_app(self.controller.active_name)\\\\\\\\r\\\\\\\\n-    #def gender_age_pred(self):\\\\\\\\r\\\\\\\\n+    # def gender_age_pred(self):\\\\\\\\r\\\\\\\\n      #  ageAndgender()\\\\\\\\r\\\\\\\\n-    #def emot(self):\\\\\\\\r\\\\\\\\n+    # def emot(self):\\\\\\\\r\\\\\\\\n      #   emotion()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+num_of_images = 0\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+class PageTakeFace(tk.Frame):\\\\\\\\r\\\\\\\\n+    def __init__(self, parent, controller):\\\\\\\\r\\\\\\\\n+        tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n+        self.controller = controller\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        global cam_on\\\\\\\\r\\\\\\\\n+        cam_on = False\\\\\\\\r\\\\\\\\n+        global cap\\\\\\\\r\\\\\\\\n+        cap = None\\\\\\\\r\\\\\\\\n+        # student_id = \\\\\\\\\\\\\\\'_\\\\\\\\\\\\\\\'.join([\\\\\\\\\\\\\\\'student\\\\\\\\\\\\\\\', stundent_id_entry])\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        def display_frame():\\\\\\\\r\\\\\\\\n+            global cam_on\\\\\\\\r\\\\\\\\n+            global num_of_images\\\\\\\\r\\\\\\\\n+            detector = cv2.CascadeClassifier(\\\\\\\\r\\\\\\\\n+                "./data/haarcascade_frontalface_default.xml")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            filepath = \\\\\\\\\\\\\\\'./data/student/raw/\\\\\\\\\\\\\\\' + stundent_id_entry.get()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            isExist = os.path.exists(filepath)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            if not isExist:\\\\\\\\r\\\\\\\\n+                print(\\\\\\\\\\\\\\\'The new directory is created!\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                print(filepath)\\\\\\\\r\\\\\\\\n+                os.makedirs(filepath)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            if cam_on:\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                ret, frame = cap.read()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                if ret:\\\\\\\\r\\\\\\\\n+                    opencv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\\\\\\\\r\\\\\\\\n+                    filename = \\\\\\\\\\\\\\\'.\\\\\\\\\\\\\\\'.join([str(num_of_images), \\\\\\\\\\\\\\\'jpg\\\\\\\\\\\\\\\'])\\\\\\\\r\\\\\\\\n+                    path = os.path.join(filepath, filename)\\\\\\\\r\\\\\\\\n+                    cv2.imwrite(path, frame)\\\\\\\\r\\\\\\\\n+                    face = detector.detectMultiScale(\\\\\\\\r\\\\\\\\n+                        image=opencv_image, scaleFactor=1.1, minNeighbors=5)\\\\\\\\r\\\\\\\\n+                    for x, y, w, h in face:\\\\\\\\r\\\\\\\\n+                        cv2.rectangle(frame, (x, y),\\\\\\\\r\\\\\\\\n+                                      (x+w, y+h), (8, 238, 255), 2)\\\\\\\\r\\\\\\\\n+                        cv2.putText(frame, "Face Detected", (x, y-5),\\\\\\\\r\\\\\\\\n+                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\\\\\\\r\\\\\\\\n+                        cv2.putText(frame, str(str(num_of_images)+" images captured"),\\\\\\\\r\\\\\\\\n+                                    (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (8, 238, 255))\\\\\\\\r\\\\\\\\n+                        # new_img = frame[y:y+h, x:x+w]\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    # Capture the latest frame and transform to image\\\\\\\\r\\\\\\\\n+                    captured_image = Image.fromarray(\\\\\\\\r\\\\\\\\n+                        cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA))\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    # Convert captured image to photoimage\\\\\\\\r\\\\\\\\n+                    photo_image = ImageTk.PhotoImage(\\\\\\\\r\\\\\\\\n+                        captured_image.resize((500, 300), Image.ANTIALIAS))\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    # Displaying photoimage in the label\\\\\\\\r\\\\\\\\n+                    label_widget.photo_image = photo_image\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    # Configure image in the label\\\\\\\\r\\\\\\\\n+                    label_widget.configure(image=photo_image)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    # Repeat the same process after every 10 seconds\\\\\\\\r\\\\\\\\n+                    num_of_images += 1\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                    if num_of_images == 21:\\\\\\\\r\\\\\\\\n+                        stop_vid()\\\\\\\\r\\\\\\\\n+                        num_of_images = 0\\\\\\\\r\\\\\\\\n+                        messagebox.showinfo(\\\\\\\\r\\\\\\\\n+                            "INSTRUCTIONS", "We captured 20 pic of your Face.")\\\\\\\\r\\\\\\\\n+                        return \\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                label_widget.after(10, display_frame)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        def start_vid():\\\\\\\\r\\\\\\\\n+            global cam_on, cap\\\\\\\\r\\\\\\\\n+            stop_vid()\\\\\\\\r\\\\\\\\n+            cam_on = True\\\\\\\\r\\\\\\\\n+            cap = cv2.VideoCapture(1)\\\\\\\\r\\\\\\\\n+            display_frame()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        def stop_vid():\\\\\\\\r\\\\\\\\n+            label_widget.configure(image=None)\\\\\\\\r\\\\\\\\n+            label_widget.configure(image="")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            global cam_on\\\\\\\\r\\\\\\\\n+            cam_on = False\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            if cap:\\\\\\\\r\\\\\\\\n+                cap.release()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        def trainmodel():\\\\\\\\r\\\\\\\\n+            # if self.controller.num_of_images < 300:\\\\\\\\r\\\\\\\\n+            #     messagebox.showerror(\\\\\\\\r\\\\\\\\n+            #         "ERROR", "No enough Data, Capture at least 300 images!")\\\\\\\\r\\\\\\\\n+            #     return\\\\\\\\r\\\\\\\\n+            regFaces()\\\\\\\\r\\\\\\\\n+            messagebox.showinfo(\\\\\\\\r\\\\\\\\n+                "SUCCESS", "You can now implement your detection")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        ####### take face screen #######\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        user_info_frame = tk.LabelFrame(self, text="User Information")\\\\\\\\r\\\\\\\\n+        user_info_frame.grid(row=0, column=0, padx=20, pady=10)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        first_name_label = tk.Label(user_info_frame, text="Your Name")\\\\\\\\r\\\\\\\\n+        first_name_label.grid(row=0, column=0)\\\\\\\\r\\\\\\\\n+        student_id_label = tk.Label(user_info_frame, text="Your Student Id")\\\\\\\\r\\\\\\\\n+        student_id_label.grid(row=0, column=1)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        first_name_entry = tk.Entry(user_info_frame)\\\\\\\\r\\\\\\\\n+        stundent_id_entry = tk.Entry(user_info_frame)\\\\\\\\r\\\\\\\\n+        first_name_entry.grid(row=1, column=0)\\\\\\\\r\\\\\\\\n+        stundent_id_entry.grid(row=1, column=1)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        buttoncanc = tk.Button(user_info_frame, text="Cancel", bg="#ffffff",\\\\\\\\r\\\\\\\\n+                               fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\\\\\r\\\\\\\\n+        buttoncanc.grid(row=2, column=0, pady=10, ipadx=5, ipady=4)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        buttoncanc = tk.Button(user_info_frame, text="Confirm", bg="#ffffff",\\\\\\\\r\\\\\\\\n+                               fg="#263942", command=start_vid)\\\\\\\\r\\\\\\\\n+        buttoncanc.grid(row=2, column=1, pady=10, ipadx=5, ipady=4)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        label_widget = tk.Label(self)\\\\\\\\r\\\\\\\\n+        label_widget.grid(row=3, column=0)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        # age_label = tk.Label(user_info_frame, text="Age")\\\\\\\\r\\\\\\\\n+        # age_spinbox = tk.Spinbox(user_info_frame, from_=18, to=110)\\\\\\\\r\\\\\\\\n+        # age_label.grid(row=2, column=0)\\\\\\\\r\\\\\\\\n+        # age_spinbox.grid(row=3, column=0)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        for widget in user_info_frame.winfo_children():\\\\\\\\r\\\\\\\\n+            widget.grid_configure(padx=10, pady=5)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        button1 = tk.Button(self, text="Training Model",\\\\\\\\r\\\\\\\\n+                            command=trainmodel)\\\\\\\\r\\\\\\\\n+        button1.grid(row=8, column=0, padx=10,\\\\\\\\r\\\\\\\\n+                     pady=10, ipadx=5, ipady=4)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n app = MainUI()\\\\\\\\r\\\\\\\\n app.iconphoto(False, tk.PhotoImage(file=\\\\\\\\\\\\\\\'icon.ico\\\\\\\\\\\\\\\'))\\\\\\\\r\\\\\\\\n app.mainloop()\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\ndiff --git a/create_classifier.py b/create_classifier.py\\\\\\\\nindex a022cf5..9a16c5e 100644\\\\\\\\n--- a/create_classifier.py\\\\\\\\n+++ b/create_classifier.py\\\\\\\\n@@ -1,10 +1,60 @@\\\\\\\\n import numpy as np\\\\\\\\r\\\\\\\\n from PIL import Image\\\\\\\\r\\\\\\\\n-import os, cv2\\\\\\\\r\\\\\\\\n+import os\\\\\\\\r\\\\\\\\n+import cv2\\\\\\\\r\\\\\\\\n+from Helper.align_dataset_mtcnn import main\\\\\\\\r\\\\\\\\n+from Helper.classifier import mainTrain\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+def regFaces():\\\\\\\\r\\\\\\\\n+    input_dir = \\\\\\\\\\\\\\\'data/student/raw\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+    output_dir = \\\\\\\\\\\\\\\'data/student/processed\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+    image_size = 160\\\\\\\\r\\\\\\\\n+    margin = 32\\\\\\\\r\\\\\\\\n+    random_order = \\\\\\\\\\\\\\\'random_order\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+    gpu_memory_fraction = 0.25\\\\\\\\r\\\\\\\\n+    args = {\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'input_dir\\\\\\\\\\\\\\\': input_dir,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\': output_dir,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'image_size\\\\\\\\\\\\\\\': image_size,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'margin\\\\\\\\\\\\\\\': margin,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'random_order\\\\\\\\\\\\\\\': random_order,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'gpu_memory_fraction\\\\\\\\\\\\\\\': gpu_memory_fraction,\\\\\\\\r\\\\\\\\n+        \\\\\\\\\\\\\\\'detect_multiple_faces\\\\\\\\\\\\\\\': False\\\\\\\\r\\\\\\\\n+    }\\\\\\\\r\\\\\\\\n+    print(args[\\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\'])\\\\\\\\r\\\\\\\\n+    data = main(args)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+    if data == \\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+        startTraining(data)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+    # data = \\\\\\\\\\\\\\\'complete reg faces\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+    return\\\\\\\\r\\\\\\\\n # Method to train custom classifier to recognize face\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+def startTraining(data):\\\\\\\\r\\\\\\\\n+    os.remove(\\\\\\\\\\\\\\\'model/facemodel.pkl\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+    # message = request.form[\\\\\\\\\\\\\\\'status\\\\\\\\\\\\\\\']\\\\\\\\r\\\\\\\\n+    if data == \\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+        data_dir = \\\\\\\\\\\\\\\'data/student/processed\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        # test_data = \\\\\\\\\\\\\\\'backend/data/test/align\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        args = {\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'mode\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'TRAIN\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'data_dir\\\\\\\\\\\\\\\': data_dir,\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'model\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'model/20180402-114759.pb\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'classifier_filename\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'model/facemodel.pkl\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'use_split_dataset\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'batch_size\\\\\\\\\\\\\\\': 1000,\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'image_size\\\\\\\\\\\\\\\': 160,\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'seed\\\\\\\\\\\\\\\': 666,\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'min_nrof_images_per_class\\\\\\\\\\\\\\\': 20,\\\\\\\\r\\\\\\\\n+            \\\\\\\\\\\\\\\'nrof_train_images_per_class\\\\\\\\\\\\\\\': 15}\\\\\\\\r\\\\\\\\n+        mainTrain(args)\\\\\\\\r\\\\\\\\n+        data = \\\\\\\\\\\\\\\'complete trained\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        return\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n def train_classifer(name):\\\\\\\\r\\\\\\\\n     # Read all the images in custom data-set\\\\\\\\r\\\\\\\\n     path = os.path.join(os.getcwd()+"/data/"+name+"/")\\\\\\\\r\\\\\\\\n@@ -14,27 +64,24 @@ def train_classifer(name):\\\\\\\\n     labels = []\\\\\\\\r\\\\\\\\n     pictures = {}\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n     # Store images in a numpy format and ids of the user on the same index in imageNp and id lists\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-    for root,dirs,files in os.walk(path):\\\\\\\\r\\\\\\\\n-            pictures = files\\\\\\\\r\\\\\\\\n+    for root, dirs, files in os.walk(path):\\\\\\\\r\\\\\\\\n+        pictures = files\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+    for pic in pictures:\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-    for pic in pictures :\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-            imgpath = path+pic\\\\\\\\r\\\\\\\\n-            img = Image.open(imgpath).convert(\\\\\\\\\\\\\\\'L\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-            imageNp = np.array(img, \\\\\\\\\\\\\\\'uint8\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-            id = int(pic.split(name)[0])\\\\\\\\r\\\\\\\\n-            #names[name].append(id)\\\\\\\\r\\\\\\\\n-            faces.append(imageNp)\\\\\\\\r\\\\\\\\n-            ids.append(id)\\\\\\\\r\\\\\\\\n+        imgpath = path+pic\\\\\\\\r\\\\\\\\n+        img = Image.open(imgpath).convert(\\\\\\\\\\\\\\\'L\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        imageNp = np.array(img, \\\\\\\\\\\\\\\'uint8\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        id = int(pic.split(name)[0])\\\\\\\\r\\\\\\\\n+        # names[name].append(id)\\\\\\\\r\\\\\\\\n+        faces.append(imageNp)\\\\\\\\r\\\\\\\\n+        ids.append(id)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n     ids = np.array(ids)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-    #Train and save classifier\\\\\\\\r\\\\\\\\n+    # Train and save classifier\\\\\\\\r\\\\\\\\n     clf = cv2.face.LBPHFaceRecognizer_create()\\\\\\\\r\\\\\\\\n     clf.train(faces, ids)\\\\\\\\r\\\\\\\\n     clf.write("./data/classifiers/"+name+"_classifier.xml")\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\ndiff --git a/create_dataset.py b/create_dataset.py\\\\\\\\nindex 1fbeab1..fbc4f04 100644\\\\\\\\n--- a/create_dataset.py\\\\\\\\n+++ b/create_dataset.py\\\\\\\\n@@ -1,38 +1,41 @@\\\\\\\\n import cv2\\\\\\\\r\\\\\\\\n import os\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-def start_capture(name):\\\\\\\\r\\\\\\\\n-        path = "./data/" + name\\\\\\\\r\\\\\\\\n-        num_of_images = 0\\\\\\\\r\\\\\\\\n-        detector = cv2.CascadeClassifier("./data/haarcascade_frontalface_default.xml")\\\\\\\\r\\\\\\\\n-        try:\\\\\\\\r\\\\\\\\n-            os.makedirs(path)\\\\\\\\r\\\\\\\\n-        except:\\\\\\\\r\\\\\\\\n-            print(\\\\\\\\\\\\\\\'Directory Already Created\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-        vid = cv2.VideoCapture(0)\\\\\\\\r\\\\\\\\n-        while True:\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-            ret, img = vid.read()\\\\\\\\r\\\\\\\\n-            new_img = None\\\\\\\\r\\\\\\\\n-            grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\\\\\\\r\\\\\\\\n-            face = detector.detectMultiScale(image=grayimg, scaleFactor=1.1, minNeighbors=5)\\\\\\\\r\\\\\\\\n-            for x, y, w, h in face:\\\\\\\\r\\\\\\\\n-                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\\\\\\\r\\\\\\\\n-                cv2.putText(img, "Face Detected", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\\\\\r\\\\\\\\n-                cv2.putText(img, str(str(num_of_images)+" images captured"), (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\\\\\r\\\\\\\\n-                new_img = img[y:y+h, x:x+w]\\\\\\\\r\\\\\\\\n-            cv2.imshow("FaceDetection", img)\\\\\\\\r\\\\\\\\n-            key = cv2.waitKey(1) & 0xFF\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+def start_capture(name):\\\\\\\\r\\\\\\\\n+    path = "./data/" + name\\\\\\\\r\\\\\\\\n+    num_of_images = 0\\\\\\\\r\\\\\\\\n+    detector = cv2.CascadeClassifier(\\\\\\\\r\\\\\\\\n+        "./data/haarcascade_frontalface_default.xml")\\\\\\\\r\\\\\\\\n+    try:\\\\\\\\r\\\\\\\\n+        os.makedirs(path)\\\\\\\\r\\\\\\\\n+    except:\\\\\\\\r\\\\\\\\n+        print(\\\\\\\\\\\\\\\'Directory Already Created\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+    vid = cv2.VideoCapture(1)\\\\\\\\r\\\\\\\\n+    while True:\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-            try :\\\\\\\\r\\\\\\\\n-                cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\\\\\\\r\\\\\\\\n-                num_of_images += 1\\\\\\\\r\\\\\\\\n-            except :\\\\\\\\r\\\\\\\\n+        ret, img = vid.read()\\\\\\\\r\\\\\\\\n+        new_img = None\\\\\\\\r\\\\\\\\n+        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\\\\\\\r\\\\\\\\n+        face = detector.detectMultiScale(\\\\\\\\r\\\\\\\\n+            image=grayimg, scaleFactor=1.1, minNeighbors=5)\\\\\\\\r\\\\\\\\n+        for x, y, w, h in face:\\\\\\\\r\\\\\\\\n+            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\\\\\\\\r\\\\\\\\n+            cv2.putText(img, "Face Detected", (x, y-5),\\\\\\\\r\\\\\\\\n+                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\\\\\r\\\\\\\\n+            cv2.putText(img, str(str(num_of_images)+" images captured"),\\\\\\\\r\\\\\\\\n+                        (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255))\\\\\\\\r\\\\\\\\n+            new_img = img[y:y+h, x:x+w]\\\\\\\\r\\\\\\\\n+        cv2.imshow("FaceDetection", img)\\\\\\\\r\\\\\\\\n+        key = cv2.waitKey(1) & 0xFF\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-                pass\\\\\\\\r\\\\\\\\n-            if key == ord("q") or key == 27 or num_of_images > 310:\\\\\\\\r\\\\\\\\n-                break\\\\\\\\r\\\\\\\\n-        cv2.destroyAllWindows()\\\\\\\\r\\\\\\\\n-        return num_of_images\\\\\\\\r\\\\\\\\n+        try:\\\\\\\\r\\\\\\\\n+            cv2.imwrite(str(path+"/"+str(num_of_images)+name+".jpg"), new_img)\\\\\\\\r\\\\\\\\n+            num_of_images += 1\\\\\\\\r\\\\\\\\n+        except:\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+            pass\\\\\\\\r\\\\\\\\n+        if key == ord("q") or key == 27 or num_of_images > 10:\\\\\\\\r\\\\\\\\n+            break\\\\\\\\r\\\\\\\\n+    cv2.destroyAllWindows()\\\\\\\\r\\\\\\\\n+    return num_of_images\\\\\\\\r\\\\\\\\ndiff --git a/nameslist.txt b/nameslist.txt\\\\\\\\nindex e605024..5f8a285 100644\\\\\\\\n--- a/nameslist.txt\\\\\\\\n+++ b/nameslist.txt\\\\\\\\n@@ -1 +1 @@\\\\\\\\n-NO \\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\n+                                                                     \\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\n+b\\\\\\\'diff --git a/.DS_Store b/.DS_Store\\\\\\\\nindex 8d5060d..fe6e40b 100644\\\\\\\\nBinary files a/.DS_Store and b/.DS_Store differ\\\\\\\\ndiff --git a/app-gui.py b/app-gui.py\\\\\\\\nindex 107ede6..403b9a3 100644\\\\\\\\n--- a/app-gui.py\\\\\\\\n+++ b/app-gui.py\\\\\\\\n@@ -1,3 +1,6 @@\\\\\\\\n+import pickle\\\\\\\\r\\\\\\\\n+import facenet.src.facenet as facenet\\\\\\\\r\\\\\\\\n+import argparse\\\\\\\\r\\\\\\\\n from Detector import main_app\\\\\\\\r\\\\\\\\n from create_classifier import train_classifer, regFaces\\\\\\\\r\\\\\\\\n from create_dataset import start_capture\\\\\\\\r\\\\\\\\n@@ -9,6 +12,9 @@ import cv2\\\\\\\\n import os\\\\\\\\r\\\\\\\\n import imutils\\\\\\\\r\\\\\\\\n from Helper.align import detect_face\\\\\\\\r\\\\\\\\n+import datetime\\\\\\\\r\\\\\\\\n+import pytz\\\\\\\\r\\\\\\\\n+from datetime import timedelta\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n import tensorflow as tf\\\\\\\\r\\\\\\\\n from imutils.video import VideoStream\\\\\\\\r\\\\\\\\n@@ -16,14 +22,17 @@ import numpy as np\\\\\\\\n import random\\\\\\\\r\\\\\\\\n import time\\\\\\\\r\\\\\\\\n import serial\\\\\\\\r\\\\\\\\n+import firebase_admin\\\\\\\\r\\\\\\\\n+from firebase_admin import credentials, firestore\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-import argparse\\\\\\\\r\\\\\\\\n-import facenet.src.facenet as facenet\\\\\\\\r\\\\\\\\n-import pickle\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-# from PIL import ImageTk, Image\\\\\\\\r\\\\\\\\n-# from gender_prediction import emotion,ageAndgender\\\\\\\\r\\\\\\\\n+cred = credentials.Certificate(\\\\\\\\r\\\\\\\\n+    "key/attendace-sys-firebase-adminsdk-e2nde-ea40d5feeb.json")\\\\\\\\r\\\\\\\\n+firebase_admin.initialize_app(cred)\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n names = set()\\\\\\\\r\\\\\\\\n+db = firestore.client()\\\\\\\\r\\\\\\\\n+utc = pytz.UTC\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class MainUI(tk.Tk):\\\\\\\\r\\\\\\\\n@@ -182,11 +191,48 @@ class PageTwo(tk.Frame):\\\\\\\\n         tk.Frame.__init__(self, parent)\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+        # def deleteDB(msg):\\\\\\\\r\\\\\\\\n+        #     print(\\\\\\\\\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        #     with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\\\\\r\\\\\\\\n+        #         time.sleep(0.1)  # wait for serial to open\\\\\\\\r\\\\\\\\n+        #         if arduino.isOpen():\\\\\\\\r\\\\\\\\n+        #             print("{} connected!".format(arduino.port))\\\\\\\\r\\\\\\\\n+        #             try:\\\\\\\\r\\\\\\\\n+        #                 while True:\\\\\\\\r\\\\\\\\n+        #                     time.sleep(0.5)  # wait for arduino to answer\\\\\\\\r\\\\\\\\n+        #                     answer = arduino.readline()\\\\\\\\r\\\\\\\\n+        #                     print(answer)\\\\\\\\r\\\\\\\\n+        #                     if answer == b\\\\\\\\\\\\\\\'sensor templates\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+        #                         arduino.write(str(msg).encode())\\\\\\\\r\\\\\\\\n+        #                     if answer == b\\\\\\\\\\\\\\\'success\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+        #                         # print(\\\\\\\\\\\\\\\'break\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        #                         arduino.flushInput()\\\\\\\\r\\\\\\\\n+        #                         break\\\\\\\\r\\\\\\\\n+        #                     # arduino.flushInput()\\\\\\\\r\\\\\\\\n+        #             except KeyboardInterrupt:\\\\\\\\r\\\\\\\\n+        #                 print("KeyboardInterrupt has been caught.")\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n         color1 = \\\\\\\\\\\\\\\'#020f12\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         color2 = \\\\\\\\\\\\\\\'#05d7ff\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         color3 = \\\\\\\\\\\\\\\'#65e7ff\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         color4 = \\\\\\\\\\\\\\\'BLACK\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         color5 = \\\\\\\\\\\\\\\'YELLOW\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+        # self.buttoncanc = tk.Button(self,\\\\\\\\r\\\\\\\\n+        #                             background=color2,\\\\\\\\r\\\\\\\\n+        #                             foreground=color4,\\\\\\\\r\\\\\\\\n+        #                             activebackground=color3,\\\\\\\\r\\\\\\\\n+        #                             activeforeground=color4,\\\\\\\\r\\\\\\\\n+        #                             highlightthickness=2,\\\\\\\\r\\\\\\\\n+        #                             highlightbackground=color2,\\\\\\\\r\\\\\\\\n+        #                             width=15,\\\\\\\\r\\\\\\\\n+        #                             height=2,\\\\\\\\r\\\\\\\\n+        #                             border=0,\\\\\\\\r\\\\\\\\n+        #                             cursor=\\\\\\\\\\\\\\\'hand2\\\\\\\\\\\\\\\',\\\\\\\\r\\\\\\\\n+        #                             text="Empty Database",\\\\\\\\r\\\\\\\\n+        #                             font=(\\\\\\\\\\\\\\\'Arial\\\\\\\\\\\\\\\', 16, \\\\\\\\\\\\\\\'bold\\\\\\\\\\\\\\\'),\\\\\\\\r\\\\\\\\n+        #                             command=deleteDB(3))\\\\\\\\r\\\\\\\\n+        # self.buttoncanc.place(relx=0.5, rely=0.7, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n         self.buttoncanc = tk.Button(self,\\\\\\\\r\\\\\\\\n                                     background=color2,\\\\\\\\r\\\\\\\\n                                     foreground=color4,\\\\\\\\r\\\\\\\\n@@ -267,9 +313,9 @@ class PageThree(tk.Frame):\\\\\\\\n                     except KeyboardInterrupt:\\\\\\\\r\\\\\\\\n                         print("KeyboardInterrupt has been caught.")\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        def arduino_enroll(msg):\\\\\\\\r\\\\\\\\n+        def arduino_enroll(msg, new_finger_id):\\\\\\\\r\\\\\\\\n             print(msg)\\\\\\\\r\\\\\\\\n-            print(fingerprint_id_entry.get())\\\\\\\\r\\\\\\\\n+            print(new_finger_id)\\\\\\\\r\\\\\\\\n             print(\\\\\\\\\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\\\\\r\\\\\\\\n                 time.sleep(0.1)  # wait for serial to open\\\\\\\\r\\\\\\\\n@@ -280,13 +326,13 @@ class PageThree(tk.Frame):\\\\\\\\n                             time.sleep(0.5)  # wait for arduino to answer\\\\\\\\r\\\\\\\\n                             answer = arduino.readline()\\\\\\\\r\\\\\\\\n                             print(answer)\\\\\\\\r\\\\\\\\n-                            if answer == b\\\\\\\\\\\\\\\'Sensor contains 11 templates\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+                            if b"Sensor contains" in answer or b"doesn\\\\\\\\\\\\\\\'t" in answer:\\\\\\\\r\\\\\\\\n                                 arduino.write(str(msg).encode())\\\\\\\\r\\\\\\\\n                             if answer == b\\\\\\\\\\\\\\\'#id\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n                                 # print(\\\\\\\\\\\\\\\'break\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n                                 arduino.flushInput()\\\\\\\\r\\\\\\\\n                                 # cmd = str(input("Enter command : "))\\\\\\\\r\\\\\\\\n-                                cmd = str(fingerprint_id_entry.get())\\\\\\\\r\\\\\\\\n+                                cmd = str(new_finger_id)\\\\\\\\r\\\\\\\\n                                 arduino.write(str(cmd).encode())\\\\\\\\r\\\\\\\\n                                 while True:\\\\\\\\r\\\\\\\\n                                     answer = arduino.readline()\\\\\\\\r\\\\\\\\n@@ -295,6 +341,10 @@ class PageThree(tk.Frame):\\\\\\\\n                                         self.notify.config(\\\\\\\\r\\\\\\\\n                                             text=\\\\\\\\\\\\\\\'Take your finger out and Put it back\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n                                     if answer == b\\\\\\\\\\\\\\\'Stored!\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+                                        db.collection(\\\\\\\\\\\\\\\'users\\\\\\\\\\\\\\\').document(\\\\\\\\r\\\\\\\\n+                                            student_code_entry.get()).set({\\\\\\\\\\\\\\\'finger_id\\\\\\\\\\\\\\\': str(new_finger_id)}, merge=True)\\\\\\\\r\\\\\\\\n+                                        db.collection(\\\\\\\\r\\\\\\\\n+                                            \\\\\\\\\\\\\\\'fingers\\\\\\\\\\\\\\\').document(\\\\\\\\\\\\\\\'id\\\\\\\\\\\\\\\').upadte({\\\\\\\\\\\\\\\'id\\\\\\\\\\\\\\\': new_finger_id + 1})\\\\\\\\r\\\\\\\\n                                         self.notify.config(\\\\\\\\r\\\\\\\\n                                             text=\\\\\\\\\\\\\\\'Successfully encode fingerprint\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n                                         break\\\\\\\\r\\\\\\\\n@@ -306,11 +356,19 @@ class PageThree(tk.Frame):\\\\\\\\n \\\\\\\\r\\\\\\\\n         def start_enroll():\\\\\\\\r\\\\\\\\n             stop_enroll()\\\\\\\\r\\\\\\\\n-            self.notify.config(text=\\\\\\\\\\\\\\\'Loading.......\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-            self.notify.place(relx=0.5, rely=0.4, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n             global message\\\\\\\\r\\\\\\\\n             message == True\\\\\\\\r\\\\\\\\n-            arduino_enroll(2)\\\\\\\\r\\\\\\\\n+            result = db.collection(\\\\\\\\\\\\\\\'users\\\\\\\\\\\\\\\').document(\\\\\\\\r\\\\\\\\n+                student_code_entry.get()).get()\\\\\\\\r\\\\\\\\n+            if result.exists:\\\\\\\\r\\\\\\\\n+                new_finger_id = db.collection(\\\\\\\\\\\\\\\'fingers\\\\\\\\\\\\\\\').document(\\\\\\\\\\\\\\\'id\\\\\\\\\\\\\\\').get()\\\\\\\\r\\\\\\\\n+                new_finger_id = new_finger_id.to_dict()\\\\\\\\r\\\\\\\\n+                new_finger_id = new_finger_id[\\\\\\\\\\\\\\\'id\\\\\\\\\\\\\\\']\\\\\\\\r\\\\\\\\n+                arduino_enroll(2, new_finger_id)\\\\\\\\r\\\\\\\\n+            else:\\\\\\\\r\\\\\\\\n+                print(\\\\\\\\\\\\\\\'no match\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                messagebox.showwarning(\\\\\\\\\\\\\\\'ALERT\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'No Users Match\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                return\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         def stop_enroll():\\\\\\\\r\\\\\\\\n             global message\\\\\\\\r\\\\\\\\n@@ -320,31 +378,27 @@ class PageThree(tk.Frame):\\\\\\\\n             self, text="Enter your student code to register new fingerprint")\\\\\\\\r\\\\\\\\n         label1.place(relx=0.5, rely=0.1, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+        student_code_entry = tk.Entry(self)\\\\\\\\r\\\\\\\\n+        student_code_entry.place(relx=0.5, rely=0.2, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        label2 = tk.Label(\\\\\\\\r\\\\\\\\n+            self, text="Enter your fingerId")\\\\\\\\r\\\\\\\\n+        label2.place(relx=0.5, rely=0.3, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n         fingerprint_id_entry = tk.Entry(self)\\\\\\\\r\\\\\\\\n-        fingerprint_id_entry.place(relx=0.5, rely=0.2, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        fingerprint_id_entry.place(relx=0.5, rely=0.4, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\\\\\\\r\\\\\\\\n                                 fg="#263942", command=start_enroll)\\\\\\\\r\\\\\\\\n-        buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        buttoncanc2.place(relx=0.5, rely=0.5, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         self.notify = tk.Label(\\\\\\\\r\\\\\\\\n             self, text="abc")\\\\\\\\r\\\\\\\\n-        self.notify.place(relx=0.5, rely=0.4, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+        self.notify.place(relx=0.5, rely=0.6, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         buttoncanc1 = tk.Button(self, text="Cancel", bg="#ffffff",\\\\\\\\r\\\\\\\\n                                 fg="#263942", command=lambda: controller.show_frame("StartPage"))\\\\\\\\r\\\\\\\\n-        buttoncanc1.place(relx=0.5, rely=0.5, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-        # def initFingerprint():\\\\\\\\r\\\\\\\\n-        #     if message == True:\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-        #         mode = int(input("Select mode detect"))\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-        #         if mode == 1:\\\\\\\\r\\\\\\\\n-        #             arduino_detect(1)\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-        #         if mode == 2:\\\\\\\\r\\\\\\\\n-        #             arduino_enroll(2)\\\\\\\\r\\\\\\\\n+        buttoncanc1.place(relx=0.5, rely=0.7, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n class PageDetectFingert(tk.Frame):\\\\\\\\r\\\\\\\\n@@ -359,7 +413,7 @@ class PageDetectFingert(tk.Frame):\\\\\\\\n         status = \\\\\\\\\\\\\\\'loading\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n         self.controller = controller\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        def arduino_detect(msg):\\\\\\\\r\\\\\\\\n+        def arduino_detect(msg, mode):\\\\\\\\r\\\\\\\\n             print(msg)\\\\\\\\r\\\\\\\\n             print(\\\\\\\\\\\\\\\'Running. Press CTRL-C to exit.\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as arduino:\\\\\\\\r\\\\\\\\n@@ -371,37 +425,78 @@ class PageDetectFingert(tk.Frame):\\\\\\\\n                             time.sleep(0.5)  # wait for arduino to answer\\\\\\\\r\\\\\\\\n                             answer = arduino.readline()\\\\\\\\r\\\\\\\\n                             print(answer)\\\\\\\\r\\\\\\\\n-                            if answer == b\\\\\\\\\\\\\\\'Sensor contains 12 templates\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+                            if b"doesn\\\\\\\\\\\\\\\'t" in answer:\\\\\\\\r\\\\\\\\n+                                messagebox.showinfo(\\\\\\\\r\\\\\\\\n+                                    "ALERT", "No fingerprint to detect")\\\\\\\\r\\\\\\\\n+                                break\\\\\\\\r\\\\\\\\n+                            if answer == b\\\\\\\\\\\\\\\'Sensor contains 14 templates\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n                                 arduino.write(str(msg).encode())\\\\\\\\r\\\\\\\\n                                 while True:\\\\\\\\r\\\\\\\\n                                     answer = arduino.readline()\\\\\\\\r\\\\\\\\n                                     print(answer)\\\\\\\\r\\\\\\\\n-                                    if answer == b\\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+                                    idText = b\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                    if b\\\\\\\\\\\\\\\'ID\\\\\\\\\\\\\\\' in answer:\\\\\\\\r\\\\\\\\n+                                        idText = answer\\\\\\\\r\\\\\\\\n+                                    if b\\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\' in answer or b\\\\\\\\\\\\\\\'Unknown\\\\\\\\\\\\\\\' in answer:\\\\\\\\r\\\\\\\\n                                         self.notify1.config(\\\\\\\\r\\\\\\\\n                                             text=\\\\\\\\\\\\\\\'Successfully detect fingerprint\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n-\\\\\\\\r\\\\\\\\n-                                        self.notify1.config(text="")\\\\\\\\r\\\\\\\\n+                                        finger_id = idText.decode(\\\\\\\\r\\\\\\\\n+                                            \\\\\\\\\\\\\\\'utf-8\\\\\\\\\\\\\\\').split("#")[1]\\\\\\\\r\\\\\\\\n+                                        print(finger_id)\\\\\\\\r\\\\\\\\n+                                        if finger_id != \\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\':\\\\\\\\r\\\\\\\\n+                                            query = db.collection(\\\\\\\\\\\\\\\'users\\\\\\\\\\\\\\\').where(\\\\\\\\r\\\\\\\\n+                                                "finger_id", "==", finger_id).get()\\\\\\\\r\\\\\\\\n+                                            for doc in query:\\\\\\\\r\\\\\\\\n+                                                user = doc.to_dict()\\\\\\\\r\\\\\\\\n+                                                result = db.collection(\\\\\\\\r\\\\\\\\n+                                                    \\\\\\\\\\\\\\\'current_subject\\\\\\\\\\\\\\\').document(\\\\\\\\\\\\\\\'current\\\\\\\\\\\\\\\').get()\\\\\\\\r\\\\\\\\n+                                                result = result.to_dict()\\\\\\\\r\\\\\\\\n+                                                today = datetime.datetime.now()\\\\\\\\r\\\\\\\\n+                                                status = \\\\\\\\\\\\\\\'in_time\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                                if mode == 1:\\\\\\\\r\\\\\\\\n+                                                    time_compare = result[\\\\\\\\\\\\\\\'time_in\\\\\\\\\\\\\\\'] + \\\\\\\\\\\\\\\\\\\\\\\\r\\\\\\\\n+                                                        timedelta(hours=7)\\\\\\\\r\\\\\\\\n+                                                    if utc.localize(today) > time_compare:\\\\\\\\r\\\\\\\\n+                                                        status = \\\\\\\\\\\\\\\'vao_tre\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                                        print(\\\\\\\\\\\\\\\'vao_tre\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                                    else:\\\\\\\\r\\\\\\\\n+                                                        status = \\\\\\\\\\\\\\\'vao_dung_gio\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                                        print(\\\\\\\\\\\\\\\'vao dung gio\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                                    db.collection(\\\\\\\\\\\\\\\'check_in\\\\\\\\\\\\\\\').add(\\\\\\\\r\\\\\\\\n+                                                        {\\\\\\\\\\\\\\\'subject\\\\\\\\\\\\\\\': result[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\': user[\\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_name\\\\\\\\\\\\\\\': user[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'status\\\\\\\\\\\\\\\': status, \\\\\\\\\\\\\\\'type\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'fingerprint_detect\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'time_in\\\\\\\\\\\\\\\': today - timedelta(hours=7)})\\\\\\\\r\\\\\\\\n+                                                else:\\\\\\\\r\\\\\\\\n+                                                    time_compare = result[\\\\\\\\\\\\\\\'time_out\\\\\\\\\\\\\\\'] + \\\\\\\\\\\\\\\\\\\\\\\\r\\\\\\\\n+                                                        timedelta(hours=7)\\\\\\\\r\\\\\\\\n+                                                    if utc.localize(today) > time_compare:\\\\\\\\r\\\\\\\\n+                                                        status = \\\\\\\\\\\\\\\'ra_dung_gio\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                                        print(\\\\\\\\\\\\\\\'ra dung gio\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                                    else:\\\\\\\\r\\\\\\\\n+                                                        status = \\\\\\\\\\\\\\\'ra_som\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                                        print(\\\\\\\\\\\\\\\'ra som\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+                                                    db.collection(\\\\\\\\\\\\\\\'check_out\\\\\\\\\\\\\\\').add(\\\\\\\\r\\\\\\\\n+                                                        {\\\\\\\\\\\\\\\'subject\\\\\\\\\\\\\\\': result[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\': user[\\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_name\\\\\\\\\\\\\\\': user[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'status\\\\\\\\\\\\\\\': status, \\\\\\\\\\\\\\\'type\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'fingerprint_detect\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'time_out\\\\\\\\\\\\\\\': today - timedelta(hours=7)})\\\\\\\\r\\\\\\\\n                                         break\\\\\\\\r\\\\\\\\n                                     # return answer\\\\\\\\r\\\\\\\\n                                 break\\\\\\\\r\\\\\\\\n                     except KeyboardInterrupt:\\\\\\\\r\\\\\\\\n                         print("KeyboardInterrupt has been caught.")\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        def start_detect():\\\\\\\\r\\\\\\\\n+        def start_check_in():\\\\\\\\r\\\\\\\\n             stop_detect()\\\\\\\\r\\\\\\\\n             global status\\\\\\\\r\\\\\\\\n             status = \\\\\\\\\\\\\\\'Init Parameters\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n             print(status)\\\\\\\\r\\\\\\\\n             global message\\\\\\\\r\\\\\\\\n             message == True\\\\\\\\r\\\\\\\\n-            arduino_detect(1)\\\\\\\\r\\\\\\\\n+            arduino_detect(1, 1)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         def stop_detect():\\\\\\\\r\\\\\\\\n             global message\\\\\\\\r\\\\\\\\n             message == False\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        buttoncanc2 = tk.Button(self, text="Enroll Fingerprint", bg="#ffffff",\\\\\\\\r\\\\\\\\n-                                fg="#263942", command=start_detect)\\\\\\\\r\\\\\\\\n+        buttoncanc2 = tk.Button(self, text="Finger Check In", bg="#ffffff",\\\\\\\\r\\\\\\\\n+                                fg="#263942", command=start_check_in)\\\\\\\\r\\\\\\\\n         buttoncanc2.place(relx=0.5, rely=0.3, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         self.notify1 = tk.Label(\\\\\\\\r\\\\\\\\n@@ -441,7 +536,9 @@ class PageTakeFace(tk.Frame):\\\\\\\\n             detector = cv2.CascadeClassifier(\\\\\\\\r\\\\\\\\n                 "./data/haarcascade_frontalface_default.xml")\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-            filepath = \\\\\\\\\\\\\\\'./data/student/raw/\\\\\\\\\\\\\\\' + stundent_id_entry.get()\\\\\\\\r\\\\\\\\n+            id = stundent_id_entry.get()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+            filepath = \\\\\\\\\\\\\\\'./data/student/raw/\\\\\\\\\\\\\\\' + id\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n             isExist = os.path.exists(filepath)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n@@ -490,6 +587,8 @@ class PageTakeFace(tk.Frame):\\\\\\\\n                     if num_of_images == 21:\\\\\\\\r\\\\\\\\n                         stop_vid()\\\\\\\\r\\\\\\\\n                         num_of_images = 0\\\\\\\\r\\\\\\\\n+                        db.collection(\\\\\\\\\\\\\\\'users\\\\\\\\\\\\\\\').document(id).set(\\\\\\\\r\\\\\\\\n+                            {\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\': first_name_entry.get(), \\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\': id, \\\\\\\\\\\\\\\'image_path\\\\\\\\\\\\\\\': filepath})\\\\\\\\r\\\\\\\\n                         messagebox.showinfo(\\\\\\\\r\\\\\\\\n                             "INSTRUCTIONS", "We captured 20 pic of your Face.")\\\\\\\\r\\\\\\\\n                         return \\\\\\\\\\\\\\\'ok\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n@@ -607,9 +706,11 @@ class PageDetectFace(tk.Frame):\\\\\\\\n         global cap_detect\\\\\\\\r\\\\\\\\n         cap_detect = None\\\\\\\\r\\\\\\\\n         global count_unknown\\\\\\\\r\\\\\\\\n-        global detect_time\\\\\\\\r\\\\\\\\n         count_unknown = 0\\\\\\\\r\\\\\\\\n+        global detect_time\\\\\\\\r\\\\\\\\n         detect_time = 0\\\\\\\\r\\\\\\\\n+        global mode\\\\\\\\r\\\\\\\\n+        mode = 1\\\\\\\\r\\\\\\\\n         # student_id = \\\\\\\\\\\\\\\'_\\\\\\\\\\\\\\\'.join([\\\\\\\\\\\\\\\'student\\\\\\\\\\\\\\\', stundent_id_entry])\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         def detect_frame():\\\\\\\\r\\\\\\\\n@@ -624,7 +725,7 @@ class PageDetectFace(tk.Frame):\\\\\\\\n                     # frame = cap.read()\\\\\\\\r\\\\\\\\n                     frame = imutils.resize(frame, width=600)\\\\\\\\r\\\\\\\\n                     frame = cv2.flip(frame, 1)\\\\\\\\r\\\\\\\\n-                    rand_name = random.randint(0, 1000)\\\\\\\\r\\\\\\\\n+                    # rand_name = random.randint(0, 1000)\\\\\\\\r\\\\\\\\n                     bounding_boxes, _ = detect_face.detect_face(\\\\\\\\r\\\\\\\\n                         frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\\\\\r\\\\\\\\n                     faces_found = bounding_boxes.shape[0]\\\\\\\\r\\\\\\\\n@@ -676,11 +777,42 @@ class PageDetectFace(tk.Frame):\\\\\\\\n                                             1, (255, 255, 255), thickness=1, lineType=2)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n                                 file_name = best_name + ".jpg"\\\\\\\\r\\\\\\\\n-                                if detect_time == 3:\\\\\\\\r\\\\\\\\n+                                if detect_time == 2:\\\\\\\\r\\\\\\\\n                                     cv2.imwrite(os.path.join(\\\\\\\\r\\\\\\\\n                                         image_path, file_name), frame)\\\\\\\\r\\\\\\\\n                                     cv2.destroyAllWindows()\\\\\\\\r\\\\\\\\n-                                    print(\\\\\\\\\\\\\\\'complete detect\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                    result = db.collection(\\\\\\\\r\\\\\\\\n+                                        \\\\\\\\\\\\\\\'current_subject\\\\\\\\\\\\\\\').document(\\\\\\\\\\\\\\\'current\\\\\\\\\\\\\\\').get()\\\\\\\\r\\\\\\\\n+                                    result = result.to_dict()\\\\\\\\r\\\\\\\\n+                                    today = datetime.datetime.now()\\\\\\\\r\\\\\\\\n+                                    print(today)\\\\\\\\r\\\\\\\\n+                                    status = \\\\\\\\\\\\\\\'in_time\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                    global mode\\\\\\\\r\\\\\\\\n+                                    if mode == 1:\\\\\\\\r\\\\\\\\n+                                        time_compare = result[\\\\\\\\\\\\\\\'time_in\\\\\\\\\\\\\\\'] + \\\\\\\\\\\\\\\\\\\\\\\\r\\\\\\\\n+                                            timedelta(hours=7)\\\\\\\\r\\\\\\\\n+                                        print(time_compare)\\\\\\\\r\\\\\\\\n+                                        if utc.localize(today) > time_compare:\\\\\\\\r\\\\\\\\n+                                            status = \\\\\\\\\\\\\\\'vao_tre\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                            print(\\\\\\\\\\\\\\\'vao tre\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                        else:\\\\\\\\r\\\\\\\\n+                                            status = \\\\\\\\\\\\\\\'vao_dung_gio\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                            print(\\\\\\\\\\\\\\\'vao dung gio\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                        db.collection(\\\\\\\\\\\\\\\'check_in\\\\\\\\\\\\\\\').add(\\\\\\\\r\\\\\\\\n+                                            {\\\\\\\\\\\\\\\'subject\\\\\\\\\\\\\\\': result[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\': best_name, \\\\\\\\\\\\\\\'student_name\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'status\\\\\\\\\\\\\\\': status, \\\\\\\\\\\\\\\'type\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'face_detect\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'time_in\\\\\\\\\\\\\\\': today - timedelta(hours=7)})\\\\\\\\r\\\\\\\\n+                                        print(\\\\\\\\\\\\\\\'complete detect\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                    else:\\\\\\\\r\\\\\\\\n+                                        time_compare = result[\\\\\\\\\\\\\\\'time_out\\\\\\\\\\\\\\\'] + \\\\\\\\\\\\\\\\\\\\\\\\r\\\\\\\\n+                                            timedelta(hours=7)\\\\\\\\r\\\\\\\\n+                                        if utc.localize(today) > time_compare:\\\\\\\\r\\\\\\\\n+                                            status = \\\\\\\\\\\\\\\'ra_dung_gio\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                            print(\\\\\\\\\\\\\\\'ra dung gio\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                        else:\\\\\\\\r\\\\\\\\n+                                            status = \\\\\\\\\\\\\\\'ra_som\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n+                                            print(\\\\\\\\\\\\\\\'ra som\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+                                        db.collection(\\\\\\\\\\\\\\\'check_out\\\\\\\\\\\\\\\').add(\\\\\\\\r\\\\\\\\n+                                            {\\\\\\\\\\\\\\\'subject\\\\\\\\\\\\\\\': result[\\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\'], \\\\\\\\\\\\\\\'student_id\\\\\\\\\\\\\\\': best_name, \\\\\\\\\\\\\\\'student_name\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'name\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'status\\\\\\\\\\\\\\\': status, \\\\\\\\\\\\\\\'type\\\\\\\\\\\\\\\': \\\\\\\\\\\\\\\'face_detect\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\'time_out\\\\\\\\\\\\\\\': today - timedelta(hours=7)})\\\\\\\\r\\\\\\\\n+                                        print(\\\\\\\\\\\\\\\'complete detect\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n                                     time.sleep(1)\\\\\\\\r\\\\\\\\n                                     stop_detect()\\\\\\\\r\\\\\\\\n                                     detect_time = 0\\\\\\\\r\\\\\\\\n@@ -688,7 +820,6 @@ class PageDetectFace(tk.Frame):\\\\\\\\n \\\\\\\\r\\\\\\\\n                                 detect_time += 1\\\\\\\\r\\\\\\\\n                             else:\\\\\\\\r\\\\\\\\n-                                name = \\\\\\\\\\\\\\\'Unknown\\\\\\\\\\\\\\\'\\\\\\\\r\\\\\\\\n                                 print(\\\\\\\\\\\\\\\'Unknown\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n                                 print(count_unknown)\\\\\\\\r\\\\\\\\n                                 if count_unknown == 20:\\\\\\\\r\\\\\\\\n@@ -716,11 +847,20 @@ class PageDetectFace(tk.Frame):\\\\\\\\n \\\\\\\\r\\\\\\\\n                 detect_widget.after(10, detect_frame)\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        def start_detect():\\\\\\\\r\\\\\\\\n-            global cam_detect_on, cap_detect\\\\\\\\r\\\\\\\\n+        def start_check_in():\\\\\\\\r\\\\\\\\n+            global cam_detect_on, cap_detect, mode\\\\\\\\r\\\\\\\\n             stop_detect()\\\\\\\\r\\\\\\\\n             cam_detect_on = True\\\\\\\\r\\\\\\\\n             cap_detect = cv2.VideoCapture(1)\\\\\\\\r\\\\\\\\n+            mode = 1\\\\\\\\r\\\\\\\\n+            detect_frame()\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n+        def start_check_out():\\\\\\\\r\\\\\\\\n+            global cam_detect_on, cap_detect, mode\\\\\\\\r\\\\\\\\n+            stop_detect()\\\\\\\\r\\\\\\\\n+            cam_detect_on = True\\\\\\\\r\\\\\\\\n+            cap_detect = cv2.VideoCapture(1)\\\\\\\\r\\\\\\\\n+            mode = 2\\\\\\\\r\\\\\\\\n             detect_frame()\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n         def stop_detect():\\\\\\\\r\\\\\\\\n@@ -743,10 +883,14 @@ class PageDetectFace(tk.Frame):\\\\\\\\n                                 fg="#263942", command=stop_detect)\\\\\\\\r\\\\\\\\n         buttoncanc3.place(relx=0.5, rely=0.3, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n-        buttoncanc2 = tk.Button(self, text="Detect", bg="#ffffff",\\\\\\\\r\\\\\\\\n-                                fg="#263942", command=start_detect)\\\\\\\\r\\\\\\\\n+        buttoncanc2 = tk.Button(self, text="Face Check In", bg="#ffffff",\\\\\\\\r\\\\\\\\n+                                fg="#263942", command=start_check_in)\\\\\\\\r\\\\\\\\n         buttoncanc2.place(relx=0.5, rely=0.1, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\n+        buttoncanc2 = tk.Button(self, text="Face Check Out", bg="#ffffff",\\\\\\\\r\\\\\\\\n+                                fg="#263942", command=start_check_out)\\\\\\\\r\\\\\\\\n+        buttoncanc2.place(relx=0.5, rely=0.2, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n+\\\\\\\\r\\\\\\\\n         detect_widget = tk.Label(self)\\\\\\\\r\\\\\\\\n         detect_widget.place(relx=0.5, rely=0.7, anchor=\\\\\\\\\\\\\\\'center\\\\\\\\\\\\\\\')\\\\\\\\r\\\\\\\\n \\\\\\\\r\\\\\\\\ndiff --git a/data/student/processed/1911368/0.png b/data/student/processed/1911368/0.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex c051192..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/0.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/1.png b/data/student/processed/1911368/1.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 99e5d28..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/1.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/10.png b/data/student/processed/1911368/10.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex df469d0..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/10.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/11.png b/data/student/processed/1911368/11.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 20d1c4d..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/11.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/12.png b/data/student/processed/1911368/12.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 088ec3b..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/12.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/13.png b/data/student/processed/1911368/13.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 0ca5dd8..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/13.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/14.png b/data/student/processed/1911368/14.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 62952ad..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/14.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/15.png b/data/student/processed/1911368/15.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex a8e62c6..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/15.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/16.png b/data/student/processed/1911368/16.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex c260216..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/16.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/17.png b/data/student/processed/1911368/17.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 380bafb..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/17.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/18.png b/data/student/processed/1911368/18.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 0c561fd..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/18.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/19.png b/data/student/processed/1911368/19.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 5e31f0c..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/19.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/2.png b/data/student/processed/1911368/2.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 36d8db6..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/2.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/3.png b/data/student/processed/1911368/3.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex f4b183a..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/3.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/4.png b/data/student/processed/1911368/4.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 218248d..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/4.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/5.png b/data/student/processed/1911368/5.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex e531ba3..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/5.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/6.png b/data/student/processed/1911368/6.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 02041a3..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/6.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/7.png b/data/student/processed/1911368/7.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 000e3f9..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/7.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/8.png b/data/student/processed/1911368/8.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 777fd4f..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/8.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/processed/1911368/9.png b/data/student/processed/1911368/9.png\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex b4b589e..0000000\\\\\\\\nBinary files a/data/student/processed/1911368/9.png and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/0.jpg b/data/student/raw/121212/0.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 7df6ce6..0000000\\\\\\\\nBinary files a/data/student/raw/121212/0.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/1.jpg b/data/student/raw/121212/1.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 8d3d02e..0000000\\\\\\\\nBinary files a/data/student/raw/121212/1.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/10.jpg b/data/student/raw/121212/10.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 542b8a7..0000000\\\\\\\\nBinary files a/data/student/raw/121212/10.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/11.jpg b/data/student/raw/121212/11.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex ce13369..0000000\\\\\\\\nBinary files a/data/student/raw/121212/11.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/12.jpg b/data/student/raw/121212/12.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 56f5b9e..0000000\\\\\\\\nBinary files a/data/student/raw/121212/12.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/13.jpg b/data/student/raw/121212/13.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 5d9aa4c..0000000\\\\\\\\nBinary files a/data/student/raw/121212/13.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/14.jpg b/data/student/raw/121212/14.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 71fa7af..0000000\\\\\\\\nBinary files a/data/student/raw/121212/14.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/15.jpg b/data/student/raw/121212/15.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 837e667..0000000\\\\\\\\nBinary files a/data/student/raw/121212/15.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/16.jpg b/data/student/raw/121212/16.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 630f676..0000000\\\\\\\\nBinary files a/data/student/raw/121212/16.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/17.jpg b/data/student/raw/121212/17.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 109fcfa..0000000\\\\\\\\nBinary files a/data/student/raw/121212/17.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/18.jpg b/data/student/raw/121212/18.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 83ce987..0000000\\\\\\\\nBinary files a/data/student/raw/121212/18.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/19.jpg b/data/student/raw/121212/19.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 32ed5b7..0000000\\\\\\\\nBinary files a/data/student/raw/121212/19.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/2.jpg b/data/student/raw/121212/2.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex eda882e..0000000\\\\\\\\nBinary files a/data/student/raw/121212/2.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/20.jpg b/data/student/raw/121212/20.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 1427526..0000000\\\\\\\\nBinary files a/data/student/raw/121212/20.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/3.jpg b/data/student/raw/121212/3.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex e68b47d..0000000\\\\\\\\nBinary files a/data/student/raw/121212/3.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/4.jpg b/data/student/raw/121212/4.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex c1214ff..0000000\\\\\\\\nBinary files a/data/student/raw/121212/4.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/5.jpg b/data/student/raw/121212/5.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex b2e483b..0000000\\\\\\\\nBinary files a/data/student/raw/121212/5.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/6.jpg b/data/student/raw/121212/6.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 9997eb1..0000000\\\\\\\\nBinary files a/data/student/raw/121212/6.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/7.jpg b/data/student/raw/121212/7.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex ed406dc..0000000\\\\\\\\nBinary files a/data/student/raw/121212/7.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/8.jpg b/data/student/raw/121212/8.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex e291c17..0000000\\\\\\\\nBinary files a/data/student/raw/121212/8.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/121212/9.jpg b/data/student/raw/121212/9.jpg\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 92c16e1..0000000\\\\\\\\nBinary files a/data/student/raw/121212/9.jpg and /dev/null differ\\\\\\\\ndiff --git a/data/student/raw/1911368/0.jpg b/data/student/raw/1911368/0.jpg\\\\\\\\nindex ba76d11..73b0c05 100644\\\\\\\\nBinary files a/data/student/raw/1911368/0.jpg and b/data/student/raw/1911368/0.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/1.jpg b/data/student/raw/1911368/1.jpg\\\\\\\\nindex 89ffad9..cfff8c6 100644\\\\\\\\nBinary files a/data/student/raw/1911368/1.jpg and b/data/student/raw/1911368/1.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/10.jpg b/data/student/raw/1911368/10.jpg\\\\\\\\nindex 7476b36..939fc2b 100644\\\\\\\\nBinary files a/data/student/raw/1911368/10.jpg and b/data/student/raw/1911368/10.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/11.jpg b/data/student/raw/1911368/11.jpg\\\\\\\\nindex 9750a6c..e07d773 100644\\\\\\\\nBinary files a/data/student/raw/1911368/11.jpg and b/data/student/raw/1911368/11.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/12.jpg b/data/student/raw/1911368/12.jpg\\\\\\\\nindex 347c1e5..5de943e 100644\\\\\\\\nBinary files a/data/student/raw/1911368/12.jpg and b/data/student/raw/1911368/12.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/13.jpg b/data/student/raw/1911368/13.jpg\\\\\\\\nindex 477426e..7585cc4 100644\\\\\\\\nBinary files a/data/student/raw/1911368/13.jpg and b/data/student/raw/1911368/13.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/14.jpg b/data/student/raw/1911368/14.jpg\\\\\\\\nindex 24c8348..a1f314c 100644\\\\\\\\nBinary files a/data/student/raw/1911368/14.jpg and b/data/student/raw/1911368/14.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/15.jpg b/data/student/raw/1911368/15.jpg\\\\\\\\nindex e27b5d7..c25550f 100644\\\\\\\\nBinary files a/data/student/raw/1911368/15.jpg and b/data/student/raw/1911368/15.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/16.jpg b/data/student/raw/1911368/16.jpg\\\\\\\\nindex c877f33..dc7563d 100644\\\\\\\\nBinary files a/data/student/raw/1911368/16.jpg and b/data/student/raw/1911368/16.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/17.jpg b/data/student/raw/1911368/17.jpg\\\\\\\\nindex 11f23aa..c771ebf 100644\\\\\\\\nBinary files a/data/student/raw/1911368/17.jpg and b/data/student/raw/1911368/17.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/18.jpg b/data/student/raw/1911368/18.jpg\\\\\\\\nindex 47abf3c..464c81d 100644\\\\\\\\nBinary files a/data/student/raw/1911368/18.jpg and b/data/student/raw/1911368/18.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/19.jpg b/data/student/raw/1911368/19.jpg\\\\\\\\nindex ac8bb01..7fa7964 100644\\\\\\\\nBinary files a/data/student/raw/1911368/19.jpg and b/data/student/raw/1911368/19.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/2.jpg b/data/student/raw/1911368/2.jpg\\\\\\\\nindex f84a399..db0db3c 100644\\\\\\\\nBinary files a/data/student/raw/1911368/2.jpg and b/data/student/raw/1911368/2.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/3.jpg b/data/student/raw/1911368/3.jpg\\\\\\\\nindex 6cc68a9..0486fa2 100644\\\\\\\\nBinary files a/data/student/raw/1911368/3.jpg and b/data/student/raw/1911368/3.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/4.jpg b/data/student/raw/1911368/4.jpg\\\\\\\\nindex 6c6f5c6..8e478e0 100644\\\\\\\\nBinary files a/data/student/raw/1911368/4.jpg and b/data/student/raw/1911368/4.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/5.jpg b/data/student/raw/1911368/5.jpg\\\\\\\\nindex cc4af9a..839d4ff 100644\\\\\\\\nBinary files a/data/student/raw/1911368/5.jpg and b/data/student/raw/1911368/5.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/6.jpg b/data/student/raw/1911368/6.jpg\\\\\\\\nindex c6fef2a..b5ceb54 100644\\\\\\\\nBinary files a/data/student/raw/1911368/6.jpg and b/data/student/raw/1911368/6.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/7.jpg b/data/student/raw/1911368/7.jpg\\\\\\\\nindex 1cb80c4..d7039d1 100644\\\\\\\\nBinary files a/data/student/raw/1911368/7.jpg and b/data/student/raw/1911368/7.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/8.jpg b/data/student/raw/1911368/8.jpg\\\\\\\\nindex 959a82c..5822d74 100644\\\\\\\\nBinary files a/data/student/raw/1911368/8.jpg and b/data/student/raw/1911368/8.jpg differ\\\\\\\\ndiff --git a/data/student/raw/1911368/9.jpg b/data/student/raw/1911368/9.jpg\\\\\\\\nindex 17ea516..9c1ae6f 100644\\\\\\\\nBinary files a/data/student/raw/1911368/9.jpg and b/data/student/raw/1911368/9.jpg differ\\\\\\\\ndiff --git a/images/attendance/1911368.jpg b/images/attendance/1911368.jpg\\\\\\\\nindex ac65182..90050a5 100644\\\\\\\\nBinary files a/images/attendance/1911368.jpg and b/images/attendance/1911368.jpg differ\\\\\\\\ndiff --git a/nameslist.txt b/nameslist.txt\\\\\\\\nindex 91a96de..46e1af2 100644\\\\\\\\n--- a/nameslist.txt\\\\\\\\n+++ b/nameslist.txt\\\\\\\\n@@ -1 +1 @@\\\\\\\\n-                                                                                                     \\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\n+                                                                                                           \\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/data/student/raw/121212/0.jpg b/data/student/raw/121212/0.jpg\\\\ndeleted file mode 100644\\\\nindex 7df6ce6..0000000\\\\nBinary files a/data/student/raw/121212/0.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/1.jpg b/data/student/raw/121212/1.jpg\\\\ndeleted file mode 100644\\\\nindex 8d3d02e..0000000\\\\nBinary files a/data/student/raw/121212/1.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/10.jpg b/data/student/raw/121212/10.jpg\\\\ndeleted file mode 100644\\\\nindex 542b8a7..0000000\\\\nBinary files a/data/student/raw/121212/10.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/11.jpg b/data/student/raw/121212/11.jpg\\\\ndeleted file mode 100644\\\\nindex ce13369..0000000\\\\nBinary files a/data/student/raw/121212/11.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/12.jpg b/data/student/raw/121212/12.jpg\\\\ndeleted file mode 100644\\\\nindex 56f5b9e..0000000\\\\nBinary files a/data/student/raw/121212/12.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/13.jpg b/data/student/raw/121212/13.jpg\\\\ndeleted file mode 100644\\\\nindex 5d9aa4c..0000000\\\\nBinary files a/data/student/raw/121212/13.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/14.jpg b/data/student/raw/121212/14.jpg\\\\ndeleted file mode 100644\\\\nindex 71fa7af..0000000\\\\nBinary files a/data/student/raw/121212/14.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/15.jpg b/data/student/raw/121212/15.jpg\\\\ndeleted file mode 100644\\\\nindex 837e667..0000000\\\\nBinary files a/data/student/raw/121212/15.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/16.jpg b/data/student/raw/121212/16.jpg\\\\ndeleted file mode 100644\\\\nindex 630f676..0000000\\\\nBinary files a/data/student/raw/121212/16.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/17.jpg b/data/student/raw/121212/17.jpg\\\\ndeleted file mode 100644\\\\nindex 109fcfa..0000000\\\\nBinary files a/data/student/raw/121212/17.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/18.jpg b/data/student/raw/121212/18.jpg\\\\ndeleted file mode 100644\\\\nindex 83ce987..0000000\\\\nBinary files a/data/student/raw/121212/18.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/19.jpg b/data/student/raw/121212/19.jpg\\\\ndeleted file mode 100644\\\\nindex 32ed5b7..0000000\\\\nBinary files a/data/student/raw/121212/19.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/2.jpg b/data/student/raw/121212/2.jpg\\\\ndeleted file mode 100644\\\\nindex eda882e..0000000\\\\nBinary files a/data/student/raw/121212/2.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/20.jpg b/data/student/raw/121212/20.jpg\\\\ndeleted file mode 100644\\\\nindex 1427526..0000000\\\\nBinary files a/data/student/raw/121212/20.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/3.jpg b/data/student/raw/121212/3.jpg\\\\ndeleted file mode 100644\\\\nindex e68b47d..0000000\\\\nBinary files a/data/student/raw/121212/3.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/4.jpg b/data/student/raw/121212/4.jpg\\\\ndeleted file mode 100644\\\\nindex c1214ff..0000000\\\\nBinary files a/data/student/raw/121212/4.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/5.jpg b/data/student/raw/121212/5.jpg\\\\ndeleted file mode 100644\\\\nindex b2e483b..0000000\\\\nBinary files a/data/student/raw/121212/5.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/6.jpg b/data/student/raw/121212/6.jpg\\\\ndeleted file mode 100644\\\\nindex 9997eb1..0000000\\\\nBinary files a/data/student/raw/121212/6.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/7.jpg b/data/student/raw/121212/7.jpg\\\\ndeleted file mode 100644\\\\nindex ed406dc..0000000\\\\nBinary files a/data/student/raw/121212/7.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/8.jpg b/data/student/raw/121212/8.jpg\\\\ndeleted file mode 100644\\\\nindex e291c17..0000000\\\\nBinary files a/data/student/raw/121212/8.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/121212/9.jpg b/data/student/raw/121212/9.jpg\\\\ndeleted file mode 100644\\\\nindex 92c16e1..0000000\\\\nBinary files a/data/student/raw/121212/9.jpg and /dev/null differ\\\\ndiff --git a/data/student/raw/1911368/0.jpg b/data/student/raw/1911368/0.jpg\\\\nindex ba76d11..a1c8ed9 100644\\\\nBinary files a/data/student/raw/1911368/0.jpg and b/data/student/raw/1911368/0.jpg differ\\\\ndiff --git a/data/student/raw/1911368/1.jpg b/data/student/raw/1911368/1.jpg\\\\nindex 89ffad9..bc5a2ce 100644\\\\nBinary files a/data/student/raw/1911368/1.jpg and b/data/student/raw/1911368/1.jpg differ\\\\ndiff --git a/data/student/raw/1911368/10.jpg b/data/student/raw/1911368/10.jpg\\\\nindex 7476b36..8a9b8c3 100644\\\\nBinary files a/data/student/raw/1911368/10.jpg and b/data/student/raw/1911368/10.jpg differ\\\\ndiff --git a/data/student/raw/1911368/11.jpg b/data/student/raw/1911368/11.jpg\\\\nindex 9750a6c..cf6dc52 100644\\\\nBinary files a/data/student/raw/1911368/11.jpg and b/data/student/raw/1911368/11.jpg differ\\\\ndiff --git a/data/student/raw/1911368/12.jpg b/data/student/raw/1911368/12.jpg\\\\nindex 347c1e5..26c51f3 100644\\\\nBinary files a/data/student/raw/1911368/12.jpg and b/data/student/raw/1911368/12.jpg differ\\\\ndiff --git a/data/student/raw/1911368/13.jpg b/data/student/raw/1911368/13.jpg\\\\nindex 477426e..a1817fd 100644\\\\nBinary files a/data/student/raw/1911368/13.jpg and b/data/student/raw/1911368/13.jpg differ\\\\ndiff --git a/data/student/raw/1911368/14.jpg b/data/student/raw/1911368/14.jpg\\\\nindex 24c8348..be41997 100644\\\\nBinary files a/data/student/raw/1911368/14.jpg and b/data/student/raw/1911368/14.jpg differ\\\\ndiff --git a/data/student/raw/1911368/15.jpg b/data/student/raw/1911368/15.jpg\\\\nindex e27b5d7..80a8a03 100644\\\\nBinary files a/data/student/raw/1911368/15.jpg and b/data/student/raw/1911368/15.jpg differ\\\\ndiff --git a/data/student/raw/1911368/16.jpg b/data/student/raw/1911368/16.jpg\\\\nindex c877f33..0fdbf61 100644\\\\nBinary files a/data/student/raw/1911368/16.jpg and b/data/student/raw/1911368/16.jpg differ\\\\ndiff --git a/data/student/raw/1911368/17.jpg b/data/student/raw/1911368/17.jpg\\\\nindex 11f23aa..83b5f68 100644\\\\nBinary files a/data/student/raw/1911368/17.jpg and b/data/student/raw/1911368/17.jpg differ\\\\ndiff --git a/data/student/raw/1911368/18.jpg b/data/student/raw/1911368/18.jpg\\\\nindex 47abf3c..a75841b 100644\\\\nBinary files a/data/student/raw/1911368/18.jpg and b/data/student/raw/1911368/18.jpg differ\\\\ndiff --git a/data/student/raw/1911368/19.jpg b/data/student/raw/1911368/19.jpg\\\\nindex ac8bb01..2ca5735 100644\\\\nBinary files a/data/student/raw/1911368/19.jpg and b/data/student/raw/1911368/19.jpg differ\\\\ndiff --git a/data/student/raw/1911368/2.jpg b/data/student/raw/1911368/2.jpg\\\\nindex f84a399..a6fbe2f 100644\\\\nBinary files a/data/student/raw/1911368/2.jpg and b/data/student/raw/1911368/2.jpg differ\\\\ndiff --git a/data/student/raw/1911368/3.jpg b/data/student/raw/1911368/3.jpg\\\\nindex 6cc68a9..c0edb2a 100644\\\\nBinary files a/data/student/raw/1911368/3.jpg and b/data/student/raw/1911368/3.jpg differ\\\\ndiff --git a/data/student/raw/1911368/4.jpg b/data/student/raw/1911368/4.jpg\\\\nindex 6c6f5c6..1ead8a6 100644\\\\nBinary files a/data/student/raw/1911368/4.jpg and b/data/student/raw/1911368/4.jpg differ\\\\ndiff --git a/data/student/raw/1911368/5.jpg b/data/student/raw/1911368/5.jpg\\\\nindex cc4af9a..5e82ee9 100644\\\\nBinary files a/data/student/raw/1911368/5.jpg and b/data/student/raw/1911368/5.jpg differ\\\\ndiff --git a/data/student/raw/1911368/6.jpg b/data/student/raw/1911368/6.jpg\\\\nindex c6fef2a..434ad08 100644\\\\nBinary files a/data/student/raw/1911368/6.jpg and b/data/student/raw/1911368/6.jpg differ\\\\ndiff --git a/data/student/raw/1911368/7.jpg b/data/student/raw/1911368/7.jpg\\\\nindex 1cb80c4..79c30a0 100644\\\\nBinary files a/data/student/raw/1911368/7.jpg and b/data/student/raw/1911368/7.jpg differ\\\\ndiff --git a/data/student/raw/1911368/8.jpg b/data/student/raw/1911368/8.jpg\\\\nindex 959a82c..9be1e2a 100644\\\\nBinary files a/data/student/raw/1911368/8.jpg and b/data/student/raw/1911368/8.jpg differ\\\\ndiff --git a/data/student/raw/1911368/9.jpg b/data/student/raw/1911368/9.jpg\\\\nindex 17ea516..16d9724 100644\\\\nBinary files a/data/student/raw/1911368/9.jpg and b/data/student/raw/1911368/9.jpg differ\\\\ndiff --git a/images/attendance/1911368.jpg b/images/attendance/1911368.jpg\\\\nindex ac65182..90050a5 100644\\\\nBinary files a/images/attendance/1911368.jpg and b/images/attendance/1911368.jpg differ\\\\ndiff --git a/nameslist.txt b/nameslist.txt\\\\nindex 91a96de..46e1af2 100644\\\\n--- a/nameslist.txt\\\\n+++ b/nameslist.txt\\\\n@@ -1 +1 @@\\\\n-                                                                                                     \\\\n\\\\\\\\ No newline at end of file\\\\n+                                                                                                           \\\\n\\\\\\\\ No newline at end of file\\\'\\n\\\\ No newline at end of file\\ndiff --git a/data/student/raw/121212/0.jpg b/data/student/raw/121212/0.jpg\\ndeleted file mode 100644\\nindex 7df6ce6..0000000\\nBinary files a/data/student/raw/121212/0.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/1.jpg b/data/student/raw/121212/1.jpg\\ndeleted file mode 100644\\nindex 8d3d02e..0000000\\nBinary files a/data/student/raw/121212/1.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/10.jpg b/data/student/raw/121212/10.jpg\\ndeleted file mode 100644\\nindex 542b8a7..0000000\\nBinary files a/data/student/raw/121212/10.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/11.jpg b/data/student/raw/121212/11.jpg\\ndeleted file mode 100644\\nindex ce13369..0000000\\nBinary files a/data/student/raw/121212/11.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/12.jpg b/data/student/raw/121212/12.jpg\\ndeleted file mode 100644\\nindex 56f5b9e..0000000\\nBinary files a/data/student/raw/121212/12.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/13.jpg b/data/student/raw/121212/13.jpg\\ndeleted file mode 100644\\nindex 5d9aa4c..0000000\\nBinary files a/data/student/raw/121212/13.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/14.jpg b/data/student/raw/121212/14.jpg\\ndeleted file mode 100644\\nindex 71fa7af..0000000\\nBinary files a/data/student/raw/121212/14.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/15.jpg b/data/student/raw/121212/15.jpg\\ndeleted file mode 100644\\nindex 837e667..0000000\\nBinary files a/data/student/raw/121212/15.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/16.jpg b/data/student/raw/121212/16.jpg\\ndeleted file mode 100644\\nindex 630f676..0000000\\nBinary files a/data/student/raw/121212/16.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/17.jpg b/data/student/raw/121212/17.jpg\\ndeleted file mode 100644\\nindex 109fcfa..0000000\\nBinary files a/data/student/raw/121212/17.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/18.jpg b/data/student/raw/121212/18.jpg\\ndeleted file mode 100644\\nindex 83ce987..0000000\\nBinary files a/data/student/raw/121212/18.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/19.jpg b/data/student/raw/121212/19.jpg\\ndeleted file mode 100644\\nindex 32ed5b7..0000000\\nBinary files a/data/student/raw/121212/19.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/2.jpg b/data/student/raw/121212/2.jpg\\ndeleted file mode 100644\\nindex eda882e..0000000\\nBinary files a/data/student/raw/121212/2.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/20.jpg b/data/student/raw/121212/20.jpg\\ndeleted file mode 100644\\nindex 1427526..0000000\\nBinary files a/data/student/raw/121212/20.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/3.jpg b/data/student/raw/121212/3.jpg\\ndeleted file mode 100644\\nindex e68b47d..0000000\\nBinary files a/data/student/raw/121212/3.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/4.jpg b/data/student/raw/121212/4.jpg\\ndeleted file mode 100644\\nindex c1214ff..0000000\\nBinary files a/data/student/raw/121212/4.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/5.jpg b/data/student/raw/121212/5.jpg\\ndeleted file mode 100644\\nindex b2e483b..0000000\\nBinary files a/data/student/raw/121212/5.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/6.jpg b/data/student/raw/121212/6.jpg\\ndeleted file mode 100644\\nindex 9997eb1..0000000\\nBinary files a/data/student/raw/121212/6.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/7.jpg b/data/student/raw/121212/7.jpg\\ndeleted file mode 100644\\nindex ed406dc..0000000\\nBinary files a/data/student/raw/121212/7.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/8.jpg b/data/student/raw/121212/8.jpg\\ndeleted file mode 100644\\nindex e291c17..0000000\\nBinary files a/data/student/raw/121212/8.jpg and /dev/null differ\\ndiff --git a/data/student/raw/121212/9.jpg b/data/student/raw/121212/9.jpg\\ndeleted file mode 100644\\nindex 92c16e1..0000000\\nBinary files a/data/student/raw/121212/9.jpg and /dev/null differ\\ndiff --git a/data/student/raw/1911368/0.jpg b/data/student/raw/1911368/0.jpg\\nindex ba76d11..8d26dd4 100644\\nBinary files a/data/student/raw/1911368/0.jpg and b/data/student/raw/1911368/0.jpg differ\\ndiff --git a/data/student/raw/1911368/1.jpg b/data/student/raw/1911368/1.jpg\\nindex 89ffad9..b427058 100644\\nBinary files a/data/student/raw/1911368/1.jpg and b/data/student/raw/1911368/1.jpg differ\\ndiff --git a/data/student/raw/1911368/10.jpg b/data/student/raw/1911368/10.jpg\\nindex 7476b36..6ff8598 100644\\nBinary files a/data/student/raw/1911368/10.jpg and b/data/student/raw/1911368/10.jpg differ\\ndiff --git a/data/student/raw/1911368/11.jpg b/data/student/raw/1911368/11.jpg\\nindex 9750a6c..24a0e18 100644\\nBinary files a/data/student/raw/1911368/11.jpg and b/data/student/raw/1911368/11.jpg differ\\ndiff --git a/data/student/raw/1911368/12.jpg b/data/student/raw/1911368/12.jpg\\nindex 347c1e5..b24b450 100644\\nBinary files a/data/student/raw/1911368/12.jpg and b/data/student/raw/1911368/12.jpg differ\\ndiff --git a/data/student/raw/1911368/13.jpg b/data/student/raw/1911368/13.jpg\\nindex 477426e..fd19984 100644\\nBinary files a/data/student/raw/1911368/13.jpg and b/data/student/raw/1911368/13.jpg differ\\ndiff --git a/data/student/raw/1911368/14.jpg b/data/student/raw/1911368/14.jpg\\nindex 24c8348..f5ebbcb 100644\\nBinary files a/data/student/raw/1911368/14.jpg and b/data/student/raw/1911368/14.jpg differ\\ndiff --git a/data/student/raw/1911368/15.jpg b/data/student/raw/1911368/15.jpg\\nindex e27b5d7..a97b401 100644\\nBinary files a/data/student/raw/1911368/15.jpg and b/data/student/raw/1911368/15.jpg differ\\ndiff --git a/data/student/raw/1911368/16.jpg b/data/student/raw/1911368/16.jpg\\nindex c877f33..f94f8f2 100644\\nBinary files a/data/student/raw/1911368/16.jpg and b/data/student/raw/1911368/16.jpg differ\\ndiff --git a/data/student/raw/1911368/17.jpg b/data/student/raw/1911368/17.jpg\\nindex 11f23aa..7a9af2e 100644\\nBinary files a/data/student/raw/1911368/17.jpg and b/data/student/raw/1911368/17.jpg differ\\ndiff --git a/data/student/raw/1911368/18.jpg b/data/student/raw/1911368/18.jpg\\nindex 47abf3c..63c02ea 100644\\nBinary files a/data/student/raw/1911368/18.jpg and b/data/student/raw/1911368/18.jpg differ\\ndiff --git a/data/student/raw/1911368/19.jpg b/data/student/raw/1911368/19.jpg\\nindex ac8bb01..3564b44 100644\\nBinary files a/data/student/raw/1911368/19.jpg and b/data/student/raw/1911368/19.jpg differ\\ndiff --git a/data/student/raw/1911368/2.jpg b/data/student/raw/1911368/2.jpg\\nindex f84a399..f258051 100644\\nBinary files a/data/student/raw/1911368/2.jpg and b/data/student/raw/1911368/2.jpg differ\\ndiff --git a/data/student/raw/1911368/3.jpg b/data/student/raw/1911368/3.jpg\\nindex 6cc68a9..518b0c6 100644\\nBinary files a/data/student/raw/1911368/3.jpg and b/data/student/raw/1911368/3.jpg differ\\ndiff --git a/data/student/raw/1911368/4.jpg b/data/student/raw/1911368/4.jpg\\nindex 6c6f5c6..e532105 100644\\nBinary files a/data/student/raw/1911368/4.jpg and b/data/student/raw/1911368/4.jpg differ\\ndiff --git a/data/student/raw/1911368/5.jpg b/data/student/raw/1911368/5.jpg\\nindex cc4af9a..045efcc 100644\\nBinary files a/data/student/raw/1911368/5.jpg and b/data/student/raw/1911368/5.jpg differ\\ndiff --git a/data/student/raw/1911368/6.jpg b/data/student/raw/1911368/6.jpg\\nindex c6fef2a..05d4d84 100644\\nBinary files a/data/student/raw/1911368/6.jpg and b/data/student/raw/1911368/6.jpg differ\\ndiff --git a/data/student/raw/1911368/7.jpg b/data/student/raw/1911368/7.jpg\\nindex 1cb80c4..fcab052 100644\\nBinary files a/data/student/raw/1911368/7.jpg and b/data/student/raw/1911368/7.jpg differ\\ndiff --git a/data/student/raw/1911368/8.jpg b/data/student/raw/1911368/8.jpg\\nindex 959a82c..50fbafc 100644\\nBinary files a/data/student/raw/1911368/8.jpg and b/data/student/raw/1911368/8.jpg differ\\ndiff --git a/data/student/raw/1911368/9.jpg b/data/student/raw/1911368/9.jpg\\nindex 17ea516..4459c84 100644\\nBinary files a/data/student/raw/1911368/9.jpg and b/data/student/raw/1911368/9.jpg differ\\ndiff --git a/images/attendance/1911368.jpg b/images/attendance/1911368.jpg\\nindex ac65182..90050a5 100644\\nBinary files a/images/attendance/1911368.jpg and b/images/attendance/1911368.jpg differ\\ndiff --git a/nameslist.txt b/nameslist.txt\\nindex 91a96de..46e1af2 100644\\n--- a/nameslist.txt\\n+++ b/nameslist.txt\\n@@ -1 +1 @@\\n-                                                                                                     \\n\\\\ No newline at end of file\\n+                                                                                                           \\n\\\\ No newline at end of file\'\n\\ No newline at end of file\ndiff --git a/data/student/raw/1911368/0.jpg b/data/student/raw/1911368/0.jpg\ndeleted file mode 100644\nindex 8d26dd4..0000000\nBinary files a/data/student/raw/1911368/0.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/1.jpg b/data/student/raw/1911368/1.jpg\ndeleted file mode 100644\nindex b427058..0000000\nBinary files a/data/student/raw/1911368/1.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/10.jpg b/data/student/raw/1911368/10.jpg\ndeleted file mode 100644\nindex 6ff8598..0000000\nBinary files a/data/student/raw/1911368/10.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/11.jpg b/data/student/raw/1911368/11.jpg\ndeleted file mode 100644\nindex 24a0e18..0000000\nBinary files a/data/student/raw/1911368/11.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/12.jpg b/data/student/raw/1911368/12.jpg\ndeleted file mode 100644\nindex b24b450..0000000\nBinary files a/data/student/raw/1911368/12.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/13.jpg b/data/student/raw/1911368/13.jpg\ndeleted file mode 100644\nindex fd19984..0000000\nBinary files a/data/student/raw/1911368/13.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/14.jpg b/data/student/raw/1911368/14.jpg\ndeleted file mode 100644\nindex f5ebbcb..0000000\nBinary files a/data/student/raw/1911368/14.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/15.jpg b/data/student/raw/1911368/15.jpg\ndeleted file mode 100644\nindex a97b401..0000000\nBinary files a/data/student/raw/1911368/15.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/16.jpg b/data/student/raw/1911368/16.jpg\ndeleted file mode 100644\nindex f94f8f2..0000000\nBinary files a/data/student/raw/1911368/16.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/17.jpg b/data/student/raw/1911368/17.jpg\ndeleted file mode 100644\nindex 7a9af2e..0000000\nBinary files a/data/student/raw/1911368/17.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/18.jpg b/data/student/raw/1911368/18.jpg\ndeleted file mode 100644\nindex 63c02ea..0000000\nBinary files a/data/student/raw/1911368/18.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/19.jpg b/data/student/raw/1911368/19.jpg\ndeleted file mode 100644\nindex 3564b44..0000000\nBinary files a/data/student/raw/1911368/19.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/2.jpg b/data/student/raw/1911368/2.jpg\ndeleted file mode 100644\nindex f258051..0000000\nBinary files a/data/student/raw/1911368/2.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/20.jpg b/data/student/raw/1911368/20.jpg\ndeleted file mode 100644\nindex 35b1486..0000000\nBinary files a/data/student/raw/1911368/20.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/3.jpg b/data/student/raw/1911368/3.jpg\ndeleted file mode 100644\nindex 518b0c6..0000000\nBinary files a/data/student/raw/1911368/3.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/4.jpg b/data/student/raw/1911368/4.jpg\ndeleted file mode 100644\nindex e532105..0000000\nBinary files a/data/student/raw/1911368/4.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/5.jpg b/data/student/raw/1911368/5.jpg\ndeleted file mode 100644\nindex 045efcc..0000000\nBinary files a/data/student/raw/1911368/5.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/6.jpg b/data/student/raw/1911368/6.jpg\ndeleted file mode 100644\nindex 05d4d84..0000000\nBinary files a/data/student/raw/1911368/6.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/7.jpg b/data/student/raw/1911368/7.jpg\ndeleted file mode 100644\nindex fcab052..0000000\nBinary files a/data/student/raw/1911368/7.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/8.jpg b/data/student/raw/1911368/8.jpg\ndeleted file mode 100644\nindex 50fbafc..0000000\nBinary files a/data/student/raw/1911368/8.jpg and /dev/null differ\ndiff --git a/data/student/raw/1911368/9.jpg b/data/student/raw/1911368/9.jpg\ndeleted file mode 100644\nindex 4459c84..0000000\nBinary files a/data/student/raw/1911368/9.jpg and /dev/null differ\ndiff --git a/data/student/raw/1915577/1.png b/data/student/raw/1915577/1.png\ndeleted file mode 100644\nindex 4933c9d..0000000\nBinary files a/data/student/raw/1915577/1.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/10.png b/data/student/raw/1915577/10.png\ndeleted file mode 100644\nindex d69176d..0000000\nBinary files a/data/student/raw/1915577/10.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/11.png b/data/student/raw/1915577/11.png\ndeleted file mode 100644\nindex f5c5c1b..0000000\nBinary files a/data/student/raw/1915577/11.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/12.png b/data/student/raw/1915577/12.png\ndeleted file mode 100644\nindex ff70d7b..0000000\nBinary files a/data/student/raw/1915577/12.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/13.png b/data/student/raw/1915577/13.png\ndeleted file mode 100644\nindex e928f8c..0000000\nBinary files a/data/student/raw/1915577/13.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/14.png b/data/student/raw/1915577/14.png\ndeleted file mode 100644\nindex 16b9f3e..0000000\nBinary files a/data/student/raw/1915577/14.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/15.png b/data/student/raw/1915577/15.png\ndeleted file mode 100644\nindex fb456cc..0000000\nBinary files a/data/student/raw/1915577/15.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/16.png b/data/student/raw/1915577/16.png\ndeleted file mode 100644\nindex 29d1874..0000000\nBinary files a/data/student/raw/1915577/16.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/17.png b/data/student/raw/1915577/17.png\ndeleted file mode 100644\nindex f864ed6..0000000\nBinary files a/data/student/raw/1915577/17.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/18.png b/data/student/raw/1915577/18.png\ndeleted file mode 100644\nindex e3dc185..0000000\nBinary files a/data/student/raw/1915577/18.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/19.png b/data/student/raw/1915577/19.png\ndeleted file mode 100644\nindex 62f3956..0000000\nBinary files a/data/student/raw/1915577/19.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/2.png b/data/student/raw/1915577/2.png\ndeleted file mode 100644\nindex 1d38d53..0000000\nBinary files a/data/student/raw/1915577/2.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/20.png b/data/student/raw/1915577/20.png\ndeleted file mode 100644\nindex 88b4e72..0000000\nBinary files a/data/student/raw/1915577/20.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/21.png b/data/student/raw/1915577/21.png\ndeleted file mode 100644\nindex 1f47ffc..0000000\nBinary files a/data/student/raw/1915577/21.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/3.png b/data/student/raw/1915577/3.png\ndeleted file mode 100644\nindex 4a4a52d..0000000\nBinary files a/data/student/raw/1915577/3.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/4.png b/data/student/raw/1915577/4.png\ndeleted file mode 100644\nindex e59b9ec..0000000\nBinary files a/data/student/raw/1915577/4.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/5.png b/data/student/raw/1915577/5.png\ndeleted file mode 100644\nindex 232704a..0000000\nBinary files a/data/student/raw/1915577/5.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/6.png b/data/student/raw/1915577/6.png\ndeleted file mode 100644\nindex 3a6b9b5..0000000\nBinary files a/data/student/raw/1915577/6.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/7.png b/data/student/raw/1915577/7.png\ndeleted file mode 100644\nindex 5b26b24..0000000\nBinary files a/data/student/raw/1915577/7.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/8.png b/data/student/raw/1915577/8.png\ndeleted file mode 100644\nindex 070b9e2..0000000\nBinary files a/data/student/raw/1915577/8.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/9.png b/data/student/raw/1915577/9.png\ndeleted file mode 100644\nindex 2778196..0000000\nBinary files a/data/student/raw/1915577/9.png and /dev/null differ\ndiff --git a/images/attendance/1911368.jpg b/images/attendance/1911368.jpg\nindex 90050a5..ee79866 100644\nBinary files a/images/attendance/1911368.jpg and b/images/attendance/1911368.jpg differ\ndiff --git a/nameslist.txt b/nameslist.txt\nindex 2f8fce4..1596b7c 100644\n--- a/nameslist.txt\n+++ b/nameslist.txt\n@@ -1 +1 @@\n-                                                                                                                    \n\\ No newline at end of file\n+                                                                                                                               \n\\ No newline at end of file\ndiff --git a/testFirebase.py b/testFirebase.py\nindex 8a5a81c..4c73c67 100644\n--- a/testFirebase.py\n+++ b/testFirebase.py\n@@ -29,9 +29,11 @@ db = firestore.client()\n #     print(i, result[i])\n # print(result.date_in)\n \n-# result = db.collection(\n-#     \'current_subject\').document(\'current\').get()\n-# result = result.to_dict()\n+result = db.collection(\n+    \'current_subject\').document(\'current\').get()\n+result = result.to_dict()\n+print(result[\'name\'])\n+\n # time_compare = result[\'time_in\'] + timedelta(hours=7)\n # print(time_compare)\n # today = datetime.datetime.now()\n@@ -51,7 +53,6 @@ db = firestore.client()\n # else:\n #     print(\'no match\')\n \n-\n-checkExist = db.collection(\'check_in\').where(\n-    "finger_id", "==", \'2\').get()\n-print(len(checkExist))\n+# checkExist = db.collection(\'check_in\').where(\n+#     "finger_id", "==", \'2\').get()\n+# print(len(checkExist))'