arguments: app-gui.py
--------------------
tensorflow version: 2.11.0
--------------------
git hash: b'5a61480f5537bceba23c43be3d285a8d332e2e61'
--------------------
b'diff --git a/.gitignore b/.gitignore\nindex 67208b9..8a268fe 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,2 +1,3 @@\n env/\n-model/\n\\ No newline at end of file\n+model/\n+node_modules/\n\\ No newline at end of file\ndiff --git a/__pycache__/create_classifier.cpython-37.pyc b/__pycache__/create_classifier.cpython-37.pyc\nindex ce214a6..9e6d32c 100644\nBinary files a/__pycache__/create_classifier.cpython-37.pyc and b/__pycache__/create_classifier.cpython-37.pyc differ\ndiff --git a/app-gui.py b/app-gui.py\nindex 0c6fe9b..d4876dd 100644\n--- a/app-gui.py\n+++ b/app-gui.py\n@@ -38,11 +38,16 @@ time.sleep(0.2)  # wait for serial to open\n names = set()\r\n db = firestore.client()\r\n utc = pytz.UTC\r\n+global subject_now\r\n+subject_now = db.collection(\r\n+    \'current_subject\').document(\'current\').get()\r\n+subject_now = subject_now.to_dict()\r\n \r\n \r\n class MainUI(tk.Tk):\r\n \r\n     def __init__(self, *args, **kwargs):\r\n+        # loadSubjectModel()\r\n         tk.Tk.__init__(self, *args, **kwargs)\r\n         global names\r\n         global open_webcam\r\n@@ -72,7 +77,7 @@ class MainUI(tk.Tk):\n         container.grid_rowconfigure(0, weight=1)\r\n         container.grid_columnconfigure(0, weight=1)\r\n         self.frames = {}\r\n-        for F in (StartPage, PageOne, PageTwo, PageThree, PageDetectFingert, PageFour, PageTakeFace, PageDetectFace):\r\n+        for F in (StartPage, FaceIndex, FingerIndex, PageEnrollFinger, PageDetectFingert, PageFour, PageTakeFace, PageDetectFace):\r\n             page_name = F.__name__\r\n             frame = F(parent=container, controller=self)\r\n             self.frames[page_name] = frame\r\n@@ -107,7 +112,7 @@ class StartPage(tk.Frame):\n             "Touch_ID.png").resize((250, 250), Image.ANTIALIAS))\r\n \r\n         button4 = tk.Button(\r\n-            self, image=render1, command=lambda: self.controller.show_frame("PageTwo"))\r\n+            self, image=render1, command=lambda: self.controller.show_frame("FingerIndex"))\r\n         button4.image = render1\r\n         button4.grid(row=0, column=0, rowspan=4,\r\n                      padx=10, pady=12, sticky="nsew")\r\n@@ -120,7 +125,7 @@ class StartPage(tk.Frame):\n             "face-id-id.png").resize((250, 250), Image.ANTIALIAS))\r\n \r\n         button5 = tk.Button(\r\n-            self, image=render2, command=lambda: self.controller.show_frame("PageOne"))\r\n+            self, image=render2, command=lambda: self.controller.show_frame("FaceIndex"))\r\n         button5.image = render2\r\n         button5.grid(row=1, column=1, rowspan=4,\r\n                      padx=10, pady=12, sticky="nsew")\r\n@@ -134,7 +139,7 @@ class StartPage(tk.Frame):\n             self.controller.destroy()\r\n \r\n \r\n-class PageOne(tk.Frame):\r\n+class FaceIndex(tk.Frame):\r\n     def __init__(self, parent, controller):\r\n         tk.Frame.__init__(self, parent)\r\n         self.controller = controller\r\n@@ -191,7 +196,7 @@ class PageOne(tk.Frame):\n         self.buttonTakeFace.place(relx=0.5, rely=0.1, anchor=\'center\')\r\n \r\n \r\n-class PageTwo(tk.Frame):\r\n+class FingerIndex(tk.Frame):\r\n     def __init__(self, parent, controller):\r\n         tk.Frame.__init__(self, parent)\r\n         self.controller = controller\r\n@@ -230,7 +235,7 @@ class PageTwo(tk.Frame):\n                                         border=0,\r\n                                         cursor=\'hand2\',\r\n                                         text="New Fingerprint",\r\n-                                        font=(\'Arial\', 16, \'bold\'), command=lambda: controller.show_frame("PageThree"))\r\n+                                        font=(\'Arial\', 16, \'bold\'), command=lambda: controller.show_frame("PageEnrollFinger"))\r\n         self.buttonTakeFace.place(relx=0.5, rely=0.3, anchor=\'center\')\r\n \r\n         self.buttonTakeFace = tk.Button(self,\r\n@@ -249,7 +254,7 @@ class PageTwo(tk.Frame):\n         self.buttonTakeFace.place(relx=0.5, rely=0.1, anchor=\'center\')\r\n \r\n \r\n-class PageThree(tk.Frame):\r\n+class PageEnrollFinger(tk.Frame):\r\n \r\n     global message\r\n     message = False\r\n@@ -259,36 +264,12 @@ class PageThree(tk.Frame):\n         global names\r\n         self.controller = controller\r\n \r\n-        def arduino_detect(msg):\r\n-            print(\'Running. Press CTRL-C to exit.\')\r\n-            if message == True:\r\n-                arduino = serial.Serial(\r\n-                    "/dev/cu.usbmodem14201", 9600, timeout=1)\r\n-                time.sleep(0.1)  # wait for serial to open\r\n-                if arduino.isOpen():\r\n-                    print("{} connected!".format(arduino.port))\r\n-                    try:\r\n-                        # cmd=str(input("Enter command : "))\r\n-                        arduino.write(str(msg).encode())\r\n-                        while True:\r\n-                            time.sleep(0.5)  # wait for arduino to answer\r\n-                            answer = arduino.readline()\r\n-                            print(answer)\r\n-                            if answer == b\'ok\':\r\n-                                # print(\'break\')\r\n-                                # cmd=str(input("Enter command : "))\r\n-                                return answer\r\n-                            # arduino.flushInput()\r\n-                    except KeyboardInterrupt:\r\n-                        print("KeyboardInterrupt has been caught.")\r\n-\r\n         def arduino_enroll(msg, new_finger_id):\r\n             print(msg)\r\n             print(new_finger_id)\r\n             print(\'Running. Press CTRL-C to exit.\')\r\n             with serial.Serial("/dev/cu.usbmodem14201", 9600, timeout=1) as enroll_finger:\r\n                 time.sleep(0.1)  # wait for serial to open\r\n-                # global arduino\r\n                 if enroll_finger.isOpen():\r\n                     print("{} connected!".format(enroll_finger.port))\r\n                     try:\r\n@@ -296,15 +277,14 @@ class PageThree(tk.Frame):\n                             time.sleep(0.5)  # wait for arduino to answer\r\n                             answer = enroll_finger.readline()\r\n                             print(answer)\r\n-                            # if b"Sensor contains" in answer or b"doesn\'t" in answer:\r\n                             enroll_finger.write(str(msg).encode())\r\n+\r\n                             if answer == b\'#id\\r\\n\':\r\n-                                # print(\'break\')\r\n                                 arduino.flushInput()\r\n                                 arduino.flushOutput()\r\n                                 arduino.reset_input_buffer()\r\n                                 arduino.reset_output_buffer()\r\n-                                # cmd = str(input("Enter command : "))\r\n+\r\n                                 cmd = str(new_finger_id)\r\n                                 enroll_finger.write(str(cmd).encode())\r\n                                 while True:\r\n@@ -544,6 +524,11 @@ class PageTakeFace(tk.Frame):\n         cam_on = False\r\n         global cap\r\n         cap = None\r\n+        global subject_now\r\n+        subject_now = db.collection(\r\n+            \'current_subject\').document(\'current\').get()\r\n+        subject_now = subject_now.to_dict()\r\n+        print(subject_now[\'name\'])\r\n         # student_id = \'_\'.join([\'student\', stundent_id_entry])\r\n \r\n         def display_frame():\r\n@@ -554,7 +539,7 @@ class PageTakeFace(tk.Frame):\n \r\n             id = stundent_id_entry.get()\r\n \r\n-            filepath = \'./data/student/raw/\' + id\r\n+            filepath = \'./data/student/raw/\' + subject_now[\'name\'] + \'/\' + id\r\n \r\n             isExist = os.path.exists(filepath)\r\n \r\n@@ -614,9 +599,19 @@ class PageTakeFace(tk.Frame):\n         def start_vid():\r\n             global cam_on, cap\r\n             stop_vid()\r\n-            cam_on = True\r\n-            cap = cv2.VideoCapture(1)\r\n-            display_frame()\r\n+            id = stundent_id_entry.get()\r\n+\r\n+            filepath = \'./data/student/raw/\' + subject_now[\'name\'] + \'/\' + id\r\n+\r\n+            isExist = os.path.exists(filepath)\r\n+\r\n+            if not isExist:\r\n+                cam_on = True\r\n+                cap = cv2.VideoCapture(1)\r\n+                display_frame()\r\n+            else:\r\n+                messagebox.showwarning("ALERT", "User exits")\r\n+                return\r\n \r\n         def stop_vid():\r\n             label_widget.configure(image=None)\r\n@@ -633,7 +628,7 @@ class PageTakeFace(tk.Frame):\n             #     messagebox.showerror(\r\n             #         "ERROR", "No enough Data, Capture at least 300 images!")\r\n             #     return\r\n-            regFaces()\r\n+            regFaces(subject_now[\'name\'])\r\n             messagebox.showinfo(\r\n                 "SUCCESS", "You can now implement your detection")\r\n \r\n@@ -682,33 +677,60 @@ THRESHOLD = [0.6, 0.7, 0.7]\n FACTOR = 0.709\r\n IMAGE_SIZE = 182\r\n INPUT_IMAGE_SIZE = 160\r\n-CLASSIFIER_PATH = \'model/facemodel.pkl\'\r\n-FACENET_MODEL_PATH = \'model/20180402-114759.pb\'\r\n-with open(CLASSIFIER_PATH, \'rb\') as file:\r\n-    model, class_names = pickle.load(file)\r\n-    print("Custom Classifier, Successfully loaded")\r\n-with tf.Graph().as_default():\r\n-\r\n-    # Cai dat GPU neu co\r\n-    gpu_options = tf.compat.v1.GPUOptions(\r\n-        per_process_gpu_memory_fraction=0.6)\r\n-    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\r\n-        gpu_options=gpu_options, log_device_placement=False))\r\n-\r\n-    with sess.as_default():\r\n-\r\n-        # Load the model\r\n-        print(\'Loading feature extraction model\')\r\n-        facenet.load_model(FACENET_MODEL_PATH)\r\n-\r\n-        # Get input and output tensors\r\n-        images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\r\n-        embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\r\n-        phase_train_placeholder = tf.compat.v1.get_default_graph(\r\n-        ).get_tensor_by_name("phase_train:0")\r\n-\r\n-        pnet, rnet, onet = detect_face.create_mtcnn(\r\n-            sess, "Helper/align")\r\n+global images_placeholder\r\n+global embeddings\r\n+global phase_train_placeholder\r\n+global pnet\r\n+global rnet\r\n+global onet\r\n+global sess\r\n+global model\r\n+global class_names\r\n+global lastSubject\r\n+lastSubject = \'\'\r\n+\r\n+\r\n+def loadSubjectModel():\r\n+    print("Loading model subject")\r\n+    global images_placeholder\r\n+    global embeddings\r\n+    global phase_train_placeholder\r\n+    global pnet\r\n+    global rnet\r\n+    global onet\r\n+    global sess\r\n+    global model\r\n+    global class_names\r\n+    global subject_now\r\n+\r\n+    CLASSIFIER_PATH = \'model/\' + subject_now[\'name\'] + \'/\' + \'facemodel.pkl\'\r\n+    FACENET_MODEL_PATH = \'model/20180402-114759.pb\'\r\n+\r\n+    with open(CLASSIFIER_PATH, \'rb\') as file:\r\n+        model, class_names = pickle.load(file)\r\n+        print("Custom Classifier, Successfully loaded")\r\n+    with tf.Graph().as_default():\r\n+\r\n+        # Cai dat GPU neu co\r\n+        gpu_options = tf.compat.v1.GPUOptions(\r\n+            per_process_gpu_memory_fraction=0.6)\r\n+        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\r\n+            gpu_options=gpu_options, log_device_placement=False))\r\n+\r\n+        with sess.as_default():\r\n+\r\n+            # Load the model\r\n+            print(\'Loading feature extraction model\')\r\n+            facenet.load_model(FACENET_MODEL_PATH)\r\n+\r\n+            # Get input and output tensors\r\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\r\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\r\n+            phase_train_placeholder = tf.compat.v1.get_default_graph(\r\n+            ).get_tensor_by_name("phase_train:0")\r\n+\r\n+            pnet, rnet, onet = detect_face.create_mtcnn(\r\n+                sess, "Helper/align")\r\n \r\n \r\n ### PAGE DETECT FACES ###\r\n@@ -727,21 +749,38 @@ class PageDetectFace(tk.Frame):\n         detect_time = 0\r\n         global mode\r\n         mode = 1\r\n-        # student_id = \'_\'.join([\'student\', stundent_id_entry])\r\n \r\n         def detect_frame():\r\n+\r\n+            global lastSubject\r\n+            subject_compare = db.collection(\r\n+                \'current_subject\').document(\'current\').get()\r\n+            subject_compare = subject_compare.to_dict()\r\n+            if subject_compare["name"] != lastSubject:\r\n+                loadSubjectModel()\r\n+                lastSubject = subject_compare["name"]\r\n+\r\n+            global images_placeholder\r\n+            global embeddings\r\n+            global phase_train_placeholder\r\n+            global pnet\r\n+            global rnet\r\n+            global onet\r\n+            global sess\r\n+            global model\r\n+            global class_names\r\n+\r\n             global cam_detect_on\r\n             global count_unknown\r\n             global detect_time\r\n+\r\n             if cam_detect_on:\r\n \r\n                 ret, frame = cap_detect.read()\r\n \r\n                 if ret:\r\n-                    # frame = cap.read()\r\n                     frame = imutils.resize(frame, width=600)\r\n                     frame = cv2.flip(frame, 1)\r\n-                    # rand_name = random.randint(0, 1000)\r\n                     bounding_boxes, _ = detect_face.detect_face(\r\n                         frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\r\n                     faces_found = bounding_boxes.shape[0]\r\n@@ -774,8 +813,6 @@ class PageDetectFace(tk.Frame):\n                             best_class_probabilities = predictions[(\r\n                                 np.arange(len(best_class_indices)), best_class_indices)]\r\n                             best_name = class_names[best_class_indices[0]]\r\n-                            # print(\'Name: {}, Probability: {}\'.format(\r\n-                            #     best_name, best_class_probabilities))\r\n \r\n                             count_unknown += 1\r\n                             if best_class_probabilities > 0.9:\r\n@@ -794,15 +831,29 @@ class PageDetectFace(tk.Frame):\n \r\n                                 file_name = best_name + ".jpg"\r\n                                 if detect_time == 2:\r\n-                                    cv2.imwrite(os.path.join(\r\n-                                        image_path, file_name), frame)\r\n-                                    cv2.destroyAllWindows()\r\n+                                    detect_time = 0\r\n                                     result = db.collection(\r\n                                         \'current_subject\').document(\'current\').get()\r\n                                     result = result.to_dict()\r\n+                                    checkInExist = db.collection(\r\n+                                        \'check_in\')\r\n+                                    checkInExist = checkInExist.where(\r\n+                                        filter=FieldFilter(\'subject\', \'==\', result[\'name\']))\r\n+                                    checkInExist = checkInExist.where(\r\n+                                        filter=FieldFilter(\'student_id\', \'==\', best_name))\r\n+                                    checkInExist = checkInExist.get()\r\n+                                    # print(checkInExist.to_dict())\r\n+                                    if len(checkInExist) != 0:\r\n+                                        messagebox.showwarning(\r\n+                                            \'ALERT\', "You had checked in this subject")\r\n+                                        stop_detect()\r\n+                                        return\r\n+                                    cv2.imwrite(os.path.join(\r\n+                                        image_path, file_name), frame)\r\n+                                    cv2.destroyAllWindows()\r\n                                     user = db.collection(\r\n-                                        \'current_subject\').document(\'current\').get()\r\n-                                    user.to_dict()\r\n+                                        \'users\').document(best_name).get()\r\n+                                    user = user.to_dict()\r\n                                     today = datetime.datetime.now()\r\n                                     print(today)\r\n                                     status = \'in_time\'\r\n@@ -811,16 +862,24 @@ class PageDetectFace(tk.Frame):\n                                         time_compare = result[\'time_in\'] + \\\r\n                                             timedelta(hours=7)\r\n                                         print(time_compare)\r\n+\r\n                                         if utc.localize(today) > time_compare:\r\n                                             status = \'vao_tre\'\r\n                                             print(\'vao tre\')\r\n                                         else:\r\n                                             status = \'vao_dung_gio\'\r\n                                             print(\'vao dung gio\')\r\n+\r\n                                         db.collection(\'check_in\').add(\r\n                                             {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'finger_id\': user[\'finger_id\'], \'time_in\': today - timedelta(hours=7)})\r\n                                         print(\'complete detect\')\r\n                                     else:\r\n+                                        checkExist = db.collection(\'check_in\').where(\r\n+                                            "finger_id", "==", best_name).get()\r\n+                                        if not checkExist:\r\n+                                            messagebox.showwarning(\r\n+                                                \'ALERT\', \'You have not check in\')\r\n+                                            return\r\n                                         time_compare = result[\'time_out\'] + \\\r\n                                             timedelta(hours=7)\r\n                                         if utc.localize(today) > time_compare:\r\n@@ -830,7 +889,7 @@ class PageDetectFace(tk.Frame):\n                                             status = \'ra_som\'\r\n                                             print(\'ra som\')\r\n                                         db.collection(\'check_out\').add(\r\n-                                            {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'time_out\': today - timedelta(hours=7)})\r\n+                                            {\'subject\': result[\'name\'], \'student_id\': best_name, \'student_name\': \'name\', \'status\': status, \'type\': \'face_detect\', \'finger_id\': user[\'finger_id\'], \'time_out\': today - timedelta(hours=7)})\r\n                                         print(\'complete detect\')\r\n                                     time.sleep(1)\r\n                                     stop_detect()\r\n@@ -842,6 +901,7 @@ class PageDetectFace(tk.Frame):\n                                 print(\'Unknown\')\r\n                                 print(count_unknown)\r\n                                 if count_unknown == 20:\r\n+                                    count_unknown = 0\r\n                                     print(\'break\')\r\n                                     best_name = \'unknown\'\r\n                                     # VideoStream(src=0).stop()\r\ndiff --git a/create_classifier.py b/create_classifier.py\nindex 9a16c5e..e274102 100644\n--- a/create_classifier.py\n+++ b/create_classifier.py\n@@ -6,9 +6,16 @@ from Helper.align_dataset_mtcnn import main\n from Helper.classifier import mainTrain\r\n \r\n \r\n-def regFaces():\r\n-    input_dir = \'data/student/raw\'\r\n-    output_dir = \'data/student/processed\'\r\n+def regFaces(subject):\r\n+    input_dir = \'data/student/raw/\' + subject\r\n+    output_dir = \'data/student/processed/\' + subject\r\n+    isExist = os.path.exists(output_dir)\r\n+\r\n+    if not isExist:\r\n+        print(\'The new directory is created!\')\r\n+        print(output_dir)\r\n+        os.makedirs(output_dir)\r\n+\r\n     image_size = 160\r\n     margin = 32\r\n     random_order = \'random_order\'\r\n@@ -26,24 +33,28 @@ def regFaces():\n     data = main(args)\r\n \r\n     if data == \'ok\':\r\n-        startTraining(data)\r\n+        startTraining(data, subject)\r\n \r\n     # data = \'complete reg faces\'\r\n     return\r\n # Method to train custom classifier to recognize face\r\n \r\n \r\n-def startTraining(data):\r\n-    os.remove(\'model/facemodel.pkl\')\r\n+def startTraining(data, subject):\r\n+    # os.remove(\'model/facemodel.pkl\')\r\n     # message = request.form[\'status\']\r\n     if data == \'ok\':\r\n-        data_dir = \'data/student/processed\'\r\n+        data_dir = \'data/student/processed/\' + subject\r\n+        checkExist = \'model/\' + subject\r\n+        isExist = os.path.exists(checkExist)\r\n+        if not isExist:\r\n+            os.mkdir(checkExist)\r\n         # test_data = \'backend/data/test/align\'\r\n         args = {\r\n             \'mode\': \'TRAIN\',\r\n             \'data_dir\': data_dir,\r\n             \'model\': \'model/20180402-114759.pb\',\r\n-            \'classifier_filename\': \'model/facemodel.pkl\',\r\n+            \'classifier_filename\': \'model/\' + subject + \'/\' + \'facemodel.pkl\',\r\n             \'use_split_dataset\': \'store_true\',\r\n             \'batch_size\': 1000,\r\n             \'image_size\': 160,\r\ndiff --git a/data/bounding_boxes_1.png b/data/bounding_boxes_1.png\nindex dbf8d69..ae0c2f8 100644\nBinary files a/data/bounding_boxes_1.png and b/data/bounding_boxes_1.png differ\ndiff --git a/data/student/raw/1915577/1.png b/data/student/raw/1915577/1.png\ndeleted file mode 100644\nindex 4933c9d..0000000\nBinary files a/data/student/raw/1915577/1.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/10.png b/data/student/raw/1915577/10.png\ndeleted file mode 100644\nindex d69176d..0000000\nBinary files a/data/student/raw/1915577/10.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/11.png b/data/student/raw/1915577/11.png\ndeleted file mode 100644\nindex f5c5c1b..0000000\nBinary files a/data/student/raw/1915577/11.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/12.png b/data/student/raw/1915577/12.png\ndeleted file mode 100644\nindex ff70d7b..0000000\nBinary files a/data/student/raw/1915577/12.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/13.png b/data/student/raw/1915577/13.png\ndeleted file mode 100644\nindex e928f8c..0000000\nBinary files a/data/student/raw/1915577/13.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/14.png b/data/student/raw/1915577/14.png\ndeleted file mode 100644\nindex 16b9f3e..0000000\nBinary files a/data/student/raw/1915577/14.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/15.png b/data/student/raw/1915577/15.png\ndeleted file mode 100644\nindex fb456cc..0000000\nBinary files a/data/student/raw/1915577/15.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/16.png b/data/student/raw/1915577/16.png\ndeleted file mode 100644\nindex 29d1874..0000000\nBinary files a/data/student/raw/1915577/16.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/17.png b/data/student/raw/1915577/17.png\ndeleted file mode 100644\nindex f864ed6..0000000\nBinary files a/data/student/raw/1915577/17.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/18.png b/data/student/raw/1915577/18.png\ndeleted file mode 100644\nindex e3dc185..0000000\nBinary files a/data/student/raw/1915577/18.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/19.png b/data/student/raw/1915577/19.png\ndeleted file mode 100644\nindex 62f3956..0000000\nBinary files a/data/student/raw/1915577/19.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/2.png b/data/student/raw/1915577/2.png\ndeleted file mode 100644\nindex 1d38d53..0000000\nBinary files a/data/student/raw/1915577/2.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/20.png b/data/student/raw/1915577/20.png\ndeleted file mode 100644\nindex 88b4e72..0000000\nBinary files a/data/student/raw/1915577/20.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/21.png b/data/student/raw/1915577/21.png\ndeleted file mode 100644\nindex 1f47ffc..0000000\nBinary files a/data/student/raw/1915577/21.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/3.png b/data/student/raw/1915577/3.png\ndeleted file mode 100644\nindex 4a4a52d..0000000\nBinary files a/data/student/raw/1915577/3.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/4.png b/data/student/raw/1915577/4.png\ndeleted file mode 100644\nindex e59b9ec..0000000\nBinary files a/data/student/raw/1915577/4.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/5.png b/data/student/raw/1915577/5.png\ndeleted file mode 100644\nindex 232704a..0000000\nBinary files a/data/student/raw/1915577/5.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/6.png b/data/student/raw/1915577/6.png\ndeleted file mode 100644\nindex 3a6b9b5..0000000\nBinary files a/data/student/raw/1915577/6.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/7.png b/data/student/raw/1915577/7.png\ndeleted file mode 100644\nindex 5b26b24..0000000\nBinary files a/data/student/raw/1915577/7.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/8.png b/data/student/raw/1915577/8.png\ndeleted file mode 100644\nindex 070b9e2..0000000\nBinary files a/data/student/raw/1915577/8.png and /dev/null differ\ndiff --git a/data/student/raw/1915577/9.png b/data/student/raw/1915577/9.png\ndeleted file mode 100644\nindex 2778196..0000000\nBinary files a/data/student/raw/1915577/9.png and /dev/null differ\ndiff --git a/images/attendance/1911368.jpg b/images/attendance/1911368.jpg\nindex 90050a5..45dfd77 100644\nBinary files a/images/attendance/1911368.jpg and b/images/attendance/1911368.jpg differ\ndiff --git a/nameslist.txt b/nameslist.txt\nindex 2f8fce4..c6a07c7 100644\n--- a/nameslist.txt\n+++ b/nameslist.txt\n@@ -1 +1 @@\n-                                                                                                                    \n\\ No newline at end of file\n+                                                                                                                          \n\\ No newline at end of file\ndiff --git a/testFirebase.py b/testFirebase.py\nindex 8a5a81c..4c73c67 100644\n--- a/testFirebase.py\n+++ b/testFirebase.py\n@@ -29,9 +29,11 @@ db = firestore.client()\n #     print(i, result[i])\n # print(result.date_in)\n \n-# result = db.collection(\n-#     \'current_subject\').document(\'current\').get()\n-# result = result.to_dict()\n+result = db.collection(\n+    \'current_subject\').document(\'current\').get()\n+result = result.to_dict()\n+print(result[\'name\'])\n+\n # time_compare = result[\'time_in\'] + timedelta(hours=7)\n # print(time_compare)\n # today = datetime.datetime.now()\n@@ -51,7 +53,6 @@ db = firestore.client()\n # else:\n #     print(\'no match\')\n \n-\n-checkExist = db.collection(\'check_in\').where(\n-    "finger_id", "==", \'2\').get()\n-print(len(checkExist))\n+# checkExist = db.collection(\'check_in\').where(\n+#     "finger_id", "==", \'2\').get()\n+# print(len(checkExist))'